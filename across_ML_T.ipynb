{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f15b7e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, time, datetime, random, glob, shutil\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from cnn_model import run_hyperparameter_search, evaluate_on_test, TimeSeriesDataset, CNNRegressor, train_model, split_LOPO\n",
    "from torch.utils.data import DataLoader\n",
    "import neurokit2 as nk  # pip install neurokit2\n",
    "import seaborn as sns\n",
    "from ml_dataloader import process_physiology_data, extract_raw_physio_windows\n",
    "from ml_utils import (\n",
    "    set_reproducible, dbg, to_NTC_strict, sample_or_load_fixed_test_pids,\n",
    "    make_participant_disjoint_masks, assert_no_pid_overlap, run_planA_one_mode,\n",
    "    negative_controls_once, summarize_split_scores, ensure_dir, center_from_train_split,\n",
    "    write_seed_metrics_csv, count_lstm_params, make_masks_from_fixed_test, recipe_for,\n",
    "    hv_mask_from_train_x, hv_mask_from_train_y, apply_per_split_mask, assert_no_pid_overlap,\n",
    "    set_seed, split_across_with_gap, to_loader, plot_train_val_loss\n",
    ")\n",
    "from ml_pipeline import (\n",
    "        run_ablation, select_features_by_ablation, run_grid_search,\n",
    "        train_and_evaluate_seeds, summarize_test_results\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ceca95",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00c832a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Raw Signals: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [02:00<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì €ìž¥ ì™„ë£Œ: ./ml_processed_raw\n",
      "ðŸ“Š X shape: (11979, 77, 150) | y shape: (11979,) | #PIDs: 103\n",
      "ðŸ§© Channels: 77 | (ì˜ˆ: ['EDA_Tonic' 'EDA_Tonic_diff1' 'EDA_Tonic_diff2' 'EDA_Tonic_ma60'\n",
      " 'EDA_Tonic_std150' 'EDA_Tonic_slope' 'EDA_Tonic_iqr' 'EDA_Phasic'\n",
      " 'EDA_Phasic_diff1' 'EDA_Phasic_diff2'])\n",
      "ðŸ“ saved: scene_array.npy, windex_array.npy, feature_tag_list.npy, meta.json\n"
     ]
    }
   ],
   "source": [
    "extract_raw_physio_windows(\n",
    "    data_path=\"./MPA_VISE\",\n",
    "    output_path=\"./ml_processed_raw\",\n",
    "    window_seconds=5,\n",
    "    stride_seconds=2,\n",
    "    sampling_rate=30,\n",
    "    scenes=\"Hallway\",\n",
    "    enable_feature_expansion=True,\n",
    "    fe_diff_orders=(1,2),\n",
    "    fe_ma_seconds=(2,),\n",
    "    fe_std_seconds=(5,),\n",
    "    fe_enable_slope=True,\n",
    "    fe_enable_iqr=True,\n",
    "    fe_enable_band_energy=False,\n",
    "    enable_target_smoothing=True,\n",
    "    target_smoothing_method=\"ema\",\n",
    "    target_smoothing_steps=15,   # â‰ˆ0.5ì´ˆ @30Hz\n",
    "    smooth_before_zscore=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d96cb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_array = np.load(\"./ml_processed_raw/X_array.npy\")       # shape: [N, C, T]\n",
    "y_array = np.load(\"./ml_processed_raw/y_array.npy\")       # shape: [N]\n",
    "pid_array = np.load(\"./ml_processed_raw/pid_array.npy\")   # shape: [N]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c17397",
   "metadata": {},
   "source": [
    "## Window 5 stride 2 30hz_Hallway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69997e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Leakage-safe main (lag OFF / (N,T,C) / publication-ready)\n",
    "# - Split FIRST (GAP=10), then derive ALL thresholds/statistics from TRAIN ONLY\n",
    "# - Train-derived HV mask (default: X-variance), Train-only target centering\n",
    "# - External-val grid (no internal split), seed ensemble (10) for final report\n",
    "# - Deterministic settings for reproducibility\n",
    "\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"42\"\n",
    "\n",
    "# Reproducibility / determinism\n",
    "torch.set_float32_matmul_precision(\"high\")  # set \"highest\" to disable TF32 if needed\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "try:\n",
    "    torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "seed = 42\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915c8d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DBG] Normalized to (N,T,C)=(11979, 150, 77), |features|=77\n",
      "[DBG] SPLIT ready (GAP=10).\n",
      "[DBG] HV_MODE=none, keep_ratio=1.000\n",
      "[DBG] Post-centering: train=(9626, 150, 77), val=(2196, 150, 77), test=(157, 150, 77)\n",
      "ðŸ” Masking EDA_Tonic (1/77)\n",
      "ðŸ” Masking EDA_Tonic_diff1 (2/77)\n",
      "ðŸ” Masking EDA_Tonic_diff2 (3/77)\n",
      "ðŸ” Masking EDA_Tonic_ma60 (4/77)\n",
      "ðŸ” Masking EDA_Tonic_std150 (5/77)\n",
      "ðŸ” Masking EDA_Tonic_slope (6/77)\n",
      "ðŸ” Masking EDA_Tonic_iqr (7/77)\n",
      "ðŸ” Masking EDA_Phasic (8/77)\n",
      "ðŸ” Masking EDA_Phasic_diff1 (9/77)\n",
      "ðŸ” Masking EDA_Phasic_diff2 (10/77)\n",
      "ðŸ” Masking EDA_Phasic_ma60 (11/77)\n",
      "ðŸ” Masking EDA_Phasic_std150 (12/77)\n",
      "ðŸ” Masking EDA_Phasic_slope (13/77)\n",
      "ðŸ” Masking EDA_Phasic_iqr (14/77)\n",
      "ðŸ” Masking SCR_Amplitude (15/77)\n",
      "ðŸ” Masking SCR_Amplitude_diff1 (16/77)\n",
      "ðŸ” Masking SCR_Amplitude_diff2 (17/77)\n",
      "ðŸ” Masking SCR_Amplitude_ma60 (18/77)\n",
      "ðŸ” Masking SCR_Amplitude_std150 (19/77)\n",
      "ðŸ” Masking SCR_Amplitude_slope (20/77)\n",
      "ðŸ” Masking SCR_Amplitude_iqr (21/77)\n",
      "ðŸ” Masking SCR_RiseTime (22/77)\n",
      "ðŸ” Masking SCR_RiseTime_diff1 (23/77)\n",
      "ðŸ” Masking SCR_RiseTime_diff2 (24/77)\n",
      "ðŸ” Masking SCR_RiseTime_ma60 (25/77)\n",
      "ðŸ” Masking SCR_RiseTime_std150 (26/77)\n",
      "ðŸ” Masking SCR_RiseTime_slope (27/77)\n",
      "ðŸ” Masking SCR_RiseTime_iqr (28/77)\n",
      "ðŸ” Masking PPG_Rate (29/77)\n",
      "ðŸ” Masking PPG_Rate_diff1 (30/77)\n",
      "ðŸ” Masking PPG_Rate_diff2 (31/77)\n",
      "ðŸ” Masking PPG_Rate_ma60 (32/77)\n",
      "ðŸ” Masking PPG_Rate_std150 (33/77)\n",
      "ðŸ” Masking PPG_Rate_slope (34/77)\n",
      "ðŸ” Masking PPG_Rate_iqr (35/77)\n",
      "ðŸ” Masking RSP_Rate (36/77)\n",
      "ðŸ” Masking RSP_Rate_diff1 (37/77)\n",
      "ðŸ” Masking RSP_Rate_diff2 (38/77)\n",
      "ðŸ” Masking RSP_Rate_ma60 (39/77)\n",
      "ðŸ” Masking RSP_Rate_std150 (40/77)\n",
      "ðŸ” Masking RSP_Rate_slope (41/77)\n",
      "ðŸ” Masking RSP_Rate_iqr (42/77)\n",
      "ðŸ” Masking RSP_RVT (43/77)\n",
      "ðŸ” Masking RSP_RVT_diff1 (44/77)\n",
      "ðŸ” Masking RSP_RVT_diff2 (45/77)\n",
      "ðŸ” Masking RSP_RVT_ma60 (46/77)\n",
      "ðŸ” Masking RSP_RVT_std150 (47/77)\n",
      "ðŸ” Masking RSP_RVT_slope (48/77)\n",
      "ðŸ” Masking RSP_RVT_iqr (49/77)\n",
      "ðŸ” Masking RSP_Amplitude (50/77)\n",
      "ðŸ” Masking RSP_Amplitude_diff1 (51/77)\n",
      "ðŸ” Masking RSP_Amplitude_diff2 (52/77)\n",
      "ðŸ” Masking RSP_Amplitude_ma60 (53/77)\n",
      "ðŸ” Masking RSP_Amplitude_std150 (54/77)\n",
      "ðŸ” Masking RSP_Amplitude_slope (55/77)\n",
      "ðŸ” Masking RSP_Amplitude_iqr (56/77)\n",
      "ðŸ” Masking pupilL (57/77)\n",
      "ðŸ” Masking pupilL_diff1 (58/77)\n",
      "ðŸ” Masking pupilL_diff2 (59/77)\n",
      "ðŸ” Masking pupilL_ma60 (60/77)\n",
      "ðŸ” Masking pupilL_std150 (61/77)\n",
      "ðŸ” Masking pupilL_slope (62/77)\n",
      "ðŸ” Masking pupilL_iqr (63/77)\n",
      "ðŸ” Masking pupilR (64/77)\n",
      "ðŸ” Masking pupilR_diff1 (65/77)\n",
      "ðŸ” Masking pupilR_diff2 (66/77)\n",
      "ðŸ” Masking pupilR_ma60 (67/77)\n",
      "ðŸ” Masking pupilR_std150 (68/77)\n",
      "ðŸ” Masking pupilR_slope (69/77)\n",
      "ðŸ” Masking pupilR_iqr (70/77)\n",
      "ðŸ” Masking pupil_mean (71/77)\n",
      "ðŸ” Masking pupil_mean_diff1 (72/77)\n",
      "ðŸ” Masking pupil_mean_diff2 (73/77)\n",
      "ðŸ” Masking pupil_mean_ma60 (74/77)\n",
      "ðŸ” Masking pupil_mean_std150 (75/77)\n",
      "ðŸ” Masking pupil_mean_slope (76/77)\n",
      "ðŸ” Masking pupil_mean_iqr (77/77)\n",
      "âœ… Ablation ê²°ê³¼ ì €ìž¥ ì™„ë£Œ â†’ results_planA_fixed_test_GRU_Attn\\ablation_GRU_Attn_20251002_161616.csv\n",
      "ðŸ“Œ ì„ íƒëœ feature ìˆ˜: 24 / 77\n",
      "ðŸ“Œ feature_indices: [31, 56, 53, 9, 1, 58, 57, 4, 3, 46, 70, 74, 0, 45, 44, 7, 25, 36, 2, 48, 71, 60, 18, 13]\n",
      "[DBG] After selection: X_train=(9626, 150, 24), X_val=(2196, 150, 24), X_test=(157, 150, 24), new_C=24\n",
      "[DBG] [GRID-PRECHECK] model=GRU_Attn | channels=24 | space_keys=['hidden_size', 'num_layers', 'dropout', 'batch_size', 'learning_rate']\n",
      "ðŸ” Trying {'hidden_size': 32, 'num_layers': 1, 'dropout': 0.2, 'batch_size': 32, 'learning_rate': 0.001}\n",
      "â¹ï¸ Early stopping at epoch 18 (best @ 11, val=0.761435)\n",
      "â¹ï¸ Early stopping at epoch 19 (best @ 12, val=0.764908)\n",
      "â¹ï¸ Early stopping at epoch 14 (best @ 7, val=0.757056)\n",
      "ðŸ” Trying {'hidden_size': 32, 'num_layers': 1, 'dropout': 0.2, 'batch_size': 32, 'learning_rate': 0.0003}\n",
      "â¹ï¸ Early stopping at epoch 18 (best @ 11, val=0.760692)\n",
      "â¹ï¸ Early stopping at epoch 19 (best @ 12, val=0.765702)\n",
      "ðŸ” Trying {'hidden_size': 32, 'num_layers': 1, 'dropout': 0.2, 'batch_size': 32, 'learning_rate': 0.0001}\n",
      "ðŸ” Trying {'hidden_size': 32, 'num_layers': 1, 'dropout': 0.3, 'batch_size': 32, 'learning_rate': 0.001}\n",
      "â¹ï¸ Early stopping at epoch 18 (best @ 11, val=0.761435)\n",
      "â¹ï¸ Early stopping at epoch 19 (best @ 12, val=0.764908)\n",
      "â¹ï¸ Early stopping at epoch 14 (best @ 7, val=0.757056)\n",
      "ðŸ” Trying {'hidden_size': 32, 'num_layers': 1, 'dropout': 0.3, 'batch_size': 32, 'learning_rate': 0.0003}\n",
      "â¹ï¸ Early stopping at epoch 18 (best @ 11, val=0.760692)\n",
      "â¹ï¸ Early stopping at epoch 19 (best @ 12, val=0.765702)\n",
      "ðŸ” Trying {'hidden_size': 32, 'num_layers': 1, 'dropout': 0.3, 'batch_size': 32, 'learning_rate': 0.0001}\n",
      "ðŸ” Trying {'hidden_size': 32, 'num_layers': 1, 'dropout': 0.4, 'batch_size': 32, 'learning_rate': 0.001}\n",
      "â¹ï¸ Early stopping at epoch 18 (best @ 11, val=0.761435)\n",
      "â¹ï¸ Early stopping at epoch 19 (best @ 12, val=0.764908)\n",
      "â¹ï¸ Early stopping at epoch 14 (best @ 7, val=0.757056)\n",
      "ðŸ” Trying {'hidden_size': 32, 'num_layers': 1, 'dropout': 0.4, 'batch_size': 32, 'learning_rate': 0.0003}\n",
      "â¹ï¸ Early stopping at epoch 18 (best @ 11, val=0.760692)\n",
      "â¹ï¸ Early stopping at epoch 19 (best @ 12, val=0.765702)\n",
      "ðŸ” Trying {'hidden_size': 32, 'num_layers': 1, 'dropout': 0.4, 'batch_size': 32, 'learning_rate': 0.0001}\n",
      "ðŸ” Trying {'hidden_size': 32, 'num_layers': 1, 'dropout': 0.5, 'batch_size': 32, 'learning_rate': 0.001}\n",
      "â¹ï¸ Early stopping at epoch 18 (best @ 11, val=0.761435)\n",
      "â¹ï¸ Early stopping at epoch 19 (best @ 12, val=0.764908)\n",
      "â¹ï¸ Early stopping at epoch 14 (best @ 7, val=0.757056)\n",
      "ðŸ” Trying {'hidden_size': 32, 'num_layers': 1, 'dropout': 0.5, 'batch_size': 32, 'learning_rate': 0.0003}\n",
      "â¹ï¸ Early stopping at epoch 18 (best @ 11, val=0.760692)\n",
      "â¹ï¸ Early stopping at epoch 19 (best @ 12, val=0.765702)\n",
      "ðŸ” Trying {'hidden_size': 32, 'num_layers': 1, 'dropout': 0.5, 'batch_size': 32, 'learning_rate': 0.0001}\n",
      "ðŸ” Trying {'hidden_size': 32, 'num_layers': 1, 'dropout': 0.6, 'batch_size': 32, 'learning_rate': 0.001}\n",
      "â¹ï¸ Early stopping at epoch 18 (best @ 11, val=0.761435)\n",
      "â¹ï¸ Early stopping at epoch 19 (best @ 12, val=0.764908)\n",
      "â¹ï¸ Early stopping at epoch 14 (best @ 7, val=0.757056)\n",
      "ðŸ” Trying {'hidden_size': 32, 'num_layers': 1, 'dropout': 0.6, 'batch_size': 32, 'learning_rate': 0.0003}\n",
      "â¹ï¸ Early stopping at epoch 18 (best @ 11, val=0.760692)\n",
      "â¹ï¸ Early stopping at epoch 19 (best @ 12, val=0.765702)\n",
      "ðŸ” Trying {'hidden_size': 32, 'num_layers': 1, 'dropout': 0.6, 'batch_size': 32, 'learning_rate': 0.0001}\n",
      "ðŸ” Trying {'hidden_size': 32, 'num_layers': 2, 'dropout': 0.2, 'batch_size': 32, 'learning_rate': 0.001}\n",
      "â¹ï¸ Early stopping at epoch 17 (best @ 10, val=0.768272)\n",
      "â¹ï¸ Early stopping at epoch 15 (best @ 8, val=0.767450)\n",
      "ðŸ” Trying {'hidden_size': 32, 'num_layers': 2, 'dropout': 0.2, 'batch_size': 32, 'learning_rate': 0.0003}\n",
      "â¹ï¸ Early stopping at epoch 16 (best @ 9, val=0.767588)\n",
      "â¹ï¸ Early stopping at epoch 19 (best @ 12, val=0.766167)\n",
      "â¹ï¸ Early stopping at epoch 15 (best @ 8, val=0.761881)\n",
      "ðŸ” Trying {'hidden_size': 32, 'num_layers': 2, 'dropout': 0.2, 'batch_size': 32, 'learning_rate': 0.0001}\n",
      "ðŸ” Trying {'hidden_size': 32, 'num_layers': 2, 'dropout': 0.3, 'batch_size': 32, 'learning_rate': 0.001}\n",
      "â¹ï¸ Early stopping at epoch 17 (best @ 10, val=0.768332)\n",
      "â¹ï¸ Early stopping at epoch 19 (best @ 12, val=0.766393)\n",
      "â¹ï¸ Early stopping at epoch 15 (best @ 8, val=0.768145)\n",
      "ðŸ” Trying {'hidden_size': 32, 'num_layers': 2, 'dropout': 0.3, 'batch_size': 32, 'learning_rate': 0.0003}\n",
      "â¹ï¸ Early stopping at epoch 16 (best @ 9, val=0.766077)\n",
      "â¹ï¸ Early stopping at epoch 19 (best @ 12, val=0.766038)\n",
      "â¹ï¸ Early stopping at epoch 15 (best @ 8, val=0.762943)\n",
      "ðŸ” Trying {'hidden_size': 32, 'num_layers': 2, 'dropout': 0.3, 'batch_size': 32, 'learning_rate': 0.0001}\n",
      "ðŸ” Trying {'hidden_size': 32, 'num_layers': 2, 'dropout': 0.4, 'batch_size': 32, 'learning_rate': 0.001}\n",
      "â¹ï¸ Early stopping at epoch 13 (best @ 6, val=0.767507)\n",
      "â¹ï¸ Early stopping at epoch 19 (best @ 12, val=0.766980)\n",
      "â¹ï¸ Early stopping at epoch 15 (best @ 8, val=0.766449)\n",
      "ðŸ” Trying {'hidden_size': 32, 'num_layers': 2, 'dropout': 0.4, 'batch_size': 32, 'learning_rate': 0.0003}\n",
      "â¹ï¸ Early stopping at epoch 16 (best @ 9, val=0.764065)\n",
      "â¹ï¸ Early stopping at epoch 19 (best @ 12, val=0.766031)\n",
      "â¹ï¸ Early stopping at epoch 15 (best @ 8, val=0.761517)\n",
      "ðŸ” Trying {'hidden_size': 32, 'num_layers': 2, 'dropout': 0.4, 'batch_size': 32, 'learning_rate': 0.0001}\n",
      "ðŸ” Trying {'hidden_size': 32, 'num_layers': 2, 'dropout': 0.5, 'batch_size': 32, 'learning_rate': 0.001}\n",
      "â¹ï¸ Early stopping at epoch 12 (best @ 5, val=0.764363)\n",
      "â¹ï¸ Early stopping at epoch 15 (best @ 8, val=0.767056)\n",
      "â¹ï¸ Early stopping at epoch 15 (best @ 8, val=0.768364)\n",
      "ðŸ” Trying {'hidden_size': 32, 'num_layers': 2, 'dropout': 0.5, 'batch_size': 32, 'learning_rate': 0.0003}\n",
      "â¹ï¸ Early stopping at epoch 16 (best @ 9, val=0.763771)\n",
      "â¹ï¸ Early stopping at epoch 19 (best @ 12, val=0.765746)\n",
      "â¹ï¸ Early stopping at epoch 15 (best @ 8, val=0.762032)\n",
      "ðŸ” Trying {'hidden_size': 32, 'num_layers': 2, 'dropout': 0.5, 'batch_size': 32, 'learning_rate': 0.0001}\n",
      "ðŸ” Trying {'hidden_size': 32, 'num_layers': 2, 'dropout': 0.6, 'batch_size': 32, 'learning_rate': 0.001}\n",
      "â¹ï¸ Early stopping at epoch 13 (best @ 6, val=0.764295)\n",
      "â¹ï¸ Early stopping at epoch 19 (best @ 12, val=0.765720)\n",
      "â¹ï¸ Early stopping at epoch 10 (best @ 3, val=0.767343)\n",
      "ðŸ” Trying {'hidden_size': 32, 'num_layers': 2, 'dropout': 0.6, 'batch_size': 32, 'learning_rate': 0.0003}\n",
      "â¹ï¸ Early stopping at epoch 18 (best @ 11, val=0.760682)\n",
      "â¹ï¸ Early stopping at epoch 15 (best @ 8, val=0.767340)\n",
      "â¹ï¸ Early stopping at epoch 18 (best @ 11, val=0.760580)\n",
      "ðŸ” Trying {'hidden_size': 32, 'num_layers': 2, 'dropout': 0.6, 'batch_size': 32, 'learning_rate': 0.0001}\n",
      "ðŸ” Trying {'hidden_size': 64, 'num_layers': 1, 'dropout': 0.2, 'batch_size': 32, 'learning_rate': 0.001}\n",
      "â¹ï¸ Early stopping at epoch 16 (best @ 9, val=0.758675)\n",
      "â¹ï¸ Early stopping at epoch 10 (best @ 3, val=0.758883)\n",
      "â¹ï¸ Early stopping at epoch 10 (best @ 3, val=0.761176)\n",
      "ðŸ” Trying {'hidden_size': 64, 'num_layers': 1, 'dropout': 0.2, 'batch_size': 32, 'learning_rate': 0.0003}\n",
      "â¹ï¸ Early stopping at epoch 20 (best @ 13, val=0.759055)\n",
      "â¹ï¸ Early stopping at epoch 16 (best @ 9, val=0.760300)\n",
      "â¹ï¸ Early stopping at epoch 18 (best @ 11, val=0.755410)\n",
      "ðŸ” Trying {'hidden_size': 64, 'num_layers': 1, 'dropout': 0.2, 'batch_size': 32, 'learning_rate': 0.0001}\n",
      "ðŸ” Trying {'hidden_size': 64, 'num_layers': 1, 'dropout': 0.3, 'batch_size': 32, 'learning_rate': 0.001}\n",
      "â¹ï¸ Early stopping at epoch 16 (best @ 9, val=0.758675)\n",
      "â¹ï¸ Early stopping at epoch 10 (best @ 3, val=0.758883)\n",
      "â¹ï¸ Early stopping at epoch 10 (best @ 3, val=0.761176)\n",
      "ðŸ” Trying {'hidden_size': 64, 'num_layers': 1, 'dropout': 0.3, 'batch_size': 32, 'learning_rate': 0.0003}\n",
      "â¹ï¸ Early stopping at epoch 20 (best @ 13, val=0.759055)\n",
      "â¹ï¸ Early stopping at epoch 16 (best @ 9, val=0.760300)\n",
      "â¹ï¸ Early stopping at epoch 18 (best @ 11, val=0.755410)\n",
      "ðŸ” Trying {'hidden_size': 64, 'num_layers': 1, 'dropout': 0.3, 'batch_size': 32, 'learning_rate': 0.0001}\n",
      "ðŸ” Trying {'hidden_size': 64, 'num_layers': 1, 'dropout': 0.4, 'batch_size': 32, 'learning_rate': 0.001}\n",
      "â¹ï¸ Early stopping at epoch 16 (best @ 9, val=0.758675)\n",
      "â¹ï¸ Early stopping at epoch 10 (best @ 3, val=0.758883)\n",
      "â¹ï¸ Early stopping at epoch 10 (best @ 3, val=0.761176)\n",
      "ðŸ” Trying {'hidden_size': 64, 'num_layers': 1, 'dropout': 0.4, 'batch_size': 32, 'learning_rate': 0.0003}\n",
      "â¹ï¸ Early stopping at epoch 20 (best @ 13, val=0.759055)\n",
      "â¹ï¸ Early stopping at epoch 16 (best @ 9, val=0.760300)\n",
      "â¹ï¸ Early stopping at epoch 18 (best @ 11, val=0.755410)\n",
      "ðŸ” Trying {'hidden_size': 64, 'num_layers': 1, 'dropout': 0.4, 'batch_size': 32, 'learning_rate': 0.0001}\n",
      "ðŸ” Trying {'hidden_size': 64, 'num_layers': 1, 'dropout': 0.5, 'batch_size': 32, 'learning_rate': 0.001}\n",
      "â¹ï¸ Early stopping at epoch 16 (best @ 9, val=0.758675)\n",
      "â¹ï¸ Early stopping at epoch 10 (best @ 3, val=0.758883)\n",
      "â¹ï¸ Early stopping at epoch 10 (best @ 3, val=0.761176)\n",
      "ðŸ” Trying {'hidden_size': 64, 'num_layers': 1, 'dropout': 0.5, 'batch_size': 32, 'learning_rate': 0.0003}\n",
      "â¹ï¸ Early stopping at epoch 20 (best @ 13, val=0.759055)\n",
      "â¹ï¸ Early stopping at epoch 16 (best @ 9, val=0.760300)\n",
      "â¹ï¸ Early stopping at epoch 18 (best @ 11, val=0.755410)\n",
      "ðŸ” Trying {'hidden_size': 64, 'num_layers': 1, 'dropout': 0.5, 'batch_size': 32, 'learning_rate': 0.0001}\n",
      "ðŸ” Trying {'hidden_size': 64, 'num_layers': 1, 'dropout': 0.6, 'batch_size': 32, 'learning_rate': 0.001}\n",
      "â¹ï¸ Early stopping at epoch 16 (best @ 9, val=0.758675)\n",
      "â¹ï¸ Early stopping at epoch 10 (best @ 3, val=0.758883)\n",
      "â¹ï¸ Early stopping at epoch 10 (best @ 3, val=0.761176)\n",
      "ðŸ” Trying {'hidden_size': 64, 'num_layers': 1, 'dropout': 0.6, 'batch_size': 32, 'learning_rate': 0.0003}\n",
      "â¹ï¸ Early stopping at epoch 20 (best @ 13, val=0.759055)\n",
      "â¹ï¸ Early stopping at epoch 16 (best @ 9, val=0.760300)\n",
      "â¹ï¸ Early stopping at epoch 18 (best @ 11, val=0.755410)\n",
      "ðŸ” Trying {'hidden_size': 64, 'num_layers': 1, 'dropout': 0.6, 'batch_size': 32, 'learning_rate': 0.0001}\n",
      "ðŸ” Trying {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.2, 'batch_size': 32, 'learning_rate': 0.001}\n",
      "â¹ï¸ Early stopping at epoch 18 (best @ 11, val=0.758876)\n",
      "â¹ï¸ Early stopping at epoch 15 (best @ 8, val=0.765918)\n",
      "â¹ï¸ Early stopping at epoch 15 (best @ 8, val=0.763695)\n",
      "ðŸ” Trying {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.2, 'batch_size': 32, 'learning_rate': 0.0003}\n",
      "â¹ï¸ Early stopping at epoch 19 (best @ 12, val=0.756316)\n",
      "â¹ï¸ Early stopping at epoch 15 (best @ 8, val=0.756618)\n",
      "ðŸ” Trying {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.2, 'batch_size': 32, 'learning_rate': 0.0001}\n",
      "â¹ï¸ Early stopping at epoch 13 (best @ 6, val=0.770516)\n",
      "ðŸ” Trying {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.3, 'batch_size': 32, 'learning_rate': 0.001}\n",
      "â¹ï¸ Early stopping at epoch 10 (best @ 3, val=0.763512)\n",
      "â¹ï¸ Early stopping at epoch 10 (best @ 3, val=0.764421)\n",
      "â¹ï¸ Early stopping at epoch 15 (best @ 8, val=0.763565)\n",
      "ðŸ” Trying {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.3, 'batch_size': 32, 'learning_rate': 0.0003}\n",
      "â¹ï¸ Early stopping at epoch 14 (best @ 7, val=0.762968)\n",
      "â¹ï¸ Early stopping at epoch 19 (best @ 12, val=0.755809)\n",
      "â¹ï¸ Early stopping at epoch 15 (best @ 8, val=0.756263)\n",
      "ðŸ” Trying {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.3, 'batch_size': 32, 'learning_rate': 0.0001}\n",
      "â¹ï¸ Early stopping at epoch 13 (best @ 6, val=0.770661)\n",
      "ðŸ” Trying {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.4, 'batch_size': 32, 'learning_rate': 0.001}\n",
      "â¹ï¸ Early stopping at epoch 10 (best @ 3, val=0.763691)\n",
      "â¹ï¸ Early stopping at epoch 10 (best @ 3, val=0.763230)\n",
      "â¹ï¸ Early stopping at epoch 15 (best @ 8, val=0.762625)\n",
      "ðŸ” Trying {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.4, 'batch_size': 32, 'learning_rate': 0.0003}\n",
      "â¹ï¸ Early stopping at epoch 14 (best @ 7, val=0.762140)\n",
      "â¹ï¸ Early stopping at epoch 19 (best @ 12, val=0.754214)\n",
      "â¹ï¸ Early stopping at epoch 15 (best @ 8, val=0.755645)\n",
      "ðŸ” Trying {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.4, 'batch_size': 32, 'learning_rate': 0.0001}\n",
      "â¹ï¸ Early stopping at epoch 13 (best @ 6, val=0.770327)\n",
      "ðŸ” Trying {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.5, 'batch_size': 32, 'learning_rate': 0.001}\n",
      "â¹ï¸ Early stopping at epoch 10 (best @ 3, val=0.762055)\n",
      "â¹ï¸ Early stopping at epoch 10 (best @ 3, val=0.763078)\n",
      "â¹ï¸ Early stopping at epoch 9 (best @ 2, val=0.762863)\n",
      "ðŸ” Trying {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.5, 'batch_size': 32, 'learning_rate': 0.0003}\n",
      "â¹ï¸ Early stopping at epoch 14 (best @ 7, val=0.760457)\n",
      "â¹ï¸ Early stopping at epoch 19 (best @ 12, val=0.753889)\n",
      "â¹ï¸ Early stopping at epoch 19 (best @ 12, val=0.756478)\n",
      "ðŸ” Trying {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.5, 'batch_size': 32, 'learning_rate': 0.0001}\n",
      "â¹ï¸ Early stopping at epoch 13 (best @ 6, val=0.769726)\n",
      "ðŸ” Trying {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.6, 'batch_size': 32, 'learning_rate': 0.001}\n",
      "â¹ï¸ Early stopping at epoch 10 (best @ 3, val=0.760701)\n",
      "â¹ï¸ Early stopping at epoch 10 (best @ 3, val=0.760579)\n",
      "â¹ï¸ Early stopping at epoch 10 (best @ 3, val=0.763080)\n",
      "ðŸ” Trying {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.6, 'batch_size': 32, 'learning_rate': 0.0003}\n",
      "â¹ï¸ Early stopping at epoch 15 (best @ 8, val=0.759916)\n",
      "â¹ï¸ Early stopping at epoch 15 (best @ 8, val=0.756227)\n",
      "ðŸ” Trying {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.6, 'batch_size': 32, 'learning_rate': 0.0001}\n",
      "ðŸ” Trying {'hidden_size': 128, 'num_layers': 1, 'dropout': 0.2, 'batch_size': 32, 'learning_rate': 0.001}\n",
      "â¹ï¸ Early stopping at epoch 12 (best @ 5, val=0.761326)\n",
      "â¹ï¸ Early stopping at epoch 16 (best @ 9, val=0.753921)\n",
      "â¹ï¸ Early stopping at epoch 10 (best @ 3, val=0.762462)\n",
      "ðŸ” Trying {'hidden_size': 128, 'num_layers': 1, 'dropout': 0.2, 'batch_size': 32, 'learning_rate': 0.0003}\n",
      "â¹ï¸ Early stopping at epoch 16 (best @ 9, val=0.754407)\n",
      "â¹ï¸ Early stopping at epoch 16 (best @ 9, val=0.760696)\n",
      "ðŸ” Trying {'hidden_size': 128, 'num_layers': 1, 'dropout': 0.2, 'batch_size': 32, 'learning_rate': 0.0001}\n",
      "â¹ï¸ Early stopping at epoch 18 (best @ 11, val=0.761454)\n",
      "ðŸ” Trying {'hidden_size': 128, 'num_layers': 1, 'dropout': 0.3, 'batch_size': 32, 'learning_rate': 0.001}\n",
      "â¹ï¸ Early stopping at epoch 12 (best @ 5, val=0.761326)\n",
      "â¹ï¸ Early stopping at epoch 16 (best @ 9, val=0.753921)\n",
      "â¹ï¸ Early stopping at epoch 10 (best @ 3, val=0.762462)\n",
      "ðŸ” Trying {'hidden_size': 128, 'num_layers': 1, 'dropout': 0.3, 'batch_size': 32, 'learning_rate': 0.0003}\n",
      "â¹ï¸ Early stopping at epoch 16 (best @ 9, val=0.754407)\n",
      "â¹ï¸ Early stopping at epoch 16 (best @ 9, val=0.760696)\n",
      "ðŸ” Trying {'hidden_size': 128, 'num_layers': 1, 'dropout': 0.3, 'batch_size': 32, 'learning_rate': 0.0001}\n",
      "â¹ï¸ Early stopping at epoch 18 (best @ 11, val=0.761454)\n",
      "ðŸ” Trying {'hidden_size': 128, 'num_layers': 1, 'dropout': 0.4, 'batch_size': 32, 'learning_rate': 0.001}\n",
      "â¹ï¸ Early stopping at epoch 12 (best @ 5, val=0.761326)\n",
      "â¹ï¸ Early stopping at epoch 16 (best @ 9, val=0.753921)\n",
      "â¹ï¸ Early stopping at epoch 10 (best @ 3, val=0.762462)\n",
      "ðŸ” Trying {'hidden_size': 128, 'num_layers': 1, 'dropout': 0.4, 'batch_size': 32, 'learning_rate': 0.0003}\n",
      "â¹ï¸ Early stopping at epoch 16 (best @ 9, val=0.754407)\n",
      "â¹ï¸ Early stopping at epoch 16 (best @ 9, val=0.760696)\n",
      "ðŸ” Trying {'hidden_size': 128, 'num_layers': 1, 'dropout': 0.4, 'batch_size': 32, 'learning_rate': 0.0001}\n",
      "â¹ï¸ Early stopping at epoch 18 (best @ 11, val=0.761454)\n",
      "ðŸ” Trying {'hidden_size': 128, 'num_layers': 1, 'dropout': 0.5, 'batch_size': 32, 'learning_rate': 0.001}\n",
      "â¹ï¸ Early stopping at epoch 12 (best @ 5, val=0.761326)\n",
      "â¹ï¸ Early stopping at epoch 16 (best @ 9, val=0.753921)\n",
      "â¹ï¸ Early stopping at epoch 10 (best @ 3, val=0.762462)\n",
      "ðŸ” Trying {'hidden_size': 128, 'num_layers': 1, 'dropout': 0.5, 'batch_size': 32, 'learning_rate': 0.0003}\n",
      "â¹ï¸ Early stopping at epoch 16 (best @ 9, val=0.754407)\n",
      "â¹ï¸ Early stopping at epoch 16 (best @ 9, val=0.760696)\n",
      "ðŸ” Trying {'hidden_size': 128, 'num_layers': 1, 'dropout': 0.5, 'batch_size': 32, 'learning_rate': 0.0001}\n",
      "â¹ï¸ Early stopping at epoch 18 (best @ 11, val=0.761454)\n",
      "ðŸ” Trying {'hidden_size': 128, 'num_layers': 1, 'dropout': 0.6, 'batch_size': 32, 'learning_rate': 0.001}\n",
      "â¹ï¸ Early stopping at epoch 12 (best @ 5, val=0.761326)\n",
      "â¹ï¸ Early stopping at epoch 16 (best @ 9, val=0.753921)\n",
      "â¹ï¸ Early stopping at epoch 10 (best @ 3, val=0.762462)\n",
      "ðŸ” Trying {'hidden_size': 128, 'num_layers': 1, 'dropout': 0.6, 'batch_size': 32, 'learning_rate': 0.0003}\n",
      "â¹ï¸ Early stopping at epoch 16 (best @ 9, val=0.754407)\n",
      "â¹ï¸ Early stopping at epoch 16 (best @ 9, val=0.760696)\n",
      "ðŸ” Trying {'hidden_size': 128, 'num_layers': 1, 'dropout': 0.6, 'batch_size': 32, 'learning_rate': 0.0001}\n",
      "â¹ï¸ Early stopping at epoch 18 (best @ 11, val=0.761454)\n",
      "ðŸ” Trying {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.2, 'batch_size': 32, 'learning_rate': 0.001}\n",
      "â¹ï¸ Early stopping at epoch 13 (best @ 6, val=0.751535)\n",
      "â¹ï¸ Early stopping at epoch 11 (best @ 4, val=0.755816)\n",
      "â¹ï¸ Early stopping at epoch 13 (best @ 6, val=0.759341)\n",
      "ðŸ” Trying {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.2, 'batch_size': 32, 'learning_rate': 0.0003}\n",
      "â¹ï¸ Early stopping at epoch 11 (best @ 4, val=0.756245)\n",
      "â¹ï¸ Early stopping at epoch 12 (best @ 5, val=0.755292)\n",
      "â¹ï¸ Early stopping at epoch 13 (best @ 6, val=0.761030)\n",
      "ðŸ” Trying {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.2, 'batch_size': 32, 'learning_rate': 0.0001}\n",
      "â¹ï¸ Early stopping at epoch 19 (best @ 12, val=0.760499)\n",
      "ðŸ” Trying {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.3, 'batch_size': 32, 'learning_rate': 0.001}\n",
      "â¹ï¸ Early stopping at epoch 13 (best @ 6, val=0.752230)\n",
      "â¹ï¸ Early stopping at epoch 11 (best @ 4, val=0.757842)\n",
      "â¹ï¸ Early stopping at epoch 13 (best @ 6, val=0.760340)\n",
      "ðŸ” Trying {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.3, 'batch_size': 32, 'learning_rate': 0.0003}\n",
      "â¹ï¸ Early stopping at epoch 13 (best @ 6, val=0.761211)\n",
      "ðŸ” Trying {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.3, 'batch_size': 32, 'learning_rate': 0.0001}\n",
      "â¹ï¸ Early stopping at epoch 19 (best @ 12, val=0.760734)\n",
      "ðŸ” Trying {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.4, 'batch_size': 32, 'learning_rate': 0.001}\n",
      "â¹ï¸ Early stopping at epoch 13 (best @ 6, val=0.751458)\n",
      "â¹ï¸ Early stopping at epoch 11 (best @ 4, val=0.753672)\n",
      "â¹ï¸ Early stopping at epoch 13 (best @ 6, val=0.761112)\n",
      "ðŸ” Trying {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.4, 'batch_size': 32, 'learning_rate': 0.0003}\n",
      "â¹ï¸ Early stopping at epoch 11 (best @ 4, val=0.755767)\n",
      "â¹ï¸ Early stopping at epoch 12 (best @ 5, val=0.755501)\n",
      "â¹ï¸ Early stopping at epoch 13 (best @ 6, val=0.760719)\n",
      "ðŸ” Trying {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.4, 'batch_size': 32, 'learning_rate': 0.0001}\n",
      "â¹ï¸ Early stopping at epoch 19 (best @ 12, val=0.760973)\n",
      "ðŸ” Trying {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.5, 'batch_size': 32, 'learning_rate': 0.001}\n",
      "â¹ï¸ Early stopping at epoch 13 (best @ 6, val=0.753067)\n",
      "â¹ï¸ Early stopping at epoch 11 (best @ 4, val=0.753729)\n",
      "â¹ï¸ Early stopping at epoch 13 (best @ 6, val=0.760863)\n",
      "ðŸ” Trying {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.5, 'batch_size': 32, 'learning_rate': 0.0003}\n",
      "â¹ï¸ Early stopping at epoch 17 (best @ 10, val=0.754321)\n",
      "â¹ï¸ Early stopping at epoch 13 (best @ 6, val=0.759769)\n",
      "ðŸ” Trying {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.5, 'batch_size': 32, 'learning_rate': 0.0001}\n",
      "â¹ï¸ Early stopping at epoch 19 (best @ 12, val=0.759627)\n",
      "ðŸ” Trying {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.6, 'batch_size': 32, 'learning_rate': 0.001}\n",
      "â¹ï¸ Early stopping at epoch 13 (best @ 6, val=0.753291)\n",
      "â¹ï¸ Early stopping at epoch 11 (best @ 4, val=0.754482)\n",
      "â¹ï¸ Early stopping at epoch 13 (best @ 6, val=0.760864)\n",
      "ðŸ” Trying {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.6, 'batch_size': 32, 'learning_rate': 0.0003}\n",
      "â¹ï¸ Early stopping at epoch 17 (best @ 10, val=0.751424)\n",
      "â¹ï¸ Early stopping at epoch 13 (best @ 6, val=0.760198)\n",
      "ðŸ” Trying {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.6, 'batch_size': 32, 'learning_rate': 0.0001}\n",
      "â¹ï¸ Early stopping at epoch 19 (best @ 12, val=0.759455)\n",
      "\n",
      "ðŸ† Best Hyperparameters:\n",
      "hidden_size : 64\n",
      "num_layers  : 2\n",
      "dropout     : 0.2\n",
      "batch_size  : 32\n",
      "learning_rate: 0.001\n",
      "âœ… Grid Search ì™„ë£Œ!\n",
      "[DBG] [GRID] best_params={'hidden_size': 64, 'num_layers': 2, 'dropout': 0.2, 'batch_size': 32, 'learning_rate': 0.001, 'val_r2_mean': 0.2590987142321011, 'val_r2_std': 0.0067398362166364864, 'val_rmse_mean': 0.8269215623537699, 'val_mae_mean': 0.6231459180514017, 'input_size': 24}\n",
      "\n",
      "ðŸŸ¢ SEED 0 ì‹œìž‘\n",
      "\n",
      "ðŸŽ¯ create_dataloaders X_train shape: (9449, 150, 24), y_train shape: (9449,)\n",
      "â¹ï¸ Early stopping at epoch 12 (best @ 5, val=0.707769)\n",
      "Saved predictions to gru_attn_test_predictions_seed0.npz\n",
      "ðŸ“Š Test RÂ²: 0.3931 | RMSE: 0.7440 | MAE: 0.4158  â†’ saved to gru_attn_test_predictions_seed0.npz\n",
      "\n",
      "ðŸŸ¢ SEED 1 ì‹œìž‘\n",
      "\n",
      "ðŸŽ¯ create_dataloaders X_train shape: (8514, 150, 24), y_train shape: (8514,)\n",
      "â¹ï¸ Early stopping at epoch 11 (best @ 4, val=0.726191)\n",
      "Saved predictions to gru_attn_test_predictions_seed1.npz\n",
      "ðŸ“Š Test RÂ²: 0.4070 | RMSE: 0.7354 | MAE: 0.3385  â†’ saved to gru_attn_test_predictions_seed1.npz\n",
      "\n",
      "ðŸŸ¢ SEED 2 ì‹œìž‘\n",
      "\n",
      "ðŸŽ¯ create_dataloaders X_train shape: (9540, 150, 24), y_train shape: (9540,)\n",
      "â¹ï¸ Early stopping at epoch 8 (best @ 1, val=0.977990)\n",
      "Saved predictions to gru_attn_test_predictions_seed2.npz\n",
      "ðŸ“Š Test RÂ²: 0.3938 | RMSE: 0.7436 | MAE: 0.3631  â†’ saved to gru_attn_test_predictions_seed2.npz\n",
      "\n",
      "ðŸŸ¢ SEED 3 ì‹œìž‘\n",
      "\n",
      "ðŸŽ¯ create_dataloaders X_train shape: (9395, 150, 24), y_train shape: (9395,)\n",
      "â¹ï¸ Early stopping at epoch 10 (best @ 3, val=0.681525)\n",
      "Saved predictions to gru_attn_test_predictions_seed3.npz\n",
      "ðŸ“Š Test RÂ²: 0.4063 | RMSE: 0.7359 | MAE: 0.4030  â†’ saved to gru_attn_test_predictions_seed3.npz\n",
      "\n",
      "ðŸŸ¢ SEED 4 ì‹œìž‘\n",
      "\n",
      "ðŸŽ¯ create_dataloaders X_train shape: (9800, 150, 24), y_train shape: (9800,)\n",
      "â¹ï¸ Early stopping at epoch 8 (best @ 1, val=0.641135)\n",
      "Saved predictions to gru_attn_test_predictions_seed4.npz\n",
      "ðŸ“Š Test RÂ²: 0.3452 | RMSE: 0.7729 | MAE: 0.3750  â†’ saved to gru_attn_test_predictions_seed4.npz\n",
      "\n",
      "ðŸŸ¢ SEED 5 ì‹œìž‘\n",
      "\n",
      "ðŸŽ¯ create_dataloaders X_train shape: (9494, 150, 24), y_train shape: (9494,)\n",
      "â¹ï¸ Early stopping at epoch 12 (best @ 5, val=0.599505)\n",
      "Saved predictions to gru_attn_test_predictions_seed5.npz\n",
      "ðŸ“Š Test RÂ²: 0.4080 | RMSE: 0.7348 | MAE: 0.4030  â†’ saved to gru_attn_test_predictions_seed5.npz\n",
      "\n",
      "ðŸŸ¢ SEED 6 ì‹œìž‘\n",
      "\n",
      "ðŸŽ¯ create_dataloaders X_train shape: (9225, 150, 24), y_train shape: (9225,)\n",
      "â¹ï¸ Early stopping at epoch 16 (best @ 9, val=0.722165)\n",
      "Saved predictions to gru_attn_test_predictions_seed6.npz\n",
      "ðŸ“Š Test RÂ²: 0.3408 | RMSE: 0.7754 | MAE: 0.3974  â†’ saved to gru_attn_test_predictions_seed6.npz\n",
      "\n",
      "ðŸŸ¢ SEED 7 ì‹œìž‘\n",
      "\n",
      "ðŸŽ¯ create_dataloaders X_train shape: (9336, 150, 24), y_train shape: (9336,)\n",
      "â¹ï¸ Early stopping at epoch 9 (best @ 2, val=0.865814)\n",
      "Saved predictions to gru_attn_test_predictions_seed7.npz\n",
      "ðŸ“Š Test RÂ²: 0.3712 | RMSE: 0.7573 | MAE: 0.3880  â†’ saved to gru_attn_test_predictions_seed7.npz\n",
      "\n",
      "ðŸŸ¢ SEED 8 ì‹œìž‘\n",
      "\n",
      "ðŸŽ¯ create_dataloaders X_train shape: (9630, 150, 24), y_train shape: (9630,)\n",
      "â¹ï¸ Early stopping at epoch 9 (best @ 2, val=0.572014)\n",
      "Saved predictions to gru_attn_test_predictions_seed8.npz\n",
      "ðŸ“Š Test RÂ²: 0.4606 | RMSE: 0.7014 | MAE: 0.3351  â†’ saved to gru_attn_test_predictions_seed8.npz\n",
      "\n",
      "ðŸŸ¢ SEED 9 ì‹œìž‘\n",
      "\n",
      "ðŸŽ¯ create_dataloaders X_train shape: (9016, 150, 24), y_train shape: (9016,)\n",
      "â¹ï¸ Early stopping at epoch 15 (best @ 8, val=0.875338)\n",
      "Saved predictions to gru_attn_test_predictions_seed9.npz\n",
      "ðŸ“Š Test RÂ²: 0.3828 | RMSE: 0.7503 | MAE: 0.3958  â†’ saved to gru_attn_test_predictions_seed9.npz\n",
      "\n",
      "ðŸŸ¢ SEED 10 ì‹œìž‘\n",
      "\n",
      "ðŸŽ¯ create_dataloaders X_train shape: (9098, 150, 24), y_train shape: (9098,)\n",
      "â¹ï¸ Early stopping at epoch 13 (best @ 6, val=0.784150)\n",
      "Saved predictions to gru_attn_test_predictions_seed10.npz\n",
      "ðŸ“Š Test RÂ²: 0.3647 | RMSE: 0.7612 | MAE: 0.3781  â†’ saved to gru_attn_test_predictions_seed10.npz\n",
      "\n",
      "ðŸŸ¢ SEED 11 ì‹œìž‘\n",
      "\n",
      "ðŸŽ¯ create_dataloaders X_train shape: (9287, 150, 24), y_train shape: (9287,)\n",
      "â¹ï¸ Early stopping at epoch 9 (best @ 2, val=0.751868)\n",
      "Saved predictions to gru_attn_test_predictions_seed11.npz\n",
      "ðŸ“Š Test RÂ²: 0.3753 | RMSE: 0.7549 | MAE: 0.3518  â†’ saved to gru_attn_test_predictions_seed11.npz\n",
      "\n",
      "ðŸŸ¢ SEED 12 ì‹œìž‘\n",
      "\n",
      "ðŸŽ¯ create_dataloaders X_train shape: (9128, 150, 24), y_train shape: (9128,)\n",
      "â¹ï¸ Early stopping at epoch 14 (best @ 7, val=0.669573)\n",
      "Saved predictions to gru_attn_test_predictions_seed12.npz\n",
      "ðŸ“Š Test RÂ²: 0.3977 | RMSE: 0.7412 | MAE: 0.4231  â†’ saved to gru_attn_test_predictions_seed12.npz\n",
      "\n",
      "ðŸŸ¢ SEED 13 ì‹œìž‘\n",
      "\n",
      "ðŸŽ¯ create_dataloaders X_train shape: (9740, 150, 24), y_train shape: (9740,)\n",
      "â¹ï¸ Early stopping at epoch 10 (best @ 3, val=0.776584)\n",
      "Saved predictions to gru_attn_test_predictions_seed13.npz\n",
      "ðŸ“Š Test RÂ²: 0.3782 | RMSE: 0.7531 | MAE: 0.4134  â†’ saved to gru_attn_test_predictions_seed13.npz\n",
      "\n",
      "ðŸŸ¢ SEED 14 ì‹œìž‘\n",
      "\n",
      "ðŸŽ¯ create_dataloaders X_train shape: (9561, 150, 24), y_train shape: (9561,)\n",
      "â¹ï¸ Early stopping at epoch 11 (best @ 4, val=0.971022)\n",
      "Saved predictions to gru_attn_test_predictions_seed14.npz\n",
      "ðŸ“Š Test RÂ²: 0.4038 | RMSE: 0.7374 | MAE: 0.3579  â†’ saved to gru_attn_test_predictions_seed14.npz\n",
      "\n",
      "ðŸŸ¢ SEED 15 ì‹œìž‘\n",
      "\n",
      "ðŸŽ¯ create_dataloaders X_train shape: (9189, 150, 24), y_train shape: (9189,)\n",
      "â¹ï¸ Early stopping at epoch 9 (best @ 2, val=0.638707)\n",
      "Saved predictions to gru_attn_test_predictions_seed15.npz\n",
      "ðŸ“Š Test RÂ²: 0.3987 | RMSE: 0.7406 | MAE: 0.4124  â†’ saved to gru_attn_test_predictions_seed15.npz\n",
      "\n",
      "ðŸŸ¢ SEED 16 ì‹œìž‘\n",
      "\n",
      "ðŸŽ¯ create_dataloaders X_train shape: (9036, 150, 24), y_train shape: (9036,)\n",
      "â¹ï¸ Early stopping at epoch 9 (best @ 2, val=0.762047)\n",
      "Saved predictions to gru_attn_test_predictions_seed16.npz\n",
      "ðŸ“Š Test RÂ²: 0.3840 | RMSE: 0.7496 | MAE: 0.3637  â†’ saved to gru_attn_test_predictions_seed16.npz\n",
      "\n",
      "ðŸŸ¢ SEED 17 ì‹œìž‘\n",
      "\n",
      "ðŸŽ¯ create_dataloaders X_train shape: (8920, 150, 24), y_train shape: (8920,)\n",
      "â¹ï¸ Early stopping at epoch 10 (best @ 3, val=0.710513)\n",
      "Saved predictions to gru_attn_test_predictions_seed17.npz\n",
      "ðŸ“Š Test RÂ²: 0.3827 | RMSE: 0.7503 | MAE: 0.4155  â†’ saved to gru_attn_test_predictions_seed17.npz\n",
      "\n",
      "ðŸŸ¢ SEED 18 ì‹œìž‘\n",
      "\n",
      "ðŸŽ¯ create_dataloaders X_train shape: (9478, 150, 24), y_train shape: (9478,)\n",
      "â¹ï¸ Early stopping at epoch 10 (best @ 3, val=0.677120)\n",
      "Saved predictions to gru_attn_test_predictions_seed18.npz\n",
      "ðŸ“Š Test RÂ²: 0.4179 | RMSE: 0.7287 | MAE: 0.4465  â†’ saved to gru_attn_test_predictions_seed18.npz\n",
      "\n",
      "ðŸŸ¢ SEED 19 ì‹œìž‘\n",
      "\n",
      "ðŸŽ¯ create_dataloaders X_train shape: (9905, 150, 24), y_train shape: (9905,)\n",
      "â¹ï¸ Early stopping at epoch 18 (best @ 11, val=0.674017)\n",
      "Saved predictions to gru_attn_test_predictions_seed19.npz\n",
      "ðŸ“Š Test RÂ²: 0.3317 | RMSE: 0.7807 | MAE: 0.4467  â†’ saved to gru_attn_test_predictions_seed19.npz\n",
      "\n",
      "ðŸ“Š í‰ê·  Test RÂ²: 0.3872 Â± 0.0284\n",
      "[SAVED] results_planA_fixed_test_GRU_Attn\\seeds_scores_GRU_Attn_20251002_161616.csv\n",
      "[SAVED] results_planA_fixed_test_GRU_Attn\\loss_curves_GRU_Attn_20251002_161616.json\n",
      "[SAVED] results_planA_fixed_test_GRU_Attn\\features_selected_GRU_Attn_20251002_161616.json\n",
      "[SAVED] results_planA_fixed_test_GRU_Attn\\predictions_index_GRU_Attn_20251002_161616.csv\n",
      "[SAVED] results_planA_fixed_test_GRU_Attn\\summary_GRU_Attn_20251002_161616.json\n",
      "[SUMMARY] test R2 mean=0.3872, RMSE mean=0.7474, MAE mean=0.3912\n",
      "\n",
      "Done. See: results_planA_fixed_test_GRU_Attn\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# 0) User config (only edit this part)\n",
    "# ===========================\n",
    "model_type = \"LSTM\"   # {\"CNN\",\"GRU\",\"GRU_Attn\",\"LSTM\"} \n",
    "DATA_DIR   = \"ml_processed_raw\"\n",
    "OUT_DIR    = f\"results_planA_fixed_test_{model_type}\"\n",
    "\n",
    "# Split / masking policy\n",
    "VAL_RATIO   = 0.20\n",
    "GAP_STEPS   = 10               # Reduce Leakage (in 30Hz, 10 steps = 0.33s)\n",
    "HV_MODE     = \"none\"           # {\"x_variance\",\"y_train\",\"none\"}\n",
    "HV_QUANTILE = 0.25\n",
    "\n",
    "# Seeds / Epochs\n",
    "SEED_MASTER = 42\n",
    "seed        = SEED_MASTER      # (Important) Fix definition to avoid undefined usage\n",
    "NUM_SEEDS_FINAL = 20\n",
    "EPOCHS_FINAL    = 50\n",
    "\n",
    "# Early stopping\n",
    "patience_ablation   = 10; min_delta_ablation = 1e-6\n",
    "patience_grid       = 7 ; min_delta_grid     = 1e-5\n",
    "patience_train      = 7 ; min_delta_train    = 1e-3\n",
    "\n",
    "# Grid / Ablation toggle\n",
    "RUN_ABLATION    = True\n",
    "ABLATION_EPOCHS = 10\n",
    "RUN_GRID        = True\n",
    "GRID_EPOCHS     = 20\n",
    "\n",
    "# Fine-tune option (for within-participant etc. extension; default pipeline is across)\n",
    "USE_ACROSS_FINAL_CKPTS = True\n",
    "FINETUNE_VAL_FRACTION  = 0.20\n",
    "FINETUNE_EPOCHS        = 8\n",
    "FINETUNE_PATIENCE      = 3\n",
    "\n",
    "# Negative controls (Default OFF)\n",
    "RUN_NEGCTRL = False\n",
    "\n",
    "# ===========================\n",
    "# 1) Reproducibility & Device\n",
    "# ===========================\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "random.seed(SEED_MASTER)\n",
    "np.random.seed(SEED_MASTER)\n",
    "torch.manual_seed(SEED_MASTER)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED_MASTER)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "ts_tag = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# ===========================\n",
    "# 2) Model-specific parameter space switch\n",
    "# - CNN uses (N,C,T) input internally â†’ check loader conversion\n",
    "# - RNN types (GRU/GRU_Attn/LSTM) use (N,T,C)\n",
    "# ===========================\n",
    "FIXED_DEFAULTS: Dict[str, Dict[str, Any]] = {\n",
    "    \"CNN\": {\n",
    "        \"num_filters\": 64,\n",
    "        \"kernel_size\": 5,\n",
    "        \"dropout\": 0.3,\n",
    "        \"batch_size\": 32,\n",
    "        \"learning_rate\": 1e-3,\n",
    "         # \"input_channels\": new_C  # Runtime injection\n",
    "    },\n",
    "    \"GRU\": {\n",
    "        \"hidden_size\": 64,\n",
    "        \"num_layers\": 1,\n",
    "        \"dropout\": 0.3,\n",
    "        \"batch_size\": 32,\n",
    "        \"learning_rate\": 1e-3,\n",
    "        # \"input_size\": C  # Runtime injection\n",
    "    },\n",
    "    \"GRU_Attn\": {\n",
    "        \"hidden_size\": 64,\n",
    "        \"num_layers\": 1,\n",
    "        \"dropout\": 0.3,\n",
    "        \"batch_size\": 32,\n",
    "        \"learning_rate\": 1e-3,\n",
    "        # \"input_size\": C\n",
    "    },\n",
    "    \"LSTM\": {\n",
    "        \"hidden_size\": 64,\n",
    "        \"num_layers\": 1,\n",
    "        \"dropout\": 0.3,\n",
    "        \"batch_size\": 32,\n",
    "        \"learning_rate\": 1e-3,\n",
    "        # \"input_size\": C\n",
    "    },\n",
    "}\n",
    "\n",
    "SEARCH_SPACES: Dict[str, Dict[str, Any]] = {\n",
    "    \"CNN\": {\n",
    "        \"num_filters\": [16, 32, 64],\n",
    "        \"kernel_size\": [3, 5, 7],  # Effective length check will be done at runtime\n",
    "        \"dropout\": [0.3, 0.4, 0.5, 0.6],\n",
    "        \"batch_size\": [32],\n",
    "        \"learning_rate\": [1e-3, 3e-4, 1e-4],\n",
    "    },\n",
    "    \"GRU\": {\n",
    "        \"hidden_size\": [32, 64, 128],\n",
    "        \"num_layers\": [1, 2],\n",
    "        \"dropout\": [0.2, 0.3, 0.4, 0.5, 0.6],\n",
    "        \"batch_size\": [32],\n",
    "        \"learning_rate\": [1e-3, 3e-4, 1e-4],\n",
    "    },\n",
    "    \"GRU_Attn\": {\n",
    "        \"hidden_size\": [32, 64, 128],\n",
    "        \"num_layers\": [1, 2],\n",
    "        \"dropout\": [0.2, 0.3, 0.4, 0.5, 0.6],\n",
    "        \"batch_size\": [32],\n",
    "        \"learning_rate\": [1e-3, 3e-4, 1e-4],\n",
    "    },\n",
    "    \"LSTM\": {\n",
    "        \"hidden_size\": [32, 64, 128],\n",
    "        \"num_layers\": [1, 2],\n",
    "        \"dropout\": [0.2, 0.3, 0.4, 0.5, 0.6],\n",
    "        \"batch_size\": [32],\n",
    "        \"learning_rate\": [1e-3, 3e-4, 1e-4],\n",
    "    },\n",
    "}\n",
    "\n",
    "HEAD_NAMES_PER_MODEL = {\n",
    "    \"CNN\":      [\"head\", \"fc\", \"out\", \"regressor\"],\n",
    "    \"GRU\":      [\"head\", \"fc\", \"out\", \"regressor\"],\n",
    "    \"GRU_Attn\": [\"head\", \"fc\", \"out\", \"regressor\", \"proj\"],\n",
    "    \"LSTM\":     [\"head\", \"fc\", \"out\", \"regressor\"],\n",
    "}\n",
    "\n",
    "assert model_type in FIXED_DEFAULTS, f\"Unknown model_type: {model_type}\"\n",
    "\n",
    "# ===========================\n",
    "# 3) Data load + enforce (N,T,C)\n",
    "# ===========================\n",
    "X = np.load(f\"{DATA_DIR}/X_array.npy\")                 # (N,C,T) or (N,T,C)\n",
    "y = np.load(f\"{DATA_DIR}/y_array.npy\").astype(np.float32)\n",
    "pid = np.load(f\"{DATA_DIR}/pid_array.npy\")\n",
    "scene = np.load(f\"{DATA_DIR}/scene_array.npy\")\n",
    "widx = np.load(f\"{DATA_DIR}/windex_array.npy\")\n",
    "feature_tag_list = np.load(f\"{DATA_DIR}/feature_tag_list.npy\", allow_pickle=True).tolist()\n",
    "\n",
    "X = to_NTC_strict(X, feature_tag_list)                # (N,T,C)\n",
    "N, T, C = X.shape\n",
    "dbg(f\"Normalized to (N,T,C)={X.shape}, |features|={len(feature_tag_list)}\")\n",
    "assert len(feature_tag_list) == C, f\"len(feature_tag_list)={len(feature_tag_list)} != C={C}\"\n",
    "\n",
    "# ===========================\n",
    "# 4) Split (GAP) â†’ HV(train only) â†’ Splitâˆ©HV â†’ Train-only Centering\n",
    "# ===========================\n",
    "train_m, val_m, test_m, split_info = split_across_with_gap(\n",
    "    pid, scene, widx, val_ratio=VAL_RATIO, gap_steps=GAP_STEPS, seed=seed\n",
    ")\n",
    "dbg(f\"SPLIT ready (GAP={GAP_STEPS}).\")\n",
    "\n",
    "if HV_MODE == \"none\":\n",
    "    keep_all = np.ones_like(y, dtype=bool)\n",
    "elif HV_MODE == \"x_variance\":\n",
    "    keep_all = hv_mask_from_train_x(X, train_m, q=HV_QUANTILE)\n",
    "else:  # \"y_train\"\n",
    "    keep_all = hv_mask_from_train_y(y, pid, scene, train_m, q=HV_QUANTILE)\n",
    "dbg(f\"HV_MODE={HV_MODE}, keep_ratio={keep_all.mean():.3f}\")\n",
    "\n",
    "(TR, VA, TE) = apply_per_split_mask(X, y, pid, scene, widx, train_m, val_m, test_m, keep_all)\n",
    "X_train_raw, y_train_raw, pid_train, scene_train, _ = TR\n",
    "X_val_raw,   y_val_raw,   pid_val,   scene_val,   _ = VA\n",
    "X_test_raw,  y_test_raw,  pid_test,  scene_test,  _ = TE\n",
    "\n",
    "assert_no_pid_overlap(pid_train, pid_test)\n",
    "\n",
    "center_fn, stat = center_from_train_split(y_train_raw, pid_train, scene_train)\n",
    "y_train = center_fn(y_train_raw, pid_train, scene_train)\n",
    "y_val   = center_fn(y_val_raw,   pid_val,   scene_val)\n",
    "y_test  = center_fn(y_test_raw,  pid_test,  scene_test)\n",
    "\n",
    "X_train, X_val, X_test = X_train_raw, X_val_raw, X_test_raw\n",
    "dbg(f\"Post-centering: train={X_train.shape}, val={X_val.shape}, test={X_test.shape}\")\n",
    "\n",
    "# Save split record\n",
    "split_json = {\n",
    "    \"val_ratio\": VAL_RATIO,\n",
    "    \"gap_steps\": GAP_STEPS,\n",
    "    \"seed\": seed,\n",
    "    \"HV_MODE\": HV_MODE,\n",
    "    \"HV_QUANTILE\": HV_QUANTILE,\n",
    "    \"train_pids\": sorted(list(set(pid_train.tolist()))),\n",
    "    \"val_pids\":   sorted(list(set(pid_val.tolist()))),\n",
    "    \"test_pids\":  sorted(list(set(pid_test.tolist()))),\n",
    "}\n",
    "with open(os.path.join(OUT_DIR, f\"split_{model_type}_{ts_tag}.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(split_json, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# ===========================\n",
    "# 5) Ablation (mask-based; leakage-safe)\n",
    "# ===========================\n",
    "# base params for ablation/grid\n",
    "fixed_params = dict(FIXED_DEFAULTS[model_type])\n",
    "\n",
    "# (CNN only) input_channels injected after feature selection\n",
    "if RUN_ABLATION:\n",
    "    # Common ablation call (branch inside by model_type)\n",
    "    ablation_path = os.path.join(OUT_DIR, f\"ablation_{model_type}_{ts_tag}.csv\")\n",
    "    df_ablation = run_ablation(\n",
    "        X_train, y_train, pid_train,\n",
    "        X_val,   y_val,   pid_val,\n",
    "        feature_tag_list,\n",
    "        model_type=model_type,\n",
    "        fixed_params=fixed_params,\n",
    "        seed=seed,\n",
    "        num_epochs=ABLATION_EPOCHS,\n",
    "        save_path=ablation_path,\n",
    "        patience=patience_ablation,\n",
    "        min_delta=min_delta_ablation\n",
    "    )\n",
    "    keep_features, keep_indices = select_features_by_ablation(df_ablation, feature_tag_list, threshold=0.0005)\n",
    "    assert len(keep_indices) > 0, \"No features selected by ablation.\"\n",
    "else:\n",
    "    keep_indices = np.arange(X_train.shape[-1]).tolist()\n",
    "    keep_features = feature_tag_list\n",
    "\n",
    "# Channel slice\n",
    "X_train = X_train[:, :, keep_indices]\n",
    "X_val   = X_val[:,   :, keep_indices]\n",
    "X_test  = X_test[:,  :, keep_indices]\n",
    "feature_tag_list = (np.array(feature_tag_list)[keep_indices]).tolist()\n",
    "new_C = X_train.shape[-1]\n",
    "dbg(f\"After selection: X_train={X_train.shape}, X_val={X_val.shape}, X_test={X_test.shape}, new_C={new_C}\")\n",
    "\n",
    "# ===========================\n",
    "# 6) Grid Search (external validation) â€” model-specific space/injection\n",
    "# ===========================\n",
    "search_space = {k: list(v) for k, v in SEARCH_SPACES[model_type].items()}\n",
    "\n",
    "# Pre-loader check (especially CNN kernel size validity)\n",
    "if model_type == \"CNN\":\n",
    "    # CNN assumes to_loader handles the (N,C,T) transformation internally\n",
    "    tmp_loader = to_loader(X_train, y_train, model_type=\"CNN\", batch_size=1, shuffle=False, input_channels=new_C)\n",
    "    xb, _ = next(iter(tmp_loader))\n",
    "    # Expectation: (1, new_C, T)\n",
    "    L_eff = xb.shape[-1]\n",
    "    # Adjust kernel_size validity\n",
    "    if \"kernel_size\" in search_space:\n",
    "        search_space[\"kernel_size\"] = [k for k in search_space[\"kernel_size\"] if k <= L_eff]\n",
    "    # Inject runtime params\n",
    "    fixed_params[\"input_channels\"] = new_C\n",
    "else:\n",
    "    # RNN types use input_size=C\n",
    "    fixed_params[\"input_size\"] = new_C\n",
    "\n",
    "dbg(f\"[GRID-PRECHECK] model={model_type} | channels={new_C} | space_keys={list(search_space.keys())}\")\n",
    "\n",
    "if RUN_GRID:\n",
    "    best_params, _ = run_grid_search(\n",
    "        X_train, y_train, pid_train,\n",
    "        model_type=model_type,\n",
    "        search_space=search_space,\n",
    "        seed=seed,\n",
    "        num_epochs=GRID_EPOCHS,\n",
    "        patience=patience_grid,\n",
    "        min_delta=min_delta_grid,\n",
    "        use_internal_split=False,\n",
    "        external_val_data=(X_val, y_val)\n",
    "    )\n",
    "    best_params = dict(best_params)\n",
    "else:\n",
    "    # Grid skip â†’ Use defaults\n",
    "    best_params = dict(FIXED_DEFAULTS[model_type])\n",
    "\n",
    "# Runtime injection of required params\n",
    "if model_type == \"CNN\":\n",
    "    best_params[\"input_channels\"] = new_C\n",
    "else:\n",
    "    best_params[\"input_size\"] = new_C\n",
    "\n",
    "# Save\n",
    "grid_best_path = os.path.join(OUT_DIR, f\"grid_best_{model_type}_{ts_tag}.json\")\n",
    "with open(grid_best_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(best_params, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "dbg(f\"[GRID] best_params={best_params}\")\n",
    "\n",
    "# ===========================\n",
    "# 7) Train on train+val â†’ Test (NUM_SEEDS_FINAL)\n",
    "# ===========================\n",
    "X_trainval = np.concatenate([X_train, X_val], axis=0)\n",
    "y_trainval = np.concatenate([y_train, y_val], axis=0)\n",
    "pid_trainval = np.concatenate([pid_train, pid_val], axis=0)\n",
    "\n",
    "# Safety\n",
    "if model_type == \"CNN\":\n",
    "    assert X_trainval.shape[-1] == X_test.shape[-1] == best_params[\"input_channels\"], \\\n",
    "        f\"C mismatch: trainval C={X_trainval.shape[-1]}, test C={X_test.shape[-1]}, param={best_params['input_channels']}\"\n",
    "else:\n",
    "    assert X_trainval.shape[-1] == X_test.shape[-1] == best_params[\"input_size\"], \\\n",
    "        f\"C mismatch: trainval C={X_trainval.shape[-1]}, test C={X_test.shape[-1]}, param={best_params['input_size']}\"\n",
    "assert_no_pid_overlap(pid_trainval, pid_test)\n",
    "\n",
    "\n",
    "train_losses, val_losses, test_scores, train_scores, val_scores  = train_and_evaluate_seeds(\n",
    "    X_trainval, y_trainval, pid_trainval,\n",
    "    X_test, y_test,\n",
    "    model_type=model_type,\n",
    "    best_params=best_params,\n",
    "    device=device,\n",
    "    num_seeds=NUM_SEEDS_FINAL,\n",
    "    num_epochs=EPOCHS_FINAL,\n",
    "    patience=patience_train,\n",
    "    min_delta=min_delta_train\n",
    ")\n",
    "\n",
    "# ===========================\n",
    "# 8) Summaries + META Save\n",
    "# ===========================\n",
    "summarize_test_results(test_scores)\n",
    "\n",
    "meta = {\n",
    "    \"timestamp\": ts_tag,\n",
    "    \"model_type\": model_type,\n",
    "    \"DATA_DIR\": DATA_DIR,\n",
    "    \"OUT_DIR\": OUT_DIR,\n",
    "    \"format\": \"(N,T,C)\",\n",
    "    \"channels\": int(new_C),\n",
    "    \"GAP_STEPS\": GAP_STEPS,\n",
    "    \"HV_MODE\": HV_MODE,\n",
    "    \"HV_QUANTILE\": HV_QUANTILE,\n",
    "    \"VAL_RATIO\": VAL_RATIO,\n",
    "    \"SEED_MASTER\": SEED_MASTER,\n",
    "    \"NUM_SEEDS_FINAL\": NUM_SEEDS_FINAL,\n",
    "    \"EPOCHS_FINAL\": EPOCHS_FINAL,\n",
    "    \"RUN_ABLATION\": RUN_ABLATION,\n",
    "    \"ABLATION_EPOCHS\": ABLATION_EPOCHS,\n",
    "    \"RUN_GRID\": RUN_GRID,\n",
    "    \"GRID_EPOCHS\": GRID_EPOCHS,\n",
    "    \"best_params\": best_params,\n",
    "    \"center_stat\": {k: (float(v) if hasattr(v, \"__float__\") else v) for k, v in stat.items()},\n",
    "    \"split_info\": split_info,\n",
    "    \"HEAD_NAMES\": HEAD_NAMES_PER_MODEL.get(model_type, []),\n",
    "    \"lag\": \"DISABLED\",\n",
    "}\n",
    "with open(os.path.join(OUT_DIR, f\"meta_{model_type}_{ts_tag}.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(meta, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# ===========================\n",
    "# 9) Save artifacts for later plotting\n",
    "# ===========================\n",
    "import os, re, json, glob, shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# 9-1) Seed-wise scores CSV (train / val / test)\n",
    "rows = []\n",
    "for s in range(len(test_scores)):\n",
    "    tr = train_scores[s] if s < len(train_scores) else (np.nan, np.nan, np.nan)\n",
    "    va = val_scores[s]   if s < len(val_scores)   else (np.nan, np.nan, np.nan)\n",
    "    te = test_scores[s]  if s < len(test_scores)  else (np.nan, np.nan, np.nan)\n",
    "    rows.append({\"seed\": s, \"split\": \"train\", \"r2\": tr[0], \"rmse\": tr[1], \"mae\": tr[2]})\n",
    "    rows.append({\"seed\": s, \"split\": \"val\",   \"r2\": va[0], \"rmse\": va[1], \"mae\": va[2]})\n",
    "    rows.append({\"seed\": s, \"split\": \"test\",  \"r2\": te[0], \"rmse\": te[1], \"mae\": te[2]})\n",
    "\n",
    "df_scores = pd.DataFrame(rows, columns=[\"seed\", \"split\", \"r2\", \"rmse\", \"mae\"])\n",
    "scores_csv = os.path.join(OUT_DIR, f\"seeds_scores_{model_type}_{ts_tag}.csv\")\n",
    "df_scores.to_csv(scores_csv, index=False, encoding=\"utf-8\")\n",
    "print(f\"[SAVED] {scores_csv}\")\n",
    "\n",
    "# 9-2) Loss curves (list-of-lists) â†’ JSON\n",
    "loss_json = {\n",
    "    \"train_losses\": [[float(x) for x in (lst or [])] for lst in (train_losses or [])],\n",
    "    \"val_losses\":   [[float(x) for x in (lst or [])] for lst in (val_losses or [])],\n",
    "}\n",
    "loss_path = os.path.join(OUT_DIR, f\"loss_curves_{model_type}_{ts_tag}.json\")\n",
    "with open(loss_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(loss_json, f, ensure_ascii=False, indent=2)\n",
    "print(f\"[SAVED] {loss_path}\")\n",
    "\n",
    "# 9-3) Selected feature tags snapshot (after ablation/selection)\n",
    "feat_path = os.path.join(OUT_DIR, f\"features_selected_{model_type}_{ts_tag}.json\")\n",
    "with open(feat_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"features\": feature_tag_list, \"num_features\": int(len(feature_tag_list))}, f, ensure_ascii=False, indent=2)\n",
    "print(f\"[SAVED] {feat_path}\")\n",
    "\n",
    "# 9-4) Prediction files: move into OUT_DIR and index them\n",
    "# evaluate_and_save()ê°€ CWDì— ì €ìž¥í–ˆì„ ìˆ˜ ìžˆìœ¼ë¯€ë¡œ íŒ¨í„´ìœ¼ë¡œ ìˆ˜ì§‘\n",
    "pred_pat = f\"{model_type.lower()}_test_predictions_seed*.npz\"\n",
    "pred_files = glob.glob(pred_pat)\n",
    "pred_index = []\n",
    "\n",
    "for src in pred_files:\n",
    "    # seed ë²ˆí˜¸ ì¶”ì¶œ\n",
    "    m = re.search(r\"seed(\\d+)\\.npz$\", src)\n",
    "    seed_str = m.group(1) if m else \"NA\"\n",
    "    dst = os.path.join(OUT_DIR, f\"{model_type.lower()}_test_predictions_seed{seed_str}_{ts_tag}.npz\")\n",
    "    try:\n",
    "        shutil.move(src, dst)\n",
    "    except Exception:\n",
    "        # ì´ë¯¸ OUT_DIRë¡œ ì €ìž¥ëœ ê²½ìš° copy ì‹œë„ or skip\n",
    "        if os.path.abspath(os.path.dirname(src)) != os.path.abspath(OUT_DIR):\n",
    "            shutil.copy2(src, dst)\n",
    "    pred_index.append({\"seed\": int(seed_str) if seed_str.isdigit() else np.nan, \"path\": dst})\n",
    "\n",
    "# ì´ë¯¸ OUT_DIRì— ì €ìž¥ëœ ê²½ìš°(ì½”ë“œê°€ evaluate_and_saveì—ì„œ ê²½ë¡œë¥¼ ë°›ë„ë¡ êµ¬í˜„ëœ ê²½ìš°)ë„ ë‹¤ì‹œ ìŠ¤ìº”\n",
    "pred_files_out = glob.glob(os.path.join(OUT_DIR, f\"{model_type.lower()}_test_predictions_seed*.npz\"))\n",
    "for p in pred_files_out:\n",
    "    m = re.search(r\"seed(\\d+)\", os.path.basename(p))\n",
    "    seed_str = m.group(1) if m else \"NA\"\n",
    "    if not any(d[\"path\"] == p for d in pred_index):\n",
    "        pred_index.append({\"seed\": int(seed_str) if seed_str.isdigit() else np.nan, \"path\": p})\n",
    "\n",
    "pred_csv = os.path.join(OUT_DIR, f\"predictions_index_{model_type}_{ts_tag}.csv\")\n",
    "pd.DataFrame(pred_index, columns=[\"seed\", \"path\"]).to_csv(pred_csv, index=False, encoding=\"utf-8\")\n",
    "print(f\"[SAVED] {pred_csv}\")\n",
    "\n",
    "# 9-5) Compact experiment summary for quick plotting dashboards\n",
    "summary = {\n",
    "    \"timestamp\": ts_tag,\n",
    "    \"model_type\": model_type,\n",
    "    \"num_seeds\": len(test_scores),\n",
    "    \"scores_csv\": os.path.basename(scores_csv),\n",
    "    \"loss_curves_json\": os.path.basename(loss_path),\n",
    "    \"features_json\": os.path.basename(feat_path),\n",
    "    \"predictions_index_csv\": os.path.basename(pred_csv),\n",
    "}\n",
    "summary_path = os.path.join(OUT_DIR, f\"summary_{model_type}_{ts_tag}.json\")\n",
    "with open(summary_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(summary, f, ensure_ascii=False, indent=2)\n",
    "print(f\"[SAVED] {summary_path}\")\n",
    "\n",
    "# (Optional) Quick sanity print\n",
    "print(f\"[SUMMARY] test R2 mean={np.nanmean([s[0] for s in test_scores]):.4f}, \"\n",
    "      f\"RMSE mean={np.nanmean([s[1] for s in test_scores]):.4f}, \"\n",
    "      f\"MAE mean={np.nanmean([s[2] for s in test_scores]):.4f}\")\n",
    "\n",
    "\n",
    "# ===========================\n",
    "# 9) (Optional) Negative Controls\n",
    "# ===========================\n",
    "if RUN_NEGCTRL:\n",
    "    try:\n",
    "        from ml_utils import negative_controls_once\n",
    "        print(\"\\n========== NEGATIVE CONTROLS ==========\")\n",
    "        negative_controls_once(\n",
    "            X_trainval, y_trainval, pid_trainval,\n",
    "            X_test, y_test,\n",
    "            best_params, model_type, device\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Negative controls skipped due to error: {e}\")\n",
    "\n",
    "print(f\"\\nDone. See: {OUT_DIR}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
