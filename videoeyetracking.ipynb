{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import pandas as pd\n",
    "# import collections\n",
    "\n",
    "\n",
    "# # Ensure you're working with a copy of the DataFrame slice\n",
    "# def ETGaze2Video(video_path, eye_data, dtype='gaze',output_video=\"pilot2/processed/output_with_gaze.mp4\"):\n",
    "#     columns = [f'{dtype}L_X', f'{dtype}L_Y', f'{dtype}L_Z',\n",
    "#               f'{dtype}R_X', f'{dtype}R_Y', f'{dtype}R_Z']\n",
    "#     # Now, you can safely modify gaze_data\n",
    "#     # eye_data[['pupilLSensorPosR_X', 'pupilLSensorPosR_Y']] = eye_data[['pupilLSensorPosR_X', 'pupilLSensorPosR_Y']].interpolate()\n",
    "#     eye_data = eye_data.copy()\n",
    "#     eye_data[columns] = eye_data[columns].interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "#     # Check for any remaining NaN values after interpolation\n",
    "#     # eye_data[['pupilLSensorPosR_X', 'pupilLSensorPosR_Y']] = eye_data[['pupilLSensorPosR_X', 'pupilLSensorPosR_Y']].fillna(0.5) #########\n",
    "#     eye_data['normalized_Unitytime'] = eye_data.groupby('Scene')['Unitytime'].transform(lambda x: x - x.min())\n",
    "\n",
    "#     # Initialize video capture and writer\n",
    "#     cap = cv2.VideoCapture(video_path)\n",
    "#     fps = int(cap.get(cv2.CAP_PROP_FPS))  # Frames per second of the video\n",
    "#     frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "#     frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "#     # Set target resolution for output video\n",
    "#     # target_width, target_height = 1920, 1080  # Example resolution\n",
    "#     target_width, target_height = 1920, 1080  # Example resolution\n",
    "    \n",
    "\n",
    "#     # Initialize VideoWriter with target resolution\n",
    "#     out = cv2.VideoWriter(output_video, cv2.VideoWriter_fourcc(*'mp4v'), fps, (target_width, target_height))\n",
    "\n",
    "#     # Scale factor for Vive Pro Eye resolution to target video resolution\n",
    "#     # vive_width, vive_height = 2880, 1600  # Original Vive resolution\n",
    "#     # scale_x = target_width / vive_width\n",
    "#     # scale_y = target_height / vive_height\n",
    "\n",
    "#     # Convert normalized Unitytime to frame indices\n",
    "#     maxlen = 30 ##Length of previous data shown\n",
    "#     eye_data['frame_idx'] = (eye_data['normalized_Unitytime'] * fps).astype(int)\n",
    "#     gaze_buffer_L = collections.deque(maxlen=maxlen)\n",
    "#     gaze_buffer_R = collections.deque(maxlen=maxlen)\n",
    "#     gaze_buffer_T = collections.deque(maxlen=maxlen)\n",
    "    \n",
    "#     # Iterate over each frame of the video\n",
    "#     frame_idx = 0\n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             print(f\"Failed to read frame {frame_idx}\")\n",
    "#             break\n",
    "#         if frame is None:\n",
    "#             print(f\"Frame {frame_idx} is None!\")\n",
    "#             continue\n",
    "#         # Resize the frame to match the target resolution (if necessary)\n",
    "#         if frame_width != target_width or frame_height != target_height:\n",
    "#             frame = cv2.resize(frame, (target_width, target_height))\n",
    "\n",
    "#         # Retrieve gaze data for the current frame\n",
    "#         gaze_data = eye_data[eye_data['frame_idx'] == frame_idx]\n",
    "\n",
    "#         if not gaze_data.empty:\n",
    "#             # Extract and scale gaze coordinates (already in 2880x1600 space)\n",
    "#             x_L, y_L = gaze_data[f'{dtype}L_X'].mean(), gaze_data[f'{dtype}L_Y'].mean()\n",
    "#             x_R, y_R = gaze_data[f'{dtype}R_X'].mean(), gaze_data[f'{dtype}R_Y'].mean()\n",
    "\n",
    "#             # Convert normalized gaze points to pixel positions\n",
    "#             x_L, y_L = int(x_L * target_width), int(y_L * target_height)  # Left eye (1440x1600)\n",
    "#             x_R, y_R = int(x_R * target_width), int(y_R * target_height)  # Right eye (shifted by 1440)\n",
    "#             x_T, y_T = (x_L + x_R) // 2, (y_L + y_R) // 2  # Combined gaze point\n",
    "\n",
    "#             # Append gaze points to buffers\n",
    "#             if 0 <= x_L < target_width and 0 <= y_L < target_height:\n",
    "#                 gaze_buffer_L.append((x_L, y_L))\n",
    "#             if 0 <= x_R < target_width and 0 <= y_R < target_height:\n",
    "#                 gaze_buffer_R.append((x_R, y_R))\n",
    "#             if 0 <= x_T < target_width and 0 <= y_T < target_height:\n",
    "#                 gaze_buffer_T.append((x_T, y_T))\n",
    "\n",
    "#         # Draw gaze points with fading effect\n",
    "#         overlay = frame.copy()\n",
    "#         for i, (gx, gy) in enumerate(gaze_buffer_L):  # Left eye (Red)\n",
    "#             alpha = (i + 1) / 30 * 0.5\n",
    "#             color = (0, 0, int(255 * alpha))\n",
    "#             cv2.circle(overlay, (gx, gy), 5, color, -1)\n",
    "#         for i, (gx, gy) in enumerate(gaze_buffer_R):  # Right eye (Green)\n",
    "#             alpha = (i + 1) / 30 * 0.5\n",
    "#             color = (0, int(255 * alpha), 0)\n",
    "#             cv2.circle(overlay, (gx, gy), 5, color, -1)\n",
    "#         for i, (gx, gy) in enumerate(gaze_buffer_T):  # Combined gaze (Blue)\n",
    "#             alpha = (i + 1) / 30 * 0.5\n",
    "#             color = (int(255 * alpha), 0, 0)\n",
    "#             cv2.circle(overlay, (gx, gy), 5, color, -1)\n",
    "\n",
    "#         # Combine overlay and original frame\n",
    "#         frame = cv2.addWeighted(overlay, 0.5, frame, 0.5, 0)\n",
    "\n",
    "#         # Highlight the latest gaze points\n",
    "#         if gaze_buffer_L:\n",
    "#             cv2.circle(frame, gaze_buffer_L[-1], 7, (0, 0, 255), -1)  # Left eye\n",
    "#         if gaze_buffer_R:\n",
    "#             cv2.circle(frame, gaze_buffer_R[-1], 7, (0, 255, 0), -1)  # Right eye\n",
    "#         if gaze_buffer_T:\n",
    "#             cv2.circle(frame, gaze_buffer_T[-1], 7, (255, 0, 0), -1)  # Combined\n",
    "\n",
    "#         # Write the frame to the output video\n",
    "#         out.write(frame)\n",
    "#         frame_idx += 1\n",
    "\n",
    "#     # Release resources\n",
    "#     cap.release()\n",
    "#     out.release()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def project_gaze_to_2d(gaze_origin, gaze_vector, convergence_distance, screen_width, screen_height, screen_mm_width, screen_mm_height):\n",
    "#     \"\"\"\n",
    "#     Project a 3D gaze vector onto a 2D screen plane using the convergence distance.\n",
    "#     Normalizes the result and converts to screen pixel coordinates.\n",
    "#     \"\"\"\n",
    "#     if convergence_distance is None or math.isnan(convergence_distance):\n",
    "#         convergence_distance = 10000\n",
    "    \n",
    "    \n",
    "#     # Calculate the 3D landing point based on gaze origin, direction, and convergence distance\n",
    "#     landing_x = gaze_origin[0] + gaze_vector[0] * convergence_distance\n",
    "#     landing_y = gaze_origin[1] + gaze_vector[1] * convergence_distance\n",
    "#     landing_z = gaze_origin[2] + gaze_vector[2] * convergence_distance\n",
    "\n",
    "#     # Convert the 3D landing point (in mm) to normalized screen coordinates (0-1)\n",
    "#     normalized_x = (landing_x + (screen_mm_width / 2)) / screen_mm_width\n",
    "#     normalized_y = 1 - ((landing_y + (screen_mm_height / 2)) / screen_mm_height)  # Flip Y-axis for top-left origin\n",
    "\n",
    "#     # Clamp to ensure the points remain within the screen boundaries\n",
    "#     normalized_x = np.clip(normalized_x, 0, 1)\n",
    "#     normalized_y = np.clip(normalized_y, 0, 1)\n",
    "\n",
    "#     # Convert normalized coordinates to pixel coordinates\n",
    "#     pixel_x = int(normalized_x * screen_width)\n",
    "#     pixel_y = int(normalized_y * screen_height)\n",
    "\n",
    "#     return pixel_x, pixel_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# import collections\n",
    "# import math\n",
    "\n",
    "# def calculate_convergence_distance(left_eye, left_gaze, right_eye, right_gaze):\n",
    "#     \"\"\"\n",
    "#     Calculate the convergence distance based on binocular eye-tracking data.\n",
    "\n",
    "\n",
    "#     Parameters:\n",
    "#         left_eye (numpy array): 3D position of the left eye [x, y, z].\n",
    "#         left_gaze (numpy array): 3D normalized gaze direction vector of the left eye [dx, dy, dz].\n",
    "#         right_eye (numpy array): 3D position of the right eye [x, y, z].\n",
    "#         right_gaze (numpy array): 3D normalized gaze direction vector of the right eye [dx, dy, dz].\n",
    "\n",
    "#     Returns:\n",
    "#         float: Convergence distance (distance from the midpoint of the eyes to the convergence point).\n",
    "#         numpy array: Convergence point in 3D space [x, y, z].\n",
    "#     \"\"\"\n",
    "#     left_eye = np.array(left_eye)\n",
    "#     left_gaze = np.array(left_gaze)\n",
    "#     right_eye = np.array(right_eye)\n",
    "#     right_gaze = np.array(right_gaze)\n",
    "    \n",
    "#     # Ensure the gaze vectors are normalized\n",
    "#     left_gaze = left_gaze / np.linalg.norm(left_gaze)\n",
    "#     right_gaze = right_gaze / np.linalg.norm(right_gaze)\n",
    "\n",
    "#     # Define variables for solving the closest point between lines\n",
    "#     p1 = left_eye\n",
    "#     d1 = left_gaze\n",
    "#     p2 = right_eye\n",
    "#     d2 = right_gaze\n",
    "\n",
    "#     # Compute cross-product and denominator\n",
    "#     d1_cross_d2 = np.cross(d1, d2)\n",
    "#     denom = np.linalg.norm(d1_cross_d2) ** 2\n",
    "\n",
    "#     if denom < 1e-6:\n",
    "#         # If the gaze lines are nearly parallel\n",
    "#         print(\"Gaze vectors are nearly parallel; convergence point may be inaccurate.\")\n",
    "#         return None, None\n",
    "\n",
    "#     # Calculate the closest points on the two lines\n",
    "#     t = np.dot(np.cross((p2 - p1), d2), d1_cross_d2) / denom\n",
    "#     s = np.dot(np.cross((p2 - p1), d1), d1_cross_d2) / denom\n",
    "\n",
    "#     # Points on the lines\n",
    "#     closest_point_left = p1 + t * d1\n",
    "#     closest_point_right = p2 + s * d2\n",
    "\n",
    "#     # Midpoint between the closest points (approximate convergence point)\n",
    "#     convergence_point = (closest_point_left + closest_point_right) / 2\n",
    "\n",
    "#     # Calculate convergence distance\n",
    "#     eye_midpoint = (p1 + p2) / 2\n",
    "#     convergence_distance = np.linalg.norm(convergence_point - eye_midpoint)\n",
    "\n",
    "#     return convergence_distance, convergence_point\n",
    "# def project_gaze_to_2d(gaze_origin, gaze_vector, screen_width, screen_height, screen_mm_width, screen_mm_height):\n",
    "#     \"\"\"\n",
    "#     Project a 3D gaze vector onto a 2D screen plane (z = 0).\n",
    "#     This function calculates the intersection of the gaze ray with the screen plane\n",
    "#     and converts it to screen pixel coordinates.\n",
    "\n",
    "#     Parameters:\n",
    "#         gaze_origin (array): 3D coordinates of the gaze ray origin [x, y, z].\n",
    "#         gaze_vector (array): 3D direction vector of the gaze ray [dx, dy, dz].\n",
    "#         screen_width (int): Width of the screen in pixels.\n",
    "#         screen_height (int): Height of the screen in pixels.\n",
    "#         screen_mm_width (float): Width of the screen in millimeters.\n",
    "#         screen_mm_height (float): Height of the screen in millimeters.\n",
    "\n",
    "#     Returns:\n",
    "#         (int, int): Pixel coordinates of the projected gaze point on the screen.\n",
    "#     \"\"\"\n",
    "#     # Ensure gaze vector is a numpy array\n",
    "#     gaze_vector = np.array(gaze_vector, dtype=float)\n",
    "\n",
    "#     # Handle the case of a zero-length gaze vector\n",
    "#     norm = np.linalg.norm(gaze_vector)\n",
    "#     if norm == 0:\n",
    "#         print(\"Warning: Gaze vector has zero length; using gaze origin projection.\")\n",
    "#         gaze_vector = np.array([0, 0, 1])  # Default fallback vector pointing directly at the screen\n",
    "#     else:\n",
    "#         # Normalize the gaze vector\n",
    "#         gaze_vector /= norm\n",
    "\n",
    "#     # Calculate intersection with the screen plane (z = 0)\n",
    "#     gaze_origin = np.array(gaze_origin, dtype=float)\n",
    "#     if abs(gaze_vector[2]) > 1e-6:  # Avoid division by zero or near-zero values\n",
    "#         t = -gaze_origin[2] / gaze_vector[2]  # Parameter t for intersection\n",
    "#         landing_x = gaze_origin[0] + t * gaze_vector[0]\n",
    "#         landing_y = gaze_origin[1] + t * gaze_vector[1]\n",
    "#     else:\n",
    "#         # Gaze is parallel to the screen plane; project directly from origin\n",
    "#         print(\"Warning: Gaze vector is parallel to the screen plane.\")\n",
    "#         landing_x, landing_y = gaze_origin[0], gaze_origin[1]\n",
    "\n",
    "#     # Convert 3D landing point (in mm) to normalized screen coordinates (0-1)\n",
    "#     normalized_x = (landing_x + (screen_mm_width / 2)) / screen_mm_width\n",
    "#     normalized_y = 1 - ((landing_y + (screen_mm_height / 2)) / screen_mm_height)  # Flip Y-axis\n",
    "\n",
    "#     # Clamp normalized coordinates to [0, 1] to stay within screen bounds\n",
    "#     normalized_x = np.clip(normalized_x, 0, 1)\n",
    "#     normalized_y = np.clip(normalized_y, 0, 1)\n",
    "\n",
    "#     # Convert normalized coordinates to pixel coordinates\n",
    "#     pixel_x = int(normalized_x * screen_width)\n",
    "#     pixel_y = int(normalized_y * screen_height)\n",
    "\n",
    "#     return pixel_x, pixel_y\n",
    "\n",
    "\n",
    "# def create_gaze_video(video_path, eye_data, output_video=\"output_with_gaze.mp4\"):\n",
    "#     \"\"\"\n",
    "#     Create a video overlaying gaze positions projected from 3D gaze vectors onto a 2D video.\n",
    "#     \"\"\"\n",
    "#     # Constants: screen and physical properties\n",
    "#     screen_width, screen_height = 2880, 1600  # HTC Vive Pro Eye resolution\n",
    "#     screen_mm_width, screen_mm_height = 89, 89  # Combined physical screen dimensions (mm)\n",
    "    \n",
    "#     # Load video\n",
    "#     cap = cv2.VideoCapture(video_path)\n",
    "#     fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "#     frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "#     frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "#     # Resize video to target screen resolution\n",
    "#     out = cv2.VideoWriter(output_video, cv2.VideoWriter_fourcc(*'mp4v'), fps, (screen_width, screen_height))\n",
    "\n",
    "#     # Normalize time and assign frame indices\n",
    "#     eye_data = eye_data.copy().interpolate(method='linear', limit_direction='both')\n",
    "#     eye_data['normalized_time'] = eye_data['UnityTime'] - eye_data['UnityTime'].min()\n",
    "#     eye_data['frame_idx'] = (eye_data['normalized_time'] * fps).astype(int)\n",
    "    \n",
    "#     # Gaze buffer for smoothing\n",
    "#     gaze_buffer = collections.deque(maxlen=30)\n",
    "\n",
    "#     frame_idx = 0\n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "\n",
    "#         # Resize the frame to match the screen resolution\n",
    "#         frame = cv2.resize(frame, (screen_width, screen_height))\n",
    "\n",
    "#         # Select gaze data for the current frame\n",
    "#         gaze_data = eye_data[eye_data['frame_idx'] == frame_idx]\n",
    "\n",
    "#         if not gaze_data.empty:\n",
    "#             # Left Eye Gaze Data\n",
    "#             gaze_origin_L = (\n",
    "#                 gaze_data['gazeoriginL_X'].mean(),\n",
    "#                 gaze_data['gazeoriginL_Y'].mean(),\n",
    "#                 gaze_data['gazeoriginL_Z'].mean(),\n",
    "#             )\n",
    "#             gaze_vector_L = (\n",
    "#                 gaze_data['gazeL_X'].mean(),\n",
    "#                 gaze_data['gazeL_Y'].mean(),\n",
    "#                 gaze_data['gazeL_Z'].mean(),\n",
    "#             )\n",
    "            \n",
    "            \n",
    "\n",
    "#             # Right Eye Gaze Data\n",
    "#             gaze_origin_R = (\n",
    "#                 gaze_data['gazeoriginR_X'].mean(),\n",
    "#                 gaze_data['gazeoriginR_Y'].mean(),\n",
    "#                 gaze_data['gazeoriginR_Z'].mean(),\n",
    "#             )\n",
    "#             gaze_vector_R = (\n",
    "#                 gaze_data['gazeR_X'].mean(),\n",
    "#                 gaze_data['gazeR_Y'].mean(),\n",
    "#                 gaze_data['gazeR_Z'].mean(),\n",
    "#             )\n",
    "            \n",
    "#             gaze_dist = gaze_data['Distance'].mean()\n",
    "\n",
    "#             # convergence_distance, _ = calculate_convergence_distance(gaze_origin_L, gaze_vector_L, gaze_origin_R, gaze_vector_R)\n",
    "#             convergence_distance = gaze_dist\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "#             # Project both eyes to 2D\n",
    "#             # proj_x_L, proj_y_L = project_gaze_to_2d(gaze_origin_L, gaze_vector_L, convergence_distance, screen_width, screen_height, screen_mm_width, screen_mm_height)\n",
    "#             # proj_x_R, proj_y_R = project_gaze_to_2d(gaze_origin_R, gaze_vector_R, convergence_distance, screen_width, screen_height, screen_mm_width, screen_mm_height)\n",
    "#             proj_x_L, proj_y_L = project_gaze_to_2d(gaze_origin_L, gaze_vector_L, screen_width, screen_height, screen_mm_width, screen_mm_height)\n",
    "#             proj_x_R, proj_y_R = project_gaze_to_2d(gaze_origin_R, gaze_vector_R, screen_width, screen_height, screen_mm_width, screen_mm_height)\n",
    "#             # Combined Gaze Point (Midpoint)\n",
    "#             proj_x_C = (proj_x_L + proj_x_R) // 2\n",
    "#             proj_y_C = (proj_y_L + proj_y_R) // 2\n",
    "\n",
    "#             # Draw the gaze points\n",
    "#             cv2.circle(frame, (proj_x_L, proj_y_L), 10, (0, 0, 255), -1)  # Left Eye (Red)\n",
    "#             cv2.circle(frame, (proj_x_R, proj_y_R), 10, (0, 255, 0), -1)  # Right Eye (Green)\n",
    "#             cv2.circle(frame, (proj_x_C, proj_y_C), 10, (255, 0, 0), -1)  # Combined (Blue)\n",
    "\n",
    "#             # Buffer for smoothing/fading effect\n",
    "#             gaze_buffer.append((proj_x_C, proj_y_C))\n",
    "\n",
    "#         # Overlay the gaze buffer for smooth effect\n",
    "#         overlay = frame.copy()\n",
    "#         for i, (gx, gy) in enumerate(gaze_buffer):\n",
    "#             alpha = (i + 1) / len(gaze_buffer) * 0.5\n",
    "#             color = (int(255 * alpha), 0, 0)\n",
    "#             cv2.circle(overlay, (gx, gy), 5, color, -1)\n",
    "#         frame = cv2.addWeighted(overlay, 0.5, frame, 0.5, 0)\n",
    "\n",
    "#         out.write(frame)\n",
    "#         frame_idx += 1\n",
    "\n",
    "#     cap.release()\n",
    "#     out.release()\n",
    "#     print(\"Gaze video processing complete! Output saved as:\", output_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# import collections\n",
    "# import math\n",
    "# def rescale_intrinsics(fx, fy, cx, cy, old_width, old_height, new_width, new_height):\n",
    "#     # Calculate scaling factors\n",
    "#     scale_x = new_width / old_width\n",
    "#     scale_y = new_height / old_height\n",
    "    \n",
    "#     # Rescale focal lengths\n",
    "#     fx_new = fx * scale_x\n",
    "#     fy_new = fy * scale_y\n",
    "    \n",
    "#     # Rescale principal point (cx, cy)\n",
    "#     cx_new = cx * scale_x\n",
    "#     cy_new = cy * scale_y\n",
    "    \n",
    "#     return fx_new, fy_new, cx_new, cy_new\n",
    "\n",
    "\n",
    "# def calculate_gaze(eye1_pos, gaze1_dir, eye2_pos, gaze2_dir, distance, fx, fy, cx, cy):\n",
    "#     # Step 1: Calculate endpoints in 3D\n",
    "#     endpoint1 = (\n",
    "#         eye1_pos[0] + gaze1_dir[0] * distance,\n",
    "#         eye1_pos[1] + gaze1_dir[1] * distance,\n",
    "#         eye1_pos[2] + gaze1_dir[2] * distance\n",
    "#     )\n",
    "#     endpoint2 = (\n",
    "#         eye2_pos[0] + gaze2_dir[0] * distance,\n",
    "#         eye2_pos[1] + gaze2_dir[1] * distance,\n",
    "#         eye2_pos[2] + gaze2_dir[2] * distance\n",
    "#     )\n",
    "    \n",
    "#     # Step 2: Calculate the final gaze point (average of both eye endpoints)\n",
    "#     final_gaze = (\n",
    "#         (endpoint1[0] + endpoint2[0]) / 2,\n",
    "#         (endpoint1[1] + endpoint2[1]) / 2,\n",
    "#         (endpoint1[2] + endpoint2[2]) / 2\n",
    "#     )\n",
    "    \n",
    "#     # Step 3: Project to 2D video space\n",
    "#     def project_to_2d(point, fx, fy, cx, cy):\n",
    "#         x, y, z = point\n",
    "#         u = fx * (x / z) + cx\n",
    "#         v = fy * (y / z) + cy\n",
    "#         return (u, v)\n",
    "    \n",
    "#     gaze1_2d = project_to_2d(endpoint1, fx, fy, cx, cy)\n",
    "#     gaze2_2d = project_to_2d(endpoint2, fx, fy, cx, cy)\n",
    "#     final_gaze_2d = project_to_2d(final_gaze, fx, fy, cx, cy)\n",
    "    \n",
    "#     return gaze1_2d, gaze2_2d, final_gaze_2d\n",
    "\n",
    "# def project_gaze_to_2d(gaze_origin, gaze_vector, screen_width, screen_height, screen_mm_width, screen_mm_height):\n",
    "#     \"\"\"\n",
    "#     Project a 3D gaze vector onto a 2D screen plane (z = 0).\n",
    "#     This function calculates the intersection of the gaze ray with the screen plane\n",
    "#     and converts it to screen pixel coordinates.\n",
    "\n",
    "#     Parameters:\n",
    "#         gaze_origin (array): 3D coordinates of the gaze ray origin [x, y, z].\n",
    "#         gaze_vector (array): 3D direction vector of the gaze ray [dx, dy, dz].\n",
    "#         screen_width (int): Width of the screen in pixels.\n",
    "#         screen_height (int): Height of the screen in pixels.\n",
    "#         screen_mm_width (float): Width of the screen in millimeters.\n",
    "#         screen_mm_height (float): Height of the screen in millimeters.\n",
    "\n",
    "#     Returns:\n",
    "#         (int, int): Pixel coordinates of the projected gaze point on the screen.\n",
    "#     \"\"\"\n",
    "#     # Ensure gaze vector is a numpy array\n",
    "#     gaze_vector = np.array(gaze_vector, dtype=float)\n",
    "\n",
    "#     # Handle the case of a zero-length gaze vector\n",
    "#     norm = np.linalg.norm(gaze_vector)\n",
    "#     if norm == 0:\n",
    "#         print(\"Warning: Gaze vector has zero length; using gaze origin projection.\")\n",
    "#         gaze_vector = np.array([0, 0, 1])  # Default fallback vector pointing directly at the screen\n",
    "#     else:\n",
    "#         # Normalize the gaze vector\n",
    "#         gaze_vector /= norm\n",
    "\n",
    "#     # Calculate intersection with the screen plane (z = 0)\n",
    "#     gaze_origin = np.array(gaze_origin, dtype=float)\n",
    "#     if abs(gaze_vector[2]) > 1e-6:  # Avoid division by zero or near-zero values\n",
    "#         t = -gaze_origin[2] / gaze_vector[2]  # Parameter t for intersection\n",
    "#         landing_x = gaze_origin[0] + t * gaze_vector[0]\n",
    "#         landing_y = gaze_origin[1] + t * gaze_vector[1]\n",
    "#     else:\n",
    "#         # Gaze is parallel to the screen plane; project directly from origin\n",
    "#         print(\"Warning: Gaze vector is parallel to the screen plane.\")\n",
    "#         landing_x, landing_y = gaze_origin[0], gaze_origin[1]\n",
    "\n",
    "#     # Convert 3D landing point (in mm) to normalized screen coordinates (0-1)\n",
    "#     normalized_x = (landing_x + (screen_mm_width / 2)) / screen_mm_width\n",
    "#     normalized_y = 1 - ((landing_y + (screen_mm_height / 2)) / screen_mm_height)  # Flip Y-axis\n",
    "\n",
    "#     # Clamp normalized coordinates to [0, 1] to stay within screen bounds\n",
    "#     normalized_x = np.clip(normalized_x, 0, 1)\n",
    "#     normalized_y = np.clip(normalized_y, 0, 1)\n",
    "\n",
    "#     # Convert normalized coordinates to pixel coordinates\n",
    "#     pixel_x = int(normalized_x * screen_width)\n",
    "#     pixel_y = int(normalized_y * screen_height)\n",
    "\n",
    "#     return pixel_x, pixel_y\n",
    "\n",
    "\n",
    "# def create_gaze_video(video_path, eye_data, output_video=\"output_with_gaze.mp4\"):\n",
    "#     \"\"\"\n",
    "#     Create a video overlaying gaze positions projected from 3D gaze vectors onto a 2D video.\n",
    "#     \"\"\"\n",
    "#     # Constants: screen and physical properties\n",
    "#     # screen_width, screen_height = 2880, 1600  # HTC Vive Pro Eye resolution\n",
    "#     # screen_mm_width, screen_mm_height = 89, 89  # Combined physical screen dimensions (mm)\n",
    "    \n",
    "#     # Example setup for binocular camera\n",
    "#     old_width = 2880\n",
    "#     old_height = 1600\n",
    "#     new_width = 3840\n",
    "#     new_height = 2160\n",
    "\n",
    "#     # Intrinsic parameters for the binocular camera\n",
    "#     fx = 1000  # Focal length in pixels (same for both eyes at original resolution)\n",
    "#     fy = 1000  # Focal length in pixels (same for both eyes at original resolution)\n",
    "#     cx = 1440  # Principal point in x (center of the binocular image)\n",
    "#     cy = 800   # Principal point in y (center of the binocular image)\n",
    "\n",
    "#     # Rescale intrinsics for the new resolution\n",
    "#     fx_new, fy_new, cx_new, cy_new = rescale_intrinsics(fx, fy, cx, cy, old_width, old_height, new_width, new_height)\n",
    "#     # Load video\n",
    "#     cap = cv2.VideoCapture(video_path)\n",
    "#     fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "#     frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "#     frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "#     # Resize video to target screen resolution\n",
    "#     out = cv2.VideoWriter(output_video, cv2.VideoWriter_fourcc(*'mp4v'), fps, (old_width, old_height))\n",
    "\n",
    "#     # Normalize time and assign frame indices\n",
    "#     eye_data = eye_data.copy().interpolate(method='linear', limit_direction='both')\n",
    "#     eye_data['normalized_time'] = eye_data['UnityTime'] - eye_data['UnityTime'].min()\n",
    "#     eye_data['frame_idx'] = (eye_data['normalized_time'] * fps).astype(int)\n",
    "    \n",
    "#     # Gaze buffer for smoothing\n",
    "#     gaze_buffer = collections.deque(maxlen=30)\n",
    "\n",
    "#     frame_idx = 0\n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "\n",
    "#         # Resize the frame to match the screen resolution\n",
    "#         frame = cv2.resize(frame, (old_width, old_height))\n",
    "\n",
    "#         # Select gaze data for the current frame\n",
    "#         gaze_data = eye_data[eye_data['frame_idx'] == frame_idx]\n",
    "\n",
    "#         if not gaze_data.empty:\n",
    "#             # Left Eye Gaze Data\n",
    "#             gaze_origin_L = (\n",
    "#                 gaze_data['gazeoriginL_X'].mean(),\n",
    "#                 gaze_data['gazeoriginL_Y'].mean(),\n",
    "#                 gaze_data['gazeoriginL_Z'].mean(),\n",
    "#             )\n",
    "#             gaze_vector_L = (\n",
    "#                 gaze_data['gazeL_X'].mean(),\n",
    "#                 gaze_data['gazeL_Y'].mean(),\n",
    "#                 gaze_data['gazeL_Z'].mean(),\n",
    "#             )\n",
    "            \n",
    "            \n",
    "\n",
    "#             # Right Eye Gaze Data\n",
    "#             gaze_origin_R = (\n",
    "#                 gaze_data['gazeoriginR_X'].mean(),\n",
    "#                 gaze_data['gazeoriginR_Y'].mean(),\n",
    "#                 gaze_data['gazeoriginR_Z'].mean(),\n",
    "#             )\n",
    "#             gaze_vector_R = (\n",
    "#                 gaze_data['gazeR_X'].mean(),\n",
    "#                 gaze_data['gazeR_Y'].mean(),\n",
    "#                 gaze_data['gazeR_Z'].mean(),\n",
    "#             )\n",
    "            \n",
    "#             gaze_dist = gaze_data['Distance'].mean()*1000\n",
    "\n",
    "#             # convergence_distance, _ = calculate_convergence_distance(gaze_origin_L, gaze_vector_L, gaze_origin_R, gaze_vector_R)\n",
    "#             convergence_distance = gaze_dist\n",
    "            \n",
    "#             gazeL_2d, gazeR_2d, final_gaze_2d = calculate_gaze(gaze_origin_L, gaze_vector_L, gaze_origin_R, gaze_vector_R, gaze_dist, fx_new, fy_new, cx_new, cy_new)\n",
    "            \n",
    "\n",
    "#             # # Project both eyes to 2D\n",
    "#             # # proj_x_L, proj_y_L = project_gaze_to_2d(gaze_origin_L, gaze_vector_L, convergence_distance, screen_width, screen_height, screen_mm_width, screen_mm_height)\n",
    "#             # # proj_x_R, proj_y_R = project_gaze_to_2d(gaze_origin_R, gaze_vector_R, convergence_distance, screen_width, screen_height, screen_mm_width, screen_mm_height)\n",
    "#             # proj_x_L, proj_y_L = project_gaze_to_2d(gaze_origin_L, gaze_vector_L, screen_width, screen_height, screen_mm_width, screen_mm_height)\n",
    "#             # proj_x_R, proj_y_R = project_gaze_to_2d(gaze_origin_R, gaze_vector_R, screen_width, screen_height, screen_mm_width, screen_mm_height)\n",
    "#             # # Combined Gaze Point (Midpoint)\n",
    "#             # proj_x_C = (proj_x_L + proj_x_R) // 2\n",
    "#             # proj_y_C = (proj_y_L + proj_y_R) // 2\n",
    "\n",
    "#             # Draw the gaze points\n",
    "#             cv2.circle(frame, (gazeL_2d[0], gazeL_2d[1]), 10, (0, 0, 255), -1)  # Left Eye (Red)\n",
    "#             cv2.circle(frame, (gazeR_2d[0], gazeR_2d[1]), 10, (0, 255, 0), -1)  # Right Eye (Green)\n",
    "#             cv2.circle(frame, (final_gaze_2d[0], final_gaze_2d[1]), 10, (255, 0, 0), -1)  # Combined (Blue)\n",
    "\n",
    "#             # Buffer for smoothing/fading effect\n",
    "#             gaze_buffer.append((final_gaze_2d[0], final_gaze_2d[1]))\n",
    "\n",
    "#         # Overlay the gaze buffer for smooth effect\n",
    "#         overlay = frame.copy()\n",
    "#         for i, (gx, gy) in enumerate(gaze_buffer):\n",
    "#             alpha = (i + 1) / len(gaze_buffer) * 0.5\n",
    "#             color = (int(255 * alpha), 0, 0)\n",
    "#             cv2.circle(overlay, (gx, gy), 5, color, -1)\n",
    "#         frame = cv2.addWeighted(overlay, 0.5, frame, 0.5, 0)\n",
    "\n",
    "#         out.write(frame)\n",
    "#         frame_idx += 1\n",
    "\n",
    "#     cap.release()\n",
    "#     out.release()\n",
    "#     print(\"Gaze video processing complete! Output saved as:\", output_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# import collections\n",
    "# import math\n",
    "# def rescale_intrinsics(fx, fy, cx, cy, old_width, old_height, new_width, new_height):\n",
    "#     # Calculate scaling factors\n",
    "#     scale_x = new_width / old_width\n",
    "#     scale_y = new_height / old_height\n",
    "    \n",
    "#     # Rescale focal lengths\n",
    "#     fx_new = fx * scale_x\n",
    "#     fy_new = fy * scale_y\n",
    "    \n",
    "#     # Rescale principal point (cx, cy)\n",
    "#     cx_new = cx * scale_x\n",
    "#     cy_new = cy * scale_y\n",
    "    \n",
    "#     return fx_new, fy_new, cx_new, cy_new\n",
    "# def calculate_gaze(eye1_pos, gaze1_dir, eye2_pos, gaze2_dir, distance, fx, fy, cx, cy):\n",
    "#     # Step 1: Calculate endpoints in 3D\n",
    "#     endpoint1 = (\n",
    "#         eye1_pos[0] + gaze1_dir[0] * distance,\n",
    "#         eye1_pos[1] + gaze1_dir[1] * distance,\n",
    "#         eye1_pos[2] + gaze1_dir[2] * distance\n",
    "#     )\n",
    "#     endpoint2 = (\n",
    "#         eye2_pos[0] + gaze2_dir[0] * distance,\n",
    "#         eye2_pos[1] + gaze2_dir[1] * distance,\n",
    "#         eye2_pos[2] + gaze2_dir[2] * distance\n",
    "#     )\n",
    "    \n",
    "#     # Step 2: Calculate the final gaze point (average of both eye endpoints)\n",
    "#     final_gaze = (\n",
    "#         (endpoint1[0] + endpoint2[0]) / 2,\n",
    "#         (endpoint1[1] + endpoint2[1]) / 2,\n",
    "#         (endpoint1[2] + endpoint2[2]) / 2\n",
    "#     )\n",
    "    \n",
    "#     # Step 3: Project to 2D video space\n",
    "#     def project_to_2d(point, fx, fy, cx, cy):\n",
    "#         x, y, z = point\n",
    "#         if z == 0:\n",
    "#             return (cx, cy)  # If z is zero, fallback to the principal point (center)\n",
    "#         u = fx * (x / z) + cx\n",
    "#         v = fy * (y / z) + cy\n",
    "#         return (u, v)\n",
    "    \n",
    "#     gaze1_2d = project_to_2d(endpoint1, fx, fy, cx, cy)\n",
    "#     gaze2_2d = project_to_2d(endpoint2, fx, fy, cx, cy)\n",
    "#     final_gaze_2d = project_to_2d(final_gaze, fx, fy, cx, cy)\n",
    "\n",
    "#     # Ensure gaze points are valid and convert to integers\n",
    "#     gaze1_2d = (int(round(gaze1_2d[0])), int(round(gaze1_2d[1]))) if all(isinstance(i, (int, float)) for i in gaze1_2d) else (0, 0)\n",
    "#     gaze2_2d = (int(round(gaze2_2d[0])), int(round(gaze2_2d[1]))) if all(isinstance(i, (int, float)) for i in gaze2_2d) else (0, 0)\n",
    "#     final_gaze_2d = (int(round(final_gaze_2d[0])), int(round(final_gaze_2d[1]))) if all(isinstance(i, (int, float)) for i in final_gaze_2d) else (0, 0)\n",
    "\n",
    "#     return gaze1_2d, gaze2_2d, final_gaze_2d\n",
    "\n",
    "\n",
    "# def create_gaze_video(video_path, eye_data, output_video=\"output_with_gaze.mp4\"):\n",
    "#     # Constants: screen and physical properties\n",
    "#     # old_width = 2880\n",
    "#     # old_height = 1600\n",
    "#     # new_width = 1920\n",
    "#     # new_height = 1080\n",
    "#     old_width = 2880\n",
    "#     old_height = 1600\n",
    "#     new_width = 3840\n",
    "#     new_height = 2160\n",
    "    \n",
    "#     # HTC Vive Pro Eye sensor dimensions (in mm)\n",
    "#     sensor_width = 78.7  # mm (estimated)\n",
    "#     sensor_height = 43.2  # mm (estimated)\n",
    "    \n",
    "#     # Resolution (per eye)\n",
    "#     resolution_width = 1440  # per eye\n",
    "#     resolution_height = 1600  # per eye\n",
    "\n",
    "#     # Focal length calculation based on the sensor size and resolution\n",
    "#     fx = (resolution_width / sensor_width) * 50  # mm focal length (approximate based on the sensor size)\n",
    "#     fy = (resolution_height / sensor_height) * 50  # mm focal length (approximate based on the sensor size)\n",
    "\n",
    "#     # Principal point (assuming it's at the center of the image)\n",
    "#     cx = old_width // 2  # Principal point in x (center of the HMD image)\n",
    "#     cy = old_height // 2  # Principal point in y (center of the HMD image)\n",
    "\n",
    "\n",
    "#     # Rescale intrinsics for the new resolution\n",
    "#     fx_new, fy_new, cx_new, cy_new = rescale_intrinsics(fx, fy, cx, cy, old_width, old_height, new_width, new_height)\n",
    "\n",
    "#     cap = cv2.VideoCapture(video_path)\n",
    "#     fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "#     frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "#     frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "#     eye_data = eye_data.copy().interpolate(method='linear', limit_direction='both')\n",
    "#     eye_data['normalized_time'] = eye_data['UnityTime'] - eye_data['UnityTime'].min()\n",
    "#     eye_data['frame_idx'] = (eye_data['normalized_time'] * fps).astype(int)\n",
    "\n",
    "#     out = cv2.VideoWriter(output_video, cv2.VideoWriter_fourcc(*'mp4v'), fps, (new_width, new_height))\n",
    "\n",
    "#     frame_idx = 0\n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "\n",
    "#         frame = cv2.resize(frame, (new_width, new_height))\n",
    "\n",
    "#         gaze_data = eye_data[eye_data['frame_idx'] == frame_idx]\n",
    "#         if not gaze_data.empty:\n",
    "#             # Left Eye Gaze Data\n",
    "#             gaze_origin_L = (gaze_data['gazeoriginL_X'].mean(), gaze_data['gazeoriginL_Y'].mean(), gaze_data['gazeoriginL_Z'].mean())\n",
    "#             gaze_vector_L = (gaze_data['gazeL_X'].mean(), gaze_data['gazeL_Y'].mean(), gaze_data['gazeL_Z'].mean())\n",
    "            \n",
    "#             # Right Eye Gaze Data\n",
    "#             gaze_origin_R = (gaze_data['gazeoriginR_X'].mean(), gaze_data['gazeoriginR_Y'].mean(), gaze_data['gazeoriginR_Z'].mean())\n",
    "#             gaze_vector_R = (gaze_data['gazeR_X'].mean(), gaze_data['gazeR_Y'].mean(), gaze_data['gazeR_Z'].mean())\n",
    "            \n",
    "#             gaze_dist = gaze_data['Distance'].mean() * 1000\n",
    "\n",
    "#             # Calculate 2D gaze positions\n",
    "#             gazeL_2d, gazeR_2d, final_gaze_2d = calculate_gaze(\n",
    "#                 gaze_origin_L, gaze_vector_L, gaze_origin_R, gaze_vector_R, gaze_dist, fx_new, fy_new, cx_new, cy_new\n",
    "#             )\n",
    "\n",
    "#             # Ensure all gaze points are valid before drawing\n",
    "#             if gazeL_2d != (0, 0):\n",
    "#                 cv2.circle(frame, gazeL_2d, 10, (0, 0, 255), -1)  # Left Eye (Red)\n",
    "#             if gazeR_2d != (0, 0):\n",
    "#                 cv2.circle(frame, gazeR_2d, 10, (0, 255, 0), -1)  # Right Eye (Green)\n",
    "#             if final_gaze_2d != (0, 0):\n",
    "#                 cv2.circle(frame, final_gaze_2d, 10, (255, 0, 0), -1)  # Combined (Blue)\n",
    "\n",
    "#         out.write(frame)\n",
    "#         frame_idx += 1\n",
    "\n",
    "#     cap.release()\n",
    "#     out.release()\n",
    "#     print(\"Gaze video processing complete! Output saved as:\", output_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# import collections\n",
    "# import math\n",
    "# def rescale_intrinsics(fx, fy, cx, cy, old_width, old_height, new_width, new_height):\n",
    "#     # Calculate scaling factors\n",
    "#     scale_x = new_width / old_width\n",
    "#     scale_y = new_height / old_height\n",
    "    \n",
    "#     # Rescale focal lengths\n",
    "#     fx_new = fx * scale_x\n",
    "#     fy_new = fy * scale_y\n",
    "    \n",
    "#     # Rescale principal point (cx, cy)\n",
    "#     cx_new = cx * scale_x\n",
    "#     cy_new = cy * scale_y \n",
    "    \n",
    "#     return fx_new, fy_new, cx_new, cy_new\n",
    "\n",
    "# def project_to_2d(point, fx, fy, cx, cy, flip_x=False, flip_y=False):\n",
    "#     x, y, z = point\n",
    "    \n",
    "#     # Flip the coordinates first\n",
    "#     if flip_x:\n",
    "#         x = -x  # Flip x-coordinate\n",
    "#     if flip_y:\n",
    "#         y = -y  # Flip y-coordinate\n",
    "    \n",
    "#     # Then project the flipped coordinates\n",
    "#     if z == 0:\n",
    "#         return (cx, cy)  # If z is zero, fallback to the principal point (center)\n",
    "    \n",
    "#     u = fx * (x / z) + cx\n",
    "#     v = fy * (y / z) + cy\n",
    "\n",
    "#     return (u, v)\n",
    "\n",
    "# def calculate_gaze(eye1_pos, gaze1_dir, eye2_pos, gaze2_dir, distance, fx, fy, cx, cy):\n",
    "#     # Step 1: Calculate endpoints in 3D\n",
    "#     endpoint1 = (\n",
    "#         eye1_pos[0] + gaze1_dir[0] * distance,\n",
    "#         eye1_pos[1] + gaze1_dir[1] * distance,\n",
    "#         eye1_pos[2] + gaze1_dir[2] * distance\n",
    "#     )\n",
    "#     endpoint2 = (\n",
    "#         eye2_pos[0] + gaze2_dir[0] * distance,\n",
    "#         eye2_pos[1] + gaze2_dir[1] * distance,\n",
    "#         eye2_pos[2] + gaze2_dir[2] * distance\n",
    "#     )\n",
    "    \n",
    "#     # Step 2: Calculate the final gaze point (average of both eye endpoints)\n",
    "#     final_gaze = (\n",
    "#         (endpoint1[0] + endpoint2[0]) / 2,\n",
    "#         (endpoint1[1] + endpoint2[1]) / 2,\n",
    "#         (endpoint1[2] + endpoint2[2]) / 2\n",
    "#     )\n",
    "    \n",
    "#     # Step 3: Project to 2D video space with flipped axes to correct orientation\n",
    "#     gaze1_2d = project_to_2d(endpoint1, fx, fy, cx, cy, flip_x=True, flip_y=True)\n",
    "#     gaze2_2d = project_to_2d(endpoint2, fx, fy, cx, cy, flip_x=True, flip_y=True)\n",
    "#     final_gaze_2d = project_to_2d(final_gaze, fx, fy, cx, cy, flip_x=True, flip_y=True)\n",
    "\n",
    "#     # Ensure gaze points are valid and convert to integers\n",
    "#     gaze1_2d = (int(round(gaze1_2d[0])), int(round(gaze1_2d[1]))) if all(isinstance(i, (int, float)) for i in gaze1_2d) else (0, 0)\n",
    "#     gaze2_2d = (int(round(gaze2_2d[0])), int(round(gaze2_2d[1]))) if all(isinstance(i, (int, float)) for i in gaze2_2d) else (0, 0)\n",
    "#     final_gaze_2d = (int(round(final_gaze_2d[0])), int(round(final_gaze_2d[1]))) if all(isinstance(i, (int, float)) for i in final_gaze_2d) else (0, 0)\n",
    "\n",
    "#     return gaze1_2d, gaze2_2d, final_gaze_2d\n",
    "\n",
    "# def create_gaze_video(video_path, eye_data, output_video=\"output_with_gaze.mp4\"):\n",
    "#     # Constants: screen and physical properties\n",
    "#     # old_width = 2880\n",
    "#     # old_height = 1600\n",
    "#     # new_width = 1920\n",
    "#     # new_height = 1080\n",
    "#     old_width = 1440\n",
    "#     old_height = 1600\n",
    "#     new_width = 2880\n",
    "#     new_height = 1600\n",
    "    \n",
    "#     # HTC Vive Pro Eye sensor dimensions (in mm)\n",
    "#     sensor_width = 78.7  # mm (estimated)\n",
    "#     sensor_height = 43.2  # mm (estimated)\n",
    "    \n",
    "#     # Resolution (per eye)\n",
    "#     resolution_width = 1440  # per eye\n",
    "#     resolution_height = 1600  # per eye\n",
    "\n",
    "#     # Focal length calculation based on the sensor size and resolution\n",
    "#     fx = (resolution_width / sensor_width) * 50  # mm focal length (approximate based on the sensor size)\n",
    "#     fy = (resolution_height / sensor_height) * 50  # mm focal length (approximate based on the sensor size)\n",
    "\n",
    "#     # Principal point (assuming it's at the center of the image)\n",
    "#     cx = old_width // 2  # Principal point in x (center of the HMD image)\n",
    "#     cy = old_height // 2  # Principal point in y (center of the HMD image)\n",
    "\n",
    "\n",
    "#     # Rescale intrinsics for the new resolution\n",
    "#     fx_new, fy_new, cx_new, cy_new = rescale_intrinsics(fx, fy, cx, cy, old_width, old_height, new_width, new_height)\n",
    "\n",
    "#     cap = cv2.VideoCapture(video_path)\n",
    "#     fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "#     frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "#     frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "#     eye_data = eye_data.copy().interpolate(method='linear', limit_direction='both')\n",
    "#     eye_data['normalized_time'] = eye_data['UnityTime'] - eye_data['UnityTime'].min()\n",
    "#     eye_data['frame_idx'] = (eye_data['normalized_time'] * fps).astype(int)\n",
    "\n",
    "#     out = cv2.VideoWriter(output_video, cv2.VideoWriter_fourcc(*'mp4v'), fps, (new_width, new_height))\n",
    "\n",
    "#     frame_idx = 0\n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "\n",
    "#         frame = cv2.resize(frame, (new_width, new_height))\n",
    "\n",
    "#         gaze_data = eye_data[eye_data['frame_idx'] == frame_idx]\n",
    "#         if not gaze_data.empty:\n",
    "#             # Left Eye Gaze Data\n",
    "#             gaze_origin_L = (gaze_data['gazeoriginL_X'].mean(), gaze_data['gazeoriginL_Y'].mean(), gaze_data['gazeoriginL_Z'].mean())\n",
    "#             gaze_vector_L = (gaze_data['gazeL_X'].mean(), gaze_data['gazeL_Y'].mean(), gaze_data['gazeL_Z'].mean())\n",
    "            \n",
    "#             # Right Eye Gaze Data\n",
    "#             gaze_origin_R = (gaze_data['gazeoriginR_X'].mean(), gaze_data['gazeoriginR_Y'].mean(), gaze_data['gazeoriginR_Z'].mean())\n",
    "#             gaze_vector_R = (gaze_data['gazeR_X'].mean(), gaze_data['gazeR_Y'].mean(), gaze_data['gazeR_Z'].mean())\n",
    "            \n",
    "#             gaze_dist = gaze_data['Distance'].mean() * 1000\n",
    "\n",
    "#             # Calculate 2D gaze positions\n",
    "#             gazeL_2d, gazeR_2d, final_gaze_2d = calculate_gaze(\n",
    "#                 gaze_origin_L, gaze_vector_L, gaze_origin_R, gaze_vector_R, gaze_dist, fx_new, fy_new, cx_new, cy_new\n",
    "#             )\n",
    "\n",
    "#             # Ensure all gaze points are valid before drawing\n",
    "#             if gazeL_2d != (0, 0):\n",
    "#                 cv2.circle(frame, gazeL_2d, 10, (0, 0, 255), -1)  # Left Eye (Red)\n",
    "#             if gazeR_2d != (0, 0):\n",
    "#                 cv2.circle(frame, gazeR_2d, 10, (0, 255, 0), -1)  # Right Eye (Green)\n",
    "#             if final_gaze_2d != (0, 0):\n",
    "#                 cv2.circle(frame, final_gaze_2d, 10, (255, 0, 0), -1)  # Combined (Blue)\n",
    "\n",
    "#         out.write(frame)\n",
    "#         frame_idx += 1\n",
    "\n",
    "#     cap.release()\n",
    "#     out.release()\n",
    "#     print(\"Gaze video processing complete! Output saved as:\", output_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import collections\n",
    "# import math\n",
    "\n",
    "# def rescale_intrinsics(fx, fy, cx, cy, old_width, old_height, new_width, new_height):\n",
    "#     scale_x = new_width / old_width\n",
    "#     scale_y = new_height / old_height\n",
    "#     fx_new = fx * scale_x\n",
    "#     fy_new = fy * scale_y\n",
    "#     cx_new = cx * scale_x\n",
    "#     cy_new = cy * scale_y\n",
    "#     return fx_new, fy_new, cx_new, cy_new\n",
    "\n",
    "# def project_to_2d(point, fx, fy, cx, cy, flip_x=False, flip_y=False):\n",
    "#     x, y, z = point\n",
    "#     if flip_x:\n",
    "#         x = -x\n",
    "#     if flip_y:\n",
    "#         y = -y\n",
    "#     if z == 0:\n",
    "#         return (cx, cy)\n",
    "#     u = fx * (x / z) + cx\n",
    "#     v = fy * (y / z) + cy\n",
    "#     return (u, v)\n",
    "\n",
    "# def calculate_gaze(eye1_pos, gaze1_dir, eye2_pos, gaze2_dir, distance, fx, fy, cx, cy):\n",
    "#     endpoint1 = (\n",
    "#         eye1_pos[0] + gaze1_dir[0] * distance,\n",
    "#         eye1_pos[1] + gaze1_dir[1] * distance,\n",
    "#         eye1_pos[2] + gaze1_dir[2] * distance\n",
    "#     )\n",
    "#     endpoint2 = (\n",
    "#         eye2_pos[0] + gaze2_dir[0] * distance,\n",
    "#         eye2_pos[1] + gaze2_dir[1] * distance,\n",
    "#         eye2_pos[2] + gaze2_dir[2] * distance\n",
    "#     )\n",
    "#     final_gaze = (\n",
    "#         (endpoint1[0] + endpoint2[0]) / 2,\n",
    "#         (endpoint1[1] + endpoint2[1]) / 2,\n",
    "#         (endpoint1[2] + endpoint2[2]) / 2\n",
    "#     )\n",
    "#     gaze1_2d = project_to_2d(endpoint1, fx, fy, cx, cy, flip_x=True, flip_y=True)\n",
    "#     gaze2_2d = project_to_2d(endpoint2, fx, fy, cx, cy, flip_x=True, flip_y=True)\n",
    "#     final_gaze_2d = project_to_2d(final_gaze, fx, fy, cx, cy, flip_x=True, flip_y=True)\n",
    "#     gaze1_2d = (int(round(gaze1_2d[0])), int(round(gaze1_2d[1]))) if all(isinstance(i, (int, float)) for i in gaze1_2d) else (0, 0)\n",
    "#     gaze2_2d = (int(round(gaze2_2d[0])), int(round(gaze2_2d[1]))) if all(isinstance(i, (int, float)) for i in gaze2_2d) else (0, 0)\n",
    "#     final_gaze_2d = (int(round(final_gaze_2d[0])), int(round(final_gaze_2d[1]))) if all(isinstance(i, (int, float)) for i in final_gaze_2d) else (0, 0)\n",
    "#     return gaze1_2d, gaze2_2d, final_gaze_2d\n",
    "\n",
    "# def align_gaze_to_video(eye_data, video_fps, gaze_fps):\n",
    "#     eye_data = eye_data.copy()\n",
    "#     eye_data['timestamp'] = eye_data['UnityTime'] - eye_data['UnityTime'].min()\n",
    "#     video_frame_duration = 1 / video_fps\n",
    "#     gaze_frame_duration = 1 / gaze_fps\n",
    "#     video_timestamps = [n * video_frame_duration for n in range(int(eye_data['timestamp'].max() * video_fps))]\n",
    "#     aligned_gaze_data = []\n",
    "#     for video_time in video_timestamps:\n",
    "#         closest_gaze = eye_data.iloc[(eye_data['timestamp'] - video_time).abs().argsort().iloc[0]]\n",
    "#         aligned_gaze_data.append(closest_gaze)\n",
    "#     return pd.DataFrame(aligned_gaze_data)\n",
    "\n",
    "# def create_gaze_video(video_path, eye_data, output_video=\"output_with_gaze.mp4\"):\n",
    "#     old_width = 1440\n",
    "#     old_height = 1600\n",
    "#     new_width = 2880\n",
    "#     new_height = 1600\n",
    "#     sensor_width = 78.7\n",
    "#     sensor_height = 43.2\n",
    "#     resolution_width = 1440\n",
    "#     resolution_height = 1600\n",
    "#     fx = (resolution_width / sensor_width) * 50\n",
    "#     fy = (resolution_height / sensor_height) * 50\n",
    "#     cx = old_width // 2\n",
    "#     cy = old_height // 2\n",
    "#     fx_new, fy_new, cx_new, cy_new = rescale_intrinsics(fx, fy, cx, cy, old_width, old_height, new_width, new_height)\n",
    "#     cap = cv2.VideoCapture(video_path)\n",
    "#     fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "#     eye_data = align_gaze_to_video(eye_data, fps, gaze_fps=120)\n",
    "#     out = cv2.VideoWriter(output_video, cv2.VideoWriter_fourcc(*'mp4v'), fps, (new_width, new_height))\n",
    "#     frame_idx = 0\n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "#         frame = cv2.resize(frame, (new_width, new_height))\n",
    "#         gaze_data = eye_data.iloc[frame_idx]\n",
    "#         gaze_origin_L = (gaze_data['gazeoriginL_X'], gaze_data['gazeoriginL_Y'], gaze_data['gazeoriginL_Z'])\n",
    "#         gaze_vector_L = (gaze_data['gazeL_X'], gaze_data['gazeL_Y'], gaze_data['gazeL_Z'])\n",
    "#         gaze_origin_R = (gaze_data['gazeoriginR_X'], gaze_data['gazeoriginR_Y'], gaze_data['gazeoriginR_Z'])\n",
    "#         gaze_vector_R = (gaze_data['gazeR_X'], gaze_data['gazeR_Y'], gaze_data['gazeR_Z'])\n",
    "#         gaze_dist = gaze_data['Distance'] * 1000\n",
    "#         gazeL_2d, gazeR_2d, final_gaze_2d = calculate_gaze(gaze_origin_L, gaze_vector_L, gaze_origin_R, gaze_vector_R, gaze_dist, fx_new, fy_new, cx_new, cy_new)\n",
    "#         if gazeL_2d != (0, 0):\n",
    "#             cv2.circle(frame, gazeL_2d, 10, (0, 0, 255), -1)\n",
    "#         if gazeR_2d != (0, 0):\n",
    "#             cv2.circle(frame, gazeR_2d, 10, (0, 255, 0), -1)\n",
    "#         if final_gaze_2d != (0, 0):\n",
    "#             cv2.circle(frame, final_gaze_2d, 10, (255, 0, 0), -1)\n",
    "#         out.write(frame)\n",
    "#         frame_idx += 1\n",
    "#     cap.release()\n",
    "#     out.release()\n",
    "#     print(\"Gaze video processing complete! Output saved as:\", output_video)\n",
    "    \n",
    "# def sanity_check_video_gaze_end(video_path, eye_data, gaze_fps):\n",
    "#     cap = cv2.VideoCapture(video_path)\n",
    "#     video_frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "#     video_fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "#     video_duration = video_frame_count / video_fps\n",
    "#     gaze_duration = eye_data['UnityTime'].max() - eye_data['UnityTime'].min()\n",
    "    \n",
    "#     print(f\"Video duration: {video_duration:.2f} seconds\")\n",
    "#     print(f\"Gaze data duration: {gaze_duration:.2f} seconds\")\n",
    "    \n",
    "#     if abs(video_duration - gaze_duration) < 0.1:  # Allowing minor differences due to rounding\n",
    "#         print(\"Sanity check passed: Video and gaze data durations are closely aligned.\")\n",
    "#     else:\n",
    "#         print(\"Warning: Video and gaze data durations differ!\")\n",
    "\n",
    "#     cap.release()\n",
    "\n",
    "# # Usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stream 1: Calculated effective sampling rate 73.0786 Hz is different from specified rate 50.0000 Hz.\n",
      "Stream 2: Calculated effective sampling rate 127.2490 Hz is different from specified rate 60.0000 Hz.\n",
      "Stream 3: Calculated effective sampling rate 127.2579 Hz is different from specified rate 250.0000 Hz.\n"
     ]
    }
   ],
   "source": [
    "# import cv2\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import neurokit2 as nk\n",
    "# import Dataloader as dl\n",
    "# # --- PARAMETERS ---\n",
    "# # data_path = \"pilot2/bnbn_eyetracker.pkl\"\n",
    "# # data_path = \"pilot2/testeyetracking_dist.xdf\"\n",
    "# data_path = \"pilot2/testz/block_0115.xdf\"\n",
    "\n",
    "# scenes = [\"Practice\", \"ElevatorTest\", \"Elevator1\",\"Outside\", \"Hallway\", \"Elevator2\", \"Hall\"]\n",
    "# data = nk.read_xdf(data_path)\n",
    "# data = data[0][['Scene', 'UnityTime', 'HitStatus', 'AgentNumber', 'Distance',\n",
    "#        'validL', 'validR', 'gazeoriginL_X', 'gazeoriginL_Y', 'gazeoriginL_Z',\n",
    "#        'gazeoriginR_X', 'gazeoriginR_Y', 'gazeoriginR_Z', 'gazeL_X', 'gazeL_Y',\n",
    "#        'gazeL_Z', 'gazeR_X', 'gazeR_Y', 'gazeR_Z', 'pupilL', 'pupilR',\n",
    "#        'eye_opennessL', 'eye_opennessR', 'pupilLSensorPosL_X',\n",
    "#        'pupilLSensorPosL_Y', 'pupilLSensorPosL_Z', 'pupilLSensorPosR_X',\n",
    "#        'pupilLSensorPosR_Y', 'pupilLSensorPosR_Z', 'convergence_distance_mm',\n",
    "#        'convergence_distance_validity']]\n",
    "# # data.rename(columns={'Scene_x':'Scene', 'UnityTime_x':'UnityTime', 'Distance_x':'Distance'}, inplace=True)\n",
    "# mapping = {\n",
    "#         0: \"Start\",\n",
    "#         1: \"Practice\",\n",
    "#         2: \"ElevatorTest\",\n",
    "#         3: \"Elevator1\",\n",
    "#         4: \"Outside\",\n",
    "#         5: \"Hallway\",\n",
    "#         6: \"Elevator2\",\n",
    "#         7: \"Hall\",\n",
    "#         8: \"End\"\n",
    "#         }\n",
    "\n",
    "#         # Replace values in the column\n",
    "# data['Scene'] = data['Scene'].map(mapping)\n",
    "# data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# def align_gaze_to_video(eye_data, video_fps):\n",
    "#     \"\"\"\n",
    "#     Align gaze data timestamps to video frames.\n",
    "#     \"\"\"\n",
    "#     eye_data = eye_data.copy()\n",
    "#     eye_data['timestamp'] = eye_data['UnityTime'] - eye_data['UnityTime'].min()\n",
    "#     video_frame_duration = 1 / video_fps\n",
    "#     video_timestamps = np.arange(0, eye_data['timestamp'].max(), video_frame_duration)\n",
    "    \n",
    "#     aligned_gaze_data = []\n",
    "#     for video_time in video_timestamps:\n",
    "#         closest_gaze = eye_data.iloc[(eye_data['timestamp'] - video_time).abs().argsort().iloc[0]]\n",
    "#         aligned_gaze_data.append(closest_gaze)\n",
    "    \n",
    "#     return pd.DataFrame(aligned_gaze_data)\n",
    "\n",
    "# def create_gaze_video(video_path, eye_data, output_video=\"output_with_gaze.mp4\"):\n",
    "#     \"\"\"\n",
    "#     Overlay gaze points on video using screen positions.\n",
    "#     \"\"\"\n",
    "#     cap = cv2.VideoCapture(video_path)\n",
    "#     video_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "#     video_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "#     video_fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "#     print(f\"Video Resolution: {video_width}x{video_height}, FPS: {video_fps}\")\n",
    "\n",
    "#     # Align gaze data timestamps with video frames\n",
    "#     eye_data = align_gaze_to_video(eye_data, video_fps)\n",
    "#     out = cv2.VideoWriter(output_video, cv2.VideoWriter_fourcc(*'mp4v'), video_fps, (video_width, video_height))\n",
    "#     # print(eye_data)\n",
    "#     frame_idx = 0\n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "\n",
    "#         # Get aligned gaze data for the current frame\n",
    "#         if frame_idx < len(eye_data):\n",
    "#             gaze_data = eye_data.iloc[frame_idx]\n",
    "\n",
    "#             # Extract screen positions\n",
    "#             screen_center_x = int(round(gaze_data['ScreenPoint_Center_X']))\n",
    "#             screen_center_y = int(round(gaze_data['ScreenPoint_Center_Y']))\n",
    "#             screen_right_x = int(round(gaze_data['ScreenPoint_Right_X']))\n",
    "#             screen_right_y = int(round(gaze_data['ScreenPoint_Right_Y']))\n",
    "#             screen_left_x = int(round(gaze_data['ScreenPoint_Left_X']))\n",
    "#             screen_left_y = int(round(gaze_data['ScreenPoint_Left_Y']))\n",
    "            \n",
    "            \n",
    "\n",
    "#             # Draw gaze points if valid\n",
    "#             if 0 <= screen_center_x < video_width and 0 <= screen_center_y < video_height:\n",
    "#                 cv2.circle(frame, (screen_center_x, screen_center_y), 20, (0, 0, 255), -1)  # Center - Red\n",
    "#                 # print(screen_center_x, screen_center_y)\n",
    "#             if 0 <= screen_right_x < video_width and 0 <= screen_right_y < video_height:\n",
    "#                 cv2.circle(frame, (screen_right_x, screen_right_y), 20, (255, 0, 0), -1)  # Right - Blue\n",
    "#             if 0 <= screen_left_x < video_width and 0 <= screen_left_y < video_height:\n",
    "#                 cv2.circle(frame, (screen_left_x, screen_left_y), 20, (0, 255, 0), -1)  # Left - Green\n",
    "\n",
    "#             out.write(frame)\n",
    "#             frame_idx += 1\n",
    "\n",
    "#     cap.release()\n",
    "#     out.release()\n",
    "#     print(f\"Gaze video processing complete! Output saved as: {output_video}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screen resolution: 1920x1080\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "import csv\n",
    "import numpy as np\n",
    "# Load CSV data\n",
    "csv_path = 'pilot2/0123/CustomEvents.csv'\n",
    "video_path = 'pilot2/0123/04_Outside.mp4'\n",
    "output_video_path = \"pilot2/processed/test_{item}_newgaze31.mp4\"\n",
    "item = \"sample\"  # Replace with your desired identifier\n",
    "# Read CSV file with flexible column handling\n",
    "def read_csv_flexible(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        # Auto-detect the delimiter\n",
    "        sample = f.read(1024)\n",
    "        dialect = csv.Sniffer().sniff(sample)\n",
    "        f.seek(0)\n",
    "        reader = csv.reader(f, delimiter=dialect.delimiter)\n",
    "        rows = list(reader)\n",
    "\n",
    "    max_columns = max(len(row) for row in rows)\n",
    "    column_names = [f'Column{i}' for i in range(max_columns)]\n",
    "    df = pd.DataFrame(rows, columns=column_names[:max_columns])\n",
    "    return df\n",
    "\n",
    "# Load and preprocess the CSV file\n",
    "data = read_csv_flexible(csv_path)\n",
    "data = data.iloc[1:]\n",
    "if len(data.columns) >= 4:\n",
    "    data.rename(columns={\n",
    "        'Column0': 'SubjectID',\n",
    "        'Column1': 'Time',\n",
    "        'Column2': 'Name',\n",
    "        'Column3': 'ID'\n",
    "    }, inplace=True)\n",
    "# Select rows with Name == 'GazeScreenPoint'\n",
    "gaze_data = data[data['Name'] == ' GazeScreenPoint'].copy()\n",
    "\n",
    "# Reset time to start from zero\n",
    "gaze_data['Time'] = pd.to_numeric(gaze_data['Time'], errors='coerce')\n",
    "start_time = gaze_data['Time'].iloc[0]\n",
    "gaze_data['Time'] = gaze_data['Time'] - start_time\n",
    "\n",
    "\n",
    "# Get screen resolution from the video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "screen_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "screen_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "print(f\"Screen resolution: {screen_width}x{screen_height}\")\n",
    "# Preprocess data into simplified form\n",
    "def clean_value(value):\n",
    "    try:\n",
    "        val = float(value.replace('(', '').replace(')', '').replace('\"', '').strip())\n",
    "        # Check for infinity and replace it with NaN\n",
    "        if np.isinf(val):\n",
    "            return np.nan\n",
    "        return val\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "preprocessed_data = []\n",
    "for index, row in gaze_data.iterrows():\n",
    "    try:\n",
    "        right_x, right_y = clean_value(row['Column5']), clean_value(row['Column6'])\n",
    "        left_x, left_y = clean_value(row['Column7']), clean_value(row['Column8'])\n",
    "        center_x, center_y = clean_value(row['Column9']), clean_value(row['Column10'])\n",
    "\n",
    "        time = row['Time']\n",
    "        preprocessed_data.append({'Time': time, 'X': right_x, 'Y': right_y, 'Tag': 'Right'})\n",
    "        preprocessed_data.append({'Time': time, 'X': left_x, 'Y': left_y, 'Tag': 'Left'})\n",
    "        preprocessed_data.append({'Time': time, 'X': center_x, 'Y': center_y, 'Tag': 'Center'})\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row {index}: {e}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "preprocessed_df = pd.DataFrame(preprocessed_data)\n",
    "preprocessed_df.dropna(subset=['X', 'Y'], inplace=True)\n",
    "preprocessed_df['X'] = preprocessed_df['X']+540\n",
    "preprocessed_df['Y'] = preprocessed_df['Y']+960\n",
    "# Function to draw gaze points on a video frame\n",
    "def draw_gaze_points(frame, gaze_points):\n",
    "    for point in gaze_points:\n",
    "        color = {'Right': (0, 255, 0), 'Left': (255, 0, 0), 'Center': (0, 0, 255)}[point['Tag']]\n",
    "        try:\n",
    "            # Ensure x and y are integers within valid screen bounds\n",
    "            x = max(0, min(int(point['X']), screen_width - 1))\n",
    "            y = max(0, min(int(point['Y']), screen_height - 1))\n",
    "            cv2.circle(frame, (x, y), 5, color, -1)\n",
    "            # Only display coordinates for the \"Center\" point\n",
    "            if point['Tag'] == 'Center':\n",
    "                cv2.putText(frame, f\"{x},{y}\", (x + 15, y - 15), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1.0, color, 2)  # Larger font size and thickness\n",
    "        except (ValueError, TypeError):\n",
    "            # Skip invalid points\n",
    "            continue\n",
    "# Set up video writer\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_video_path.format(item=item), fourcc, fps, (screen_width, screen_height))\n",
    "\n",
    "# Initialize time tracking\n",
    "current_time = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Get gaze points for the current time frame\n",
    "    gaze_points = preprocessed_df[(preprocessed_df['Time'] >= current_time) & \n",
    "                                  (preprocessed_df['Time'] < current_time + 1 / fps)]\n",
    "\n",
    "    # Draw gaze points on the frame\n",
    "    draw_gaze_points(frame, gaze_points.to_dict('records'))\n",
    "\n",
    "    # Write the frame to the output video\n",
    "    out.write(frame)\n",
    "\n",
    "    # Update the current time\n",
    "    current_time += 1 / fps\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>2126.91</td>\n",
       "      <td>-196.51</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>2111.91</td>\n",
       "      <td>-173.96</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>2119.86</td>\n",
       "      <td>-185.85</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>2135.41</td>\n",
       "      <td>-193.58</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>2116.34</td>\n",
       "      <td>-177.72</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>24.57338</td>\n",
       "      <td>1420.07</td>\n",
       "      <td>-347.12</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>24.57338</td>\n",
       "      <td>1223.14</td>\n",
       "      <td>-386.36</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>24.60663</td>\n",
       "      <td>1234.10</td>\n",
       "      <td>-388.96</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>24.60663</td>\n",
       "      <td>1406.74</td>\n",
       "      <td>-371.16</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>24.60663</td>\n",
       "      <td>1234.11</td>\n",
       "      <td>-388.96</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1980 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Time        X       Y     Tag\n",
       "0      0.00000  2126.91 -196.51   Right\n",
       "1      0.00000  2111.91 -173.96    Left\n",
       "2      0.00000  2119.86 -185.85  Center\n",
       "3      0.00000  2135.41 -193.58   Right\n",
       "4      0.00000  2116.34 -177.72    Left\n",
       "...        ...      ...     ...     ...\n",
       "1975  24.57338  1420.07 -347.12    Left\n",
       "1976  24.57338  1223.14 -386.36  Center\n",
       "1977  24.60663  1234.10 -388.96   Right\n",
       "1978  24.60663  1406.74 -371.16    Left\n",
       "1979  24.60663  1234.11 -388.96  Center\n",
       "\n",
       "[1980 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screen resolution: 2468x2740\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.patches import Circle\n",
    "# import csv\n",
    "# import numpy as np\n",
    "# # Load CSV data\n",
    "# csv_path = 'pilot2/0121/CustomEvents.csv'\n",
    "# video_path = 'pilot2/0121/04_Outside.mp4'\n",
    "# output_video_path = \"pilot2/processed/test_{item}_newgaze30.mp4\"\n",
    "# item = \"sample\"  # Replace with your desired identifier\n",
    "# # Read CSV file with flexible column handling\n",
    "# def read_csv_flexible(file_path):\n",
    "#     with open(file_path, 'r') as f:\n",
    "#         # Auto-detect the delimiter\n",
    "#         sample = f.read(1024)\n",
    "#         dialect = csv.Sniffer().sniff(sample)\n",
    "#         f.seek(0)\n",
    "#         reader = csv.reader(f, delimiter=dialect.delimiter)\n",
    "#         rows = list(reader)\n",
    "\n",
    "#     max_columns = max(len(row) for row in rows)\n",
    "#     column_names = [f'Column{i}' for i in range(max_columns)]\n",
    "#     df = pd.DataFrame(rows, columns=column_names[:max_columns])\n",
    "#     return df\n",
    "\n",
    "# # Load and preprocess the CSV file\n",
    "# data = read_csv_flexible(csv_path)\n",
    "# data = data.iloc[1:]\n",
    "# if len(data.columns) >= 4:\n",
    "#     data.rename(columns={\n",
    "#         'Column0': 'SubjectID',\n",
    "#         'Column1': 'Time',\n",
    "#         'Column2': 'Name',\n",
    "#         'Column3': 'ID'\n",
    "#     }, inplace=True)\n",
    "# # Select rows with Name == 'GazeScreenPoint'\n",
    "# gaze_data = data[data['Name'] == ' GazeUIpoint'].copy()\n",
    "\n",
    "# # Reset time to start from zero\n",
    "# gaze_data['Time'] = pd.to_numeric(gaze_data['Time'], errors='coerce')\n",
    "# start_time = gaze_data['Time'].iloc[0]\n",
    "# gaze_data['Time'] = gaze_data['Time'] - start_time\n",
    "\n",
    "\n",
    "# # Get screen resolution from the video\n",
    "# cap = cv2.VideoCapture(video_path)\n",
    "# screen_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "# screen_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "# print(f\"Screen resolution: {screen_width}x{screen_height}\")\n",
    "# # Preprocess data into simplified form\n",
    "# def extract_vector3(value):\n",
    "#     \"\"\"Extract the X and Y components from a Vector3-like string.\"\"\"\n",
    "#     try:\n",
    "#         # Remove surrounding characters and split the components\n",
    "#         vector_values = value.apply(lambda val: val.replace('(', '').replace(')', '').replace('\"', ''))\n",
    "#         x = float(vector_values[0])  # First value is X\n",
    "#         return x\n",
    "#     except (ValueError, IndexError):\n",
    "#         return np.nan, np.nan  # Return NaN if parsing fails\n",
    "# preprocessed_data = []\n",
    "# for index, row in gaze_data.iterrows():\n",
    "#     try:\n",
    "#         # Extract X, Y values from the Vector3 in the new format\n",
    "#         vector3_value_x = row[['Column5']]  # Assuming 'Column4' contains the vector,'Column6'\n",
    "#         vector3_value_y = row[['Column6']]  # Assuming 'Column4' contains the vector,'Column6'\n",
    "        \n",
    "#         x, y = extract_vector3(vector3_value_x), extract_vector3(vector3_value_y)\n",
    "        \n",
    "#         time = row['Time']\n",
    "#         preprocessed_data.append({'Time': time, 'X': x, 'Y': y, 'Tag': 'Center'})  # Assuming 'Center' tag\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing row {index}: {e}\")\n",
    "\n",
    "# # Convert to DataFrame\n",
    "# preprocessed_df = pd.DataFrame(preprocessed_data)\n",
    "# preprocessed_df.dropna(subset=['X', 'Y'], inplace=True)\n",
    "# preprocessed_df['X'] = (preprocessed_df['X']+1234)*0.9\n",
    "# preprocessed_df['Y'] = (preprocessed_df['Y']+1870)*0.9\n",
    "\n",
    "# # Function to draw gaze points on a video frame\n",
    "# def draw_gaze_points(frame, gaze_points):\n",
    "#     for point in gaze_points:\n",
    "#         color = {'Right': (0, 255, 0), 'Left': (255, 0, 0), 'Center': (0, 0, 255)}[point['Tag']]\n",
    "#         try:\n",
    "#             # Ensure x and y are integers within valid screen bounds\n",
    "#             x = max(0, min(int(point['X']), screen_width - 1))\n",
    "#             y = max(0, min(int(point['Y']), screen_height - 1))\n",
    "#             cv2.circle(frame, (x, y), 5, color, -1)\n",
    "#             # Only display coordinates for the \"Center\" point\n",
    "#             if point['Tag'] == 'Center':\n",
    "#                 cv2.putText(frame, f\"{x},{y}\", (x + 15, y - 15), \n",
    "#                             cv2.FONT_HERSHEY_SIMPLEX, 1.0, color, 2)  # Larger font size and thickness\n",
    "#         except (ValueError, TypeError):\n",
    "#             # Skip invalid points\n",
    "#             continue\n",
    "# # Set up video writer\n",
    "# fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "# out = cv2.VideoWriter(output_video_path.format(item=item), fourcc, fps, (screen_width, screen_height))\n",
    "\n",
    "# # Initialize time tracking\n",
    "# current_time = 0\n",
    "\n",
    "# while cap.isOpened():\n",
    "#     ret, frame = cap.read()\n",
    "#     if not ret:\n",
    "#         break\n",
    "\n",
    "#     # Get gaze points for the current time frame\n",
    "#     gaze_points = preprocessed_df[(preprocessed_df['Time'] >= current_time) & \n",
    "#                                   (preprocessed_df['Time'] < current_time + 1 / fps)]\n",
    "\n",
    "#     # Draw gaze points on the frame\n",
    "#     draw_gaze_points(frame, gaze_points.to_dict('records'))\n",
    "\n",
    "#     # Write the frame to the output video\n",
    "#     out.write(frame)\n",
    "\n",
    "#     # Update the current time\n",
    "#     current_time += 1 / fps\n",
    "\n",
    "# # Release resources\n",
    "# cap.release()\n",
    "# out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>159.27</td>\n",
       "      <td>-186.36</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>193.35</td>\n",
       "      <td>395.96</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02000</td>\n",
       "      <td>122.34</td>\n",
       "      <td>448.72</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.06141</td>\n",
       "      <td>82.98</td>\n",
       "      <td>446.22</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.10278</td>\n",
       "      <td>24.14</td>\n",
       "      <td>438.16</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>27.44300</td>\n",
       "      <td>414.92</td>\n",
       "      <td>-96.71</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>27.47776</td>\n",
       "      <td>416.03</td>\n",
       "      <td>-95.74</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>27.51489</td>\n",
       "      <td>422.75</td>\n",
       "      <td>-94.76</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>27.54878</td>\n",
       "      <td>421.61</td>\n",
       "      <td>-91.37</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>27.58397</td>\n",
       "      <td>420.46</td>\n",
       "      <td>-96.86</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>739 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Time       X       Y     Tag\n",
       "0     0.00000  159.27 -186.36  Center\n",
       "1     0.00000  193.35  395.96  Center\n",
       "2     0.02000  122.34  448.72  Center\n",
       "3     0.06141   82.98  446.22  Center\n",
       "4     0.10278   24.14  438.16  Center\n",
       "..        ...     ...     ...     ...\n",
       "734  27.44300  414.92  -96.71  Center\n",
       "735  27.47776  416.03  -95.74  Center\n",
       "736  27.51489  422.75  -94.76  Center\n",
       "737  27.54878  421.61  -91.37  Center\n",
       "738  27.58397  420.46  -96.86  Center\n",
       "\n",
       "[739 rows x 4 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100      159.27\n",
       "126      193.35\n",
       "153      122.34\n",
       "180       82.98\n",
       "207       24.14\n",
       "          ...  \n",
       "30749    414.92\n",
       "30785    416.03\n",
       "30821    422.75\n",
       "30857    421.61\n",
       "30893    420.46\n",
       "Name: Column5, Length: 739, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubjectID</th>\n",
       "      <th>Time</th>\n",
       "      <th>Name</th>\n",
       "      <th>ID</th>\n",
       "      <th>Column4</th>\n",
       "      <th>Column5</th>\n",
       "      <th>Column6</th>\n",
       "      <th>Column7</th>\n",
       "      <th>Column8</th>\n",
       "      <th>Column9</th>\n",
       "      <th>Column10</th>\n",
       "      <th>Column11</th>\n",
       "      <th>Column12</th>\n",
       "      <th>Column13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>GazeUIpoint</td>\n",
       "      <td>\"Player</td>\n",
       "      <td>C</td>\n",
       "      <td>(159.27</td>\n",
       "      <td>-186.36</td>\n",
       "      <td>0.00)\"</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>GazeUIpoint</td>\n",
       "      <td>\"Player</td>\n",
       "      <td>C</td>\n",
       "      <td>(193.35</td>\n",
       "      <td>395.96</td>\n",
       "      <td>0.00)\"</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.02000</td>\n",
       "      <td>GazeUIpoint</td>\n",
       "      <td>\"Player</td>\n",
       "      <td>C</td>\n",
       "      <td>(122.34</td>\n",
       "      <td>448.72</td>\n",
       "      <td>0.00)\"</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.06141</td>\n",
       "      <td>GazeUIpoint</td>\n",
       "      <td>\"Player</td>\n",
       "      <td>C</td>\n",
       "      <td>(82.98</td>\n",
       "      <td>446.22</td>\n",
       "      <td>0.00)\"</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.10278</td>\n",
       "      <td>GazeUIpoint</td>\n",
       "      <td>\"Player</td>\n",
       "      <td>C</td>\n",
       "      <td>(24.14</td>\n",
       "      <td>438.16</td>\n",
       "      <td>0.00)\"</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30749</th>\n",
       "      <td>-1</td>\n",
       "      <td>27.44300</td>\n",
       "      <td>GazeUIpoint</td>\n",
       "      <td>\"Player</td>\n",
       "      <td>C</td>\n",
       "      <td>(414.92</td>\n",
       "      <td>-96.71</td>\n",
       "      <td>0.00)\"</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30785</th>\n",
       "      <td>-1</td>\n",
       "      <td>27.47776</td>\n",
       "      <td>GazeUIpoint</td>\n",
       "      <td>\"Player</td>\n",
       "      <td>C</td>\n",
       "      <td>(416.03</td>\n",
       "      <td>-95.74</td>\n",
       "      <td>0.00)\"</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30821</th>\n",
       "      <td>-1</td>\n",
       "      <td>27.51489</td>\n",
       "      <td>GazeUIpoint</td>\n",
       "      <td>\"Player</td>\n",
       "      <td>C</td>\n",
       "      <td>(422.75</td>\n",
       "      <td>-94.76</td>\n",
       "      <td>0.00)\"</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30857</th>\n",
       "      <td>-1</td>\n",
       "      <td>27.54878</td>\n",
       "      <td>GazeUIpoint</td>\n",
       "      <td>\"Player</td>\n",
       "      <td>C</td>\n",
       "      <td>(421.61</td>\n",
       "      <td>-91.37</td>\n",
       "      <td>0.00)\"</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30893</th>\n",
       "      <td>-1</td>\n",
       "      <td>27.58397</td>\n",
       "      <td>GazeUIpoint</td>\n",
       "      <td>\"Player</td>\n",
       "      <td>C</td>\n",
       "      <td>(420.46</td>\n",
       "      <td>-96.86</td>\n",
       "      <td>0.00)\"</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>739 rows  14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SubjectID      Time          Name        ID Column4  Column5   Column6  \\\n",
       "100          -1   0.00000   GazeUIpoint   \"Player       C  (159.27   -186.36   \n",
       "126          -1   0.00000   GazeUIpoint   \"Player       C  (193.35    395.96   \n",
       "153          -1   0.02000   GazeUIpoint   \"Player       C  (122.34    448.72   \n",
       "180          -1   0.06141   GazeUIpoint   \"Player       C   (82.98    446.22   \n",
       "207          -1   0.10278   GazeUIpoint   \"Player       C   (24.14    438.16   \n",
       "...         ...       ...           ...       ...     ...      ...       ...   \n",
       "30749        -1  27.44300   GazeUIpoint   \"Player       C  (414.92    -96.71   \n",
       "30785        -1  27.47776   GazeUIpoint   \"Player       C  (416.03    -95.74   \n",
       "30821        -1  27.51489   GazeUIpoint   \"Player       C  (422.75    -94.76   \n",
       "30857        -1  27.54878   GazeUIpoint   \"Player       C  (421.61    -91.37   \n",
       "30893        -1  27.58397   GazeUIpoint   \"Player       C  (420.46    -96.86   \n",
       "\n",
       "       Column7 Column8 Column9 Column10 Column11 Column12 Column13  \n",
       "100     0.00)\"    None    None     None     None     None     None  \n",
       "126     0.00)\"    None    None     None     None     None     None  \n",
       "153     0.00)\"    None    None     None     None     None     None  \n",
       "180     0.00)\"    None    None     None     None     None     None  \n",
       "207     0.00)\"    None    None     None     None     None     None  \n",
       "...        ...     ...     ...      ...      ...      ...      ...  \n",
       "30749   0.00)\"    None    None     None     None     None     None  \n",
       "30785   0.00)\"    None    None     None     None     None     None  \n",
       "30821   0.00)\"    None    None     None     None     None     None  \n",
       "30857   0.00)\"    None    None     None     None     None     None  \n",
       "30893   0.00)\"    None    None     None     None     None     None  \n",
       "\n",
       "[739 rows x 14 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaze_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Time, X, Y, Tag]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>561.47</td>\n",
       "      <td>2369.29</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>561.47</td>\n",
       "      <td>2369.29</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2468.00</td>\n",
       "      <td>2740.00</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2468.00</td>\n",
       "      <td>2740.00</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2468.00</td>\n",
       "      <td>2740.00</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.02</td>\n",
       "      <td>2248.79</td>\n",
       "      <td>1606.55</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.02</td>\n",
       "      <td>2169.41</td>\n",
       "      <td>1582.21</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.02</td>\n",
       "      <td>2169.41</td>\n",
       "      <td>1582.21</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        X        Y     Tag\n",
       "0  0.00     0.00     0.00   Right\n",
       "1  0.00   561.47  2369.29    Left\n",
       "2  0.00   561.47  2369.29  Center\n",
       "3  0.00  2468.00  2740.00   Right\n",
       "4  0.00  2468.00  2740.00    Left\n",
       "5  0.00  2468.00  2740.00  Center\n",
       "6  0.02  2248.79  1606.55   Right\n",
       "7  0.02  2169.41  1582.21    Left\n",
       "8  0.02  2169.41  1582.21  Center"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df[(preprocessed_df['Time'] >= 0) & \n",
    "                                  (preprocessed_df['Time'] < 0 + 1 / fps)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df['X'] = preprocessed_df['X']+1234\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>1234.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>1795.47</td>\n",
       "      <td>2369.29</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>1795.47</td>\n",
       "      <td>2369.29</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>3702.00</td>\n",
       "      <td>2740.00</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>3702.00</td>\n",
       "      <td>2740.00</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2713</th>\n",
       "      <td>30.78625</td>\n",
       "      <td>3512.15</td>\n",
       "      <td>1273.01</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714</th>\n",
       "      <td>30.78625</td>\n",
       "      <td>3506.44</td>\n",
       "      <td>1272.49</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2715</th>\n",
       "      <td>30.81617</td>\n",
       "      <td>3281.69</td>\n",
       "      <td>1261.65</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2716</th>\n",
       "      <td>30.81617</td>\n",
       "      <td>3513.89</td>\n",
       "      <td>1273.28</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2717</th>\n",
       "      <td>30.81617</td>\n",
       "      <td>3509.75</td>\n",
       "      <td>1273.08</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2718 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Time        X        Y     Tag\n",
       "0      0.00000  1234.00     0.00   Right\n",
       "1      0.00000  1795.47  2369.29    Left\n",
       "2      0.00000  1795.47  2369.29  Center\n",
       "3      0.00000  3702.00  2740.00   Right\n",
       "4      0.00000  3702.00  2740.00    Left\n",
       "...        ...      ...      ...     ...\n",
       "2713  30.78625  3512.15  1273.01    Left\n",
       "2714  30.78625  3506.44  1272.49  Center\n",
       "2715  30.81617  3281.69  1261.65   Right\n",
       "2716  30.81617  3513.89  1273.28    Left\n",
       "2717  30.81617  3509.75  1273.08  Center\n",
       "\n",
       "[2718 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>561.47</td>\n",
       "      <td>2369.29</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>2468.00</td>\n",
       "      <td>2740.00</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.02000</td>\n",
       "      <td>2169.41</td>\n",
       "      <td>1582.21</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.05657</td>\n",
       "      <td>2060.46</td>\n",
       "      <td>1545.27</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.09195</td>\n",
       "      <td>2060.78</td>\n",
       "      <td>1567.89</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.12789</td>\n",
       "      <td>2051.45</td>\n",
       "      <td>1580.05</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.16112</td>\n",
       "      <td>2048.93</td>\n",
       "      <td>1580.12</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.19418</td>\n",
       "      <td>2101.54</td>\n",
       "      <td>1526.92</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.22896</td>\n",
       "      <td>2034.45</td>\n",
       "      <td>1333.60</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.26226</td>\n",
       "      <td>1755.34</td>\n",
       "      <td>1313.88</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.29761</td>\n",
       "      <td>1542.33</td>\n",
       "      <td>1296.46</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.33768</td>\n",
       "      <td>1354.80</td>\n",
       "      <td>1183.88</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.37434</td>\n",
       "      <td>1098.54</td>\n",
       "      <td>1188.54</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.41337</td>\n",
       "      <td>949.29</td>\n",
       "      <td>1199.69</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.45334</td>\n",
       "      <td>811.04</td>\n",
       "      <td>1194.71</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.49158</td>\n",
       "      <td>762.47</td>\n",
       "      <td>1187.41</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.52758</td>\n",
       "      <td>763.32</td>\n",
       "      <td>1176.39</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.56503</td>\n",
       "      <td>845.71</td>\n",
       "      <td>1151.06</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.60534</td>\n",
       "      <td>832.12</td>\n",
       "      <td>1126.99</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.64163</td>\n",
       "      <td>879.49</td>\n",
       "      <td>1123.96</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.67949</td>\n",
       "      <td>961.04</td>\n",
       "      <td>1127.27</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.71471</td>\n",
       "      <td>1027.47</td>\n",
       "      <td>1151.62</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.74810</td>\n",
       "      <td>1054.75</td>\n",
       "      <td>1180.03</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.78354</td>\n",
       "      <td>1119.27</td>\n",
       "      <td>1193.51</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.81893</td>\n",
       "      <td>1166.70</td>\n",
       "      <td>1186.91</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.85448</td>\n",
       "      <td>1206.19</td>\n",
       "      <td>1186.23</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.88933</td>\n",
       "      <td>1202.88</td>\n",
       "      <td>1174.58</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.92536</td>\n",
       "      <td>1243.19</td>\n",
       "      <td>1172.60</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.96227</td>\n",
       "      <td>1284.75</td>\n",
       "      <td>1175.29</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.99740</td>\n",
       "      <td>1297.39</td>\n",
       "      <td>1192.98</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time        X        Y     Tag\n",
       "2   0.00000   561.47  2369.29  Center\n",
       "5   0.00000  2468.00  2740.00  Center\n",
       "8   0.02000  2169.41  1582.21  Center\n",
       "11  0.05657  2060.46  1545.27  Center\n",
       "14  0.09195  2060.78  1567.89  Center\n",
       "17  0.12789  2051.45  1580.05  Center\n",
       "20  0.16112  2048.93  1580.12  Center\n",
       "23  0.19418  2101.54  1526.92  Center\n",
       "26  0.22896  2034.45  1333.60  Center\n",
       "29  0.26226  1755.34  1313.88  Center\n",
       "32  0.29761  1542.33  1296.46  Center\n",
       "35  0.33768  1354.80  1183.88  Center\n",
       "38  0.37434  1098.54  1188.54  Center\n",
       "41  0.41337   949.29  1199.69  Center\n",
       "44  0.45334   811.04  1194.71  Center\n",
       "47  0.49158   762.47  1187.41  Center\n",
       "50  0.52758   763.32  1176.39  Center\n",
       "53  0.56503   845.71  1151.06  Center\n",
       "56  0.60534   832.12  1126.99  Center\n",
       "59  0.64163   879.49  1123.96  Center\n",
       "62  0.67949   961.04  1127.27  Center\n",
       "65  0.71471  1027.47  1151.62  Center\n",
       "68  0.74810  1054.75  1180.03  Center\n",
       "71  0.78354  1119.27  1193.51  Center\n",
       "74  0.81893  1166.70  1186.91  Center\n",
       "77  0.85448  1206.19  1186.23  Center\n",
       "80  0.88933  1202.88  1174.58  Center\n",
       "83  0.92536  1243.19  1172.60  Center\n",
       "86  0.96227  1284.75  1175.29  Center\n",
       "89  0.99740  1297.39  1192.98  Center"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df[preprocessed_df[\"Tag\"]==\"Center\"].iloc[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved as pilot2/processed/debug_pixel_marker.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Video settings\n",
    "width, height = 1920, 1080\n",
    "fps = 30\n",
    "num_frames = 90\n",
    "output_file = 'pilot2/processed/debug_pixel_marker.mp4'\n",
    "\n",
    "# Define the video writer\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_file, fourcc, fps, (width, height))\n",
    "\n",
    "# Marker settings\n",
    "marker_size = 20\n",
    "positions = [(1,1080), (1919, 1), (1, 1919)]\n",
    "frame_ranges = [(1, 30), (31, 60), (61, 90)]\n",
    "\n",
    "# Generate frames\n",
    "for frame_idx in range(1, num_frames + 1):\n",
    "    # Create a white frame\n",
    "    frame = np.ones((height, width, 3), dtype=np.uint8) * 255\n",
    "\n",
    "    # Determine marker position for the current frame\n",
    "    for i, (start, end) in enumerate(frame_ranges):\n",
    "        if start <= frame_idx <= end:\n",
    "            position = positions[i]\n",
    "            cv2.circle(frame, position, marker_size, (0, 0, 0), -1)\n",
    "            break\n",
    "\n",
    "    # Write the frame to the video\n",
    "    out.write(frame)\n",
    "\n",
    "# Release the video writer\n",
    "out.release()\n",
    "print(f\"Video saved as {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the video file\n",
    "video_path = '/pilot2/process/test.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Frame numbers to extract\n",
    "frames_to_extract = [50, 100, 150, 200, 250]\n",
    "\n",
    "# Store extracted frames\n",
    "extracted_frames = []\n",
    "\n",
    "# Extract frames\n",
    "frame_index = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    if frame_index in frames_to_extract:\n",
    "        extracted_frames.append((frame_index, cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)))\n",
    "        if len(extracted_frames) == len(frames_to_extract):\n",
    "            break\n",
    "\n",
    "    frame_index += 1\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Plot the extracted frames\n",
    "fig, axes = plt.subplots(1, len(extracted_frames), figsize=(20, 5))\n",
    "for ax, (idx, frame) in zip(axes, extracted_frames):\n",
    "    ax.imshow(frame)\n",
    "    ax.set_title(f\"Frame {idx}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>2.02082</td>\n",
       "      <td>817.68</td>\n",
       "      <td>495.42</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>2.02082</td>\n",
       "      <td>762.15</td>\n",
       "      <td>499.16</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>2.02082</td>\n",
       "      <td>789.68</td>\n",
       "      <td>497.31</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>2.06015</td>\n",
       "      <td>825.33</td>\n",
       "      <td>496.48</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>2.06015</td>\n",
       "      <td>776.35</td>\n",
       "      <td>500.57</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>2.06015</td>\n",
       "      <td>800.50</td>\n",
       "      <td>498.55</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>2.09608</td>\n",
       "      <td>833.02</td>\n",
       "      <td>496.54</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>2.09608</td>\n",
       "      <td>782.06</td>\n",
       "      <td>500.63</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>2.09608</td>\n",
       "      <td>806.92</td>\n",
       "      <td>498.63</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>2.13269</td>\n",
       "      <td>848.88</td>\n",
       "      <td>480.83</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>2.13269</td>\n",
       "      <td>787.31</td>\n",
       "      <td>480.69</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>2.13269</td>\n",
       "      <td>815.43</td>\n",
       "      <td>480.75</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>2.17001</td>\n",
       "      <td>836.80</td>\n",
       "      <td>412.61</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>2.17001</td>\n",
       "      <td>784.35</td>\n",
       "      <td>414.26</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>2.17001</td>\n",
       "      <td>836.17</td>\n",
       "      <td>412.63</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>2.20834</td>\n",
       "      <td>834.64</td>\n",
       "      <td>399.19</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>2.20834</td>\n",
       "      <td>779.71</td>\n",
       "      <td>406.43</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>2.20834</td>\n",
       "      <td>833.65</td>\n",
       "      <td>399.32</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2.24495</td>\n",
       "      <td>841.61</td>\n",
       "      <td>401.87</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2.24495</td>\n",
       "      <td>786.56</td>\n",
       "      <td>402.56</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>2.24495</td>\n",
       "      <td>841.52</td>\n",
       "      <td>401.87</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>2.28592</td>\n",
       "      <td>842.89</td>\n",
       "      <td>400.39</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>2.28592</td>\n",
       "      <td>787.81</td>\n",
       "      <td>403.85</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>2.28592</td>\n",
       "      <td>834.02</td>\n",
       "      <td>400.95</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>2.32276</td>\n",
       "      <td>844.66</td>\n",
       "      <td>399.51</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>2.32276</td>\n",
       "      <td>788.07</td>\n",
       "      <td>402.67</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>2.32276</td>\n",
       "      <td>836.92</td>\n",
       "      <td>399.94</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>2.35958</td>\n",
       "      <td>844.06</td>\n",
       "      <td>399.39</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>2.35958</td>\n",
       "      <td>787.76</td>\n",
       "      <td>403.56</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>2.35958</td>\n",
       "      <td>830.62</td>\n",
       "      <td>400.38</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Time       X       Y     Tag\n",
       "162  2.02082  817.68  495.42   Right\n",
       "163  2.02082  762.15  499.16    Left\n",
       "164  2.02082  789.68  497.31  Center\n",
       "165  2.06015  825.33  496.48   Right\n",
       "166  2.06015  776.35  500.57    Left\n",
       "167  2.06015  800.50  498.55  Center\n",
       "168  2.09608  833.02  496.54   Right\n",
       "169  2.09608  782.06  500.63    Left\n",
       "170  2.09608  806.92  498.63  Center\n",
       "171  2.13269  848.88  480.83   Right\n",
       "172  2.13269  787.31  480.69    Left\n",
       "173  2.13269  815.43  480.75  Center\n",
       "174  2.17001  836.80  412.61   Right\n",
       "175  2.17001  784.35  414.26    Left\n",
       "176  2.17001  836.17  412.63  Center\n",
       "177  2.20834  834.64  399.19   Right\n",
       "178  2.20834  779.71  406.43    Left\n",
       "179  2.20834  833.65  399.32  Center\n",
       "180  2.24495  841.61  401.87   Right\n",
       "181  2.24495  786.56  402.56    Left\n",
       "182  2.24495  841.52  401.87  Center\n",
       "183  2.28592  842.89  400.39   Right\n",
       "184  2.28592  787.81  403.85    Left\n",
       "185  2.28592  834.02  400.95  Center\n",
       "186  2.32276  844.66  399.51   Right\n",
       "187  2.32276  788.07  402.67    Left\n",
       "188  2.32276  836.92  399.94  Center\n",
       "189  2.35958  844.06  399.39   Right\n",
       "190  2.35958  787.76  403.56    Left\n",
       "191  2.35958  830.62  400.38  Center"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df[preprocessed_df['Time']>=2][:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "found likely XDF file corruption (unpack requires a buffer of 8 bytes), scanning forward to next boundary chunk.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stream 1: Calculated effective sampling rate 72.6329 Hz is different from specified rate 50.0000 Hz.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import neurokit2 as nk\n",
    "import Dataloader as dl\n",
    "# --- PARAMETERS ---\n",
    "# data_path = \"pilot2/bnbn_eyetracker.pkl\"\n",
    "# data_path = \"pilot2/testeyetracking_dist.xdf\"\n",
    "data_path = \"pilot2/0117/block_0117.xdf\"\n",
    "\n",
    "scenes = [\"Practice\", \"ElevatorTest\", \"Elevator1\",\"Outside\", \"Hallway\", \"Elevator2\", \"Hall\"]\n",
    "data = nk.read_xdf(data_path)\n",
    "data = data[0][['Scene', 'UnityTime', 'GazeEndpoint_Right_X', 'GazeEndpoint_Right_Y',\n",
    "       'GazeEndpoint_Right_Z', 'ScreenPoint_Right_X', 'ScreenPoint_Right_Y',\n",
    "       'GazeEndpoint_Left_X', 'GazeEndpoint_Left_Y', 'GazeEndpoint_Left_Z',\n",
    "       'ScreenPoint_Left_X', 'ScreenPoint_Left_Y', 'GazeEndpoint_Center_X',\n",
    "       'GazeEndpoint_Center_Y', 'GazeEndpoint_Center_Z',\n",
    "       'ScreenPoint_Center_X', 'ScreenPoint_Center_Y', 'Convergence_Distance']]\n",
    "\n",
    "mapping = {\n",
    "        0: \"Start\",\n",
    "        1: \"Practice\",\n",
    "        2: \"ElevatorTest\",\n",
    "        3: \"Elevator1\",\n",
    "        4: \"Outside\",\n",
    "        5: \"Hallway\",\n",
    "        6: \"Elevator2\",\n",
    "        7: \"Hall\",\n",
    "        8: \"End\"\n",
    "        }\n",
    "\n",
    "#         # Replace values in the column\n",
    "data['Scene'] = data['Scene'].map(mapping)\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Resolution: 1920x1080, FPS: 30\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 1\n",
      "0 317\n",
      "0 13\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 111\n",
      "0 164\n",
      "0 171\n",
      "0 165\n",
      "0 169\n",
      "0 101\n",
      "0 128\n",
      "0 121\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 916\n",
      "0 651\n",
      "0 743\n",
      "0 776\n",
      "0 647\n",
      "0 608\n",
      "652 486\n",
      "715 470\n",
      "740 467\n",
      "1099 433\n",
      "1031 456\n",
      "1049 464\n",
      "1289 430\n",
      "1329 425\n",
      "1688 374\n",
      "1721 364\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "834 187\n",
      "1913 440\n",
      "1914 440\n",
      "1890 441\n",
      "1891 442\n",
      "1889 442\n",
      "1911 435\n",
      "1898 430\n",
      "1908 433\n",
      "1911 432\n",
      "1887 432\n",
      "1890 432\n",
      "1891 431\n",
      "1886 430\n",
      "1887 430\n",
      "1892 429\n",
      "1893 429\n",
      "1904 428\n",
      "1917 426\n",
      "1914 426\n",
      "1905 424\n",
      "1905 425\n",
      "1871 430\n",
      "1833 433\n",
      "1769 435\n",
      "1827 448\n",
      "Gaze video processing complete! Output saved as: pilot2/processed/test_04_Outside_newgaze24.mp4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# data.rename(columns={'scene':'Scene'}, inplace=True)\n",
    "# scenes = [\"02_ElevatorTest\", \"03_Elevator1\", \"04_Outside\", \"05_Hallway\", \"06_Elevator2\", \"07_Hall\"]\n",
    "scenes = [\"04_Outside\"]\n",
    "\n",
    "for item in scenes:\n",
    "    video_path = f\"pilot2/0117/{item}.mp4\"\n",
    "    # eye_data = data[data[\"Scene\"]==pd.to_numeric(item[1])]\n",
    "    eye_data = data[data[\"Scene\"]==item.split('_')[1]]\n",
    "    # sanity_check_video_gaze_end(video_path, eye_data, gaze_fps=120)\n",
    "    \n",
    "    output_video = f\"pilot2/processed/test_{item}_newgaze24.mp4\"\n",
    "    create_gaze_video(video_path, eye_data, output_video)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['Scene']==\"Outside\"]['ScreenPoint_Center_Y'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaze1 2D: (516.7616463138852, 100.3799185888738)\n",
      "Gaze2 2D: (1425.8525554047942, 104.95929443690642)\n",
      "Final Gaze 2D: (971.3071008593397, 102.66960651289008)\n"
     ]
    }
   ],
   "source": [
    "def rescale_intrinsics(fx, fy, cx, cy, old_width, old_height, new_width, new_height):\n",
    "    # Calculate scaling factors\n",
    "    scale_x = new_width / old_width\n",
    "    scale_y = new_height / old_height\n",
    "    \n",
    "    # Rescale focal lengths\n",
    "    fx_new = fx * scale_x\n",
    "    fy_new = fy * scale_y\n",
    "    \n",
    "    # Rescale principal point (cx, cy)\n",
    "    cx_new = cx * scale_x\n",
    "    cy_new = cy * scale_y\n",
    "    \n",
    "    return fx_new, fy_new, cx_new, cy_new\n",
    "\n",
    "def calculate_gaze(eye1_pos, gaze1_dir, eye2_pos, gaze2_dir, distance, fx, fy, cx, cy):\n",
    "    # Step 1: Calculate endpoints in 3D\n",
    "    endpoint1 = (\n",
    "        eye1_pos[0] + gaze1_dir[0] * distance,\n",
    "        eye1_pos[1] + gaze1_dir[1] * distance,\n",
    "        eye1_pos[2] + gaze1_dir[2] * distance\n",
    "    )\n",
    "    endpoint2 = (\n",
    "        eye2_pos[0] + gaze2_dir[0] * distance,\n",
    "        eye2_pos[1] + gaze2_dir[1] * distance,\n",
    "        eye2_pos[2] + gaze2_dir[2] * distance\n",
    "    )\n",
    "    \n",
    "    # Step 2: Calculate the final gaze point (average of both eye endpoints)\n",
    "    final_gaze = (\n",
    "        (endpoint1[0] + endpoint2[0]) / 2,\n",
    "        (endpoint1[1] + endpoint2[1]) / 2,\n",
    "        (endpoint1[2] + endpoint2[2]) / 2\n",
    "    )\n",
    "    \n",
    "    # Step 3: Project to 2D video space\n",
    "    def project_to_2d(point, fx, fy, cx, cy):\n",
    "        x, y, z = point\n",
    "        u = fx * (x / z) + cx\n",
    "        v = fy * (y / z) + cy\n",
    "        return (u, v)\n",
    "    \n",
    "    gaze1_2d = project_to_2d(endpoint1, fx, fy, cx, cy)\n",
    "    gaze2_2d = project_to_2d(endpoint2, fx, fy, cx, cy)\n",
    "    final_gaze_2d = project_to_2d(final_gaze, fx, fy, cx, cy)\n",
    "    \n",
    "    return gaze1_2d, gaze2_2d, final_gaze_2d\n",
    "\n",
    "# Example setup for binocular camera\n",
    "old_width = 2880\n",
    "old_height = 1600\n",
    "new_width = 1920\n",
    "new_height = 1080\n",
    "\n",
    "# Intrinsic parameters for the binocular camera\n",
    "fx = 1000  # Focal length in pixels (same for both eyes at original resolution)\n",
    "fy = 1000  # Focal length in pixels (same for both eyes at original resolution)\n",
    "cx = 1440  # Principal point in x (center of the binocular image)\n",
    "cy = 800   # Principal point in y (center of the binocular image)\n",
    "\n",
    "# Rescale intrinsics for the new resolution\n",
    "fx_new, fy_new, cx_new, cy_new = rescale_intrinsics(fx, fy, cx, cy, old_width, old_height, new_width, new_height)\n",
    "\n",
    "# Example eye positions and normalized gaze directions (assuming normalized gaze vector)\n",
    "eye1_pos = (10, 20, 30)  # Left eye position (in mm)\n",
    "gaze1_dir = (-0.5, -0.5, 0.707)  # Normalized direction vector for left eye\n",
    "eye2_pos = (15, 25, 30)  # Right eye position (in mm)\n",
    "gaze2_dir = (0.5, -0.5, 0.707)  # Normalized direction vector for right eye\n",
    "distance = 1000  # Distance to the object (in mm)\n",
    "\n",
    "# Calculate the gaze points in 2D (projected from 3D)\n",
    "gaze1_2d, gaze2_2d, final_gaze_2d = calculate_gaze(\n",
    "    eye1_pos, gaze1_dir, eye2_pos, gaze2_dir, distance, fx_new, fy_new, cx_new, cy_new\n",
    ")\n",
    "\n",
    "# Output the results\n",
    "print(\"Gaze1 2D:\", gaze1_2d)\n",
    "print(\"Gaze2 2D:\", gaze2_2d)\n",
    "print(\"Final Gaze 2D:\", final_gaze_2d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load video and eye-tracking data\n",
    "# import Dataloader as dl\n",
    "# data_path = \"pilot2/test_calibration.xdf\"\n",
    "# data = dl.xdfreaderfixer(data_path)\n",
    "# # data.rename(columns={'scene':'Scene'}, inplace=True)\n",
    "# # scenes = [\"02_ElevatorTest\", \"03_Elevator1\", \"04_Outside\", \"05_Hallway\", \"06_Elevator2\", \"07_Hall\"]\n",
    "# # scenes = [\"04_Outside\"]\n",
    "\n",
    "# # for item in scenes:\n",
    "# #     video_path = f\"pilot2/bnbn/{item}.mp4\"\n",
    "# #     # eye_data = data[data[\"Scene\"]==pd.to_numeric(item[1])]\n",
    "# #     eye_data = data[data[\"Scene\"]==item.split('_')[1]]\n",
    "    \n",
    "# #     output_video = f\"pilot2/processed/test_{item}_newgaze.mp4\"\n",
    "# #     create_gaze_video(video_path, eye_data, output_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan,  0.], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data[0]['convergence_distance_mm'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Scene'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Jiyoon\\anaconda3\\envs\\torch\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Jiyoon\\anaconda3\\envs\\torch\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Jiyoon\\anaconda3\\envs\\torch\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Scene'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_72096/2239124692.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"pilot2/processed/eyetracker.pkl\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0meye_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Scene'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Jiyoon\\anaconda3\\envs\\torch\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3457\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3458\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3459\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Jiyoon\\anaconda3\\envs\\torch\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Scene'"
     ]
    }
   ],
   "source": [
    "# scenes = [\"02_ElevatorTest\", \"03_Elevator1\", \"04_Outside\", \"05_Hallway\", \"06_Elevator2\", \"07_Hall\"]\n",
    "# data_path = \"pilot2/processed/eyetracker.pkl\"\n",
    "# data = pd.read_pickle(data_path)\n",
    "# eye_data = data[data['Scene']==2].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAM AOI segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"GPU Available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 4.8ms\n",
      "Speed: 3.0ms preprocess, 4.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 chair, 3.0ms\n",
      "Speed: 1.5ms preprocess, 3.0ms inference, 8.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 3.0ms\n",
      "Speed: 1.8ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 3.0ms\n",
      "Speed: 2.9ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 3.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 3.0ms\n",
      "Speed: 2.0ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.8ms\n",
      "Speed: 1.0ms preprocess, 5.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 3.8ms\n",
      "Speed: 1.0ms preprocess, 3.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 3.6ms\n",
      "Speed: 1.0ms preprocess, 3.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 3.0ms\n",
      "Speed: 2.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 3.0ms\n",
      "Speed: 2.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bench, 7.5ms\n",
      "Speed: 4.0ms preprocess, 7.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 3.0ms\n",
      "Speed: 2.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 3.0ms\n",
      "Speed: 2.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 1.7ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 3.0ms\n",
      "Speed: 1.8ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 3.0ms\n",
      "Speed: 2.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 3.8ms\n",
      "Speed: 1.7ms preprocess, 3.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 3.8ms\n",
      "Speed: 1.0ms preprocess, 3.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 3.0ms\n",
      "Speed: 2.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 3.0ms\n",
      "Speed: 2.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 3.9ms\n",
      "Speed: 1.0ms preprocess, 3.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 chair, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 chair, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 3.0ms\n",
      "Speed: 2.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 2.1ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.8ms\n",
      "Speed: 1.0ms preprocess, 4.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 chair, 4.0ms\n",
      "Speed: 1.4ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 3.0ms\n",
      "Speed: 2.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 3.0ms\n",
      "Speed: 2.0ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.8ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 1.4ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bench, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 3.9ms\n",
      "Speed: 1.7ms preprocess, 3.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 chair, 5.8ms\n",
      "Speed: 1.0ms preprocess, 5.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bench, 3.8ms\n",
      "Speed: 1.0ms preprocess, 3.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.6ms\n",
      "Speed: 1.0ms preprocess, 5.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 3.8ms\n",
      "Speed: 2.0ms preprocess, 3.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bench, 3.8ms\n",
      "Speed: 1.0ms preprocess, 3.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bench, 3.0ms\n",
      "Speed: 2.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 chair, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bench, 1 chair, 4.2ms\n",
      "Speed: 2.0ms preprocess, 4.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bench, 1 chair, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bench, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bench, 1 chair, 7.8ms\n",
      "Speed: 1.0ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bench, 1 chair, 11.0ms\n",
      "Speed: 1.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bench, 1 chair, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bench, 1 chair, 5.8ms\n",
      "Speed: 2.0ms preprocess, 5.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 2.5ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 chair, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.2ms\n",
      "Speed: 1.0ms preprocess, 4.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 3.9ms\n",
      "Speed: 2.0ms preprocess, 3.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 chair, 5.3ms\n",
      "Speed: 1.0ms preprocess, 5.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 chair, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 chair, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 chair, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 chair, 3.8ms\n",
      "Speed: 2.0ms preprocess, 3.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 chair, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.8ms\n",
      "Speed: 1.0ms preprocess, 4.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bench, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bench, 1 chair, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 chair, 7.8ms\n",
      "Speed: 1.0ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 chair, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bench, 1 chair, 4.8ms\n",
      "Speed: 1.0ms preprocess, 4.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bench, 3.9ms\n",
      "Speed: 2.0ms preprocess, 3.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bench, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bench, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bench, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bench, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bench, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 chair, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 chair, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 chair, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 chair, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 chair, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 1.7ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 1.9ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 chair, 5.4ms\n",
      "Speed: 2.0ms preprocess, 5.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 3.8ms\n",
      "Speed: 1.0ms preprocess, 3.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 chair, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 chair, 3.5ms\n",
      "Speed: 2.0ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bench, 6.6ms\n",
      "Speed: 1.0ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 chair, 6.0ms\n",
      "Speed: 1.8ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 chair, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 1.5ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.5ms\n",
      "Speed: 2.0ms preprocess, 7.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.1ms\n",
      "Speed: 1.9ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.7ms\n",
      "Speed: 2.0ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.3ms\n",
      "Speed: 2.0ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.8ms\n",
      "Speed: 2.0ms preprocess, 7.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.7ms\n",
      "Speed: 2.0ms preprocess, 11.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.6ms\n",
      "Speed: 1.0ms preprocess, 6.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.4ms\n",
      "Speed: 2.0ms preprocess, 4.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.8ms\n",
      "Speed: 1.5ms preprocess, 5.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 3.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.5ms\n",
      "Speed: 2.0ms preprocess, 4.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.7ms\n",
      "Speed: 2.0ms preprocess, 6.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.8ms\n",
      "Speed: 2.0ms preprocess, 4.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.9ms\n",
      "Speed: 1.0ms preprocess, 4.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.6ms\n",
      "Speed: 1.5ms preprocess, 6.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.2ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.6ms\n",
      "Speed: 1.0ms preprocess, 5.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 chair, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 3.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.7ms\n",
      "Speed: 2.0ms preprocess, 6.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.5ms\n",
      "Speed: 1.0ms preprocess, 5.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.6ms\n",
      "Speed: 1.5ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.2ms\n",
      "Speed: 2.0ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.0ms\n",
      "Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.0ms\n",
      "Speed: 1.0ms preprocess, 11.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.9ms\n",
      "Speed: 2.0ms preprocess, 4.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.2ms\n",
      "Speed: 2.0ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.6ms\n",
      "Speed: 2.0ms preprocess, 6.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 1.5ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.5ms\n",
      "Speed: 1.0ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.9ms\n",
      "Speed: 2.0ms preprocess, 8.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.6ms\n",
      "Speed: 2.5ms preprocess, 12.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.7ms\n",
      "Speed: 2.0ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.9ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.6ms\n",
      "Speed: 2.0ms preprocess, 4.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 1.5ms preprocess, 7.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.8ms\n",
      "Speed: 1.0ms preprocess, 12.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.8ms\n",
      "Speed: 2.0ms preprocess, 5.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.5ms\n",
      "Speed: 2.0ms preprocess, 7.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.8ms\n",
      "Speed: 1.0ms preprocess, 6.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.7ms\n",
      "Speed: 2.0ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.9ms\n",
      "Speed: 1.0ms preprocess, 8.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.9ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.3ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 2.3ms preprocess, 9.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 chair, 5.8ms\n",
      "Speed: 1.0ms preprocess, 5.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.9ms\n",
      "Speed: 2.0ms preprocess, 4.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.0ms\n",
      "Speed: 1.0ms preprocess, 11.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 chair, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 chair, 6.9ms\n",
      "Speed: 2.0ms preprocess, 6.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 3.5ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 23.8ms\n",
      "Speed: 1.0ms preprocess, 23.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.2ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 4.0ms preprocess, 9.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 1.3ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.8ms\n",
      "Speed: 2.0ms preprocess, 5.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.2ms\n",
      "Speed: 1.0ms preprocess, 13.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.9ms\n",
      "Speed: 2.0ms preprocess, 12.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.6ms\n",
      "Speed: 2.0ms preprocess, 4.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.6ms\n",
      "Speed: 2.0ms preprocess, 5.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.6ms\n",
      "Speed: 2.0ms preprocess, 6.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.8ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.2ms\n",
      "Speed: 2.0ms preprocess, 8.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.7ms\n",
      "Speed: 2.0ms preprocess, 7.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.7ms\n",
      "Speed: 1.6ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.8ms\n",
      "Speed: 1.0ms preprocess, 5.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.9ms\n",
      "Speed: 1.0ms preprocess, 9.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.5ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.0ms\n",
      "Speed: 1.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.4ms\n",
      "Speed: 1.0ms preprocess, 13.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.1ms\n",
      "Speed: 2.0ms preprocess, 9.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.5ms\n",
      "Speed: 1.0ms preprocess, 5.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.6ms\n",
      "Speed: 2.0ms preprocess, 5.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 9.0ms\n",
      "Speed: 5.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 1.5ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 1.8ms preprocess, 6.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.3ms preprocess, 5.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 4.8ms\n",
      "Speed: 2.0ms preprocess, 4.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.1ms\n",
      "Speed: 2.0ms preprocess, 5.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.5ms\n",
      "Speed: 1.8ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 13.6ms\n",
      "Speed: 2.0ms preprocess, 13.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.7ms\n",
      "Speed: 3.0ms preprocess, 5.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 4.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.9ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 10.5ms\n",
      "Speed: 0.8ms preprocess, 10.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 8.6ms\n",
      "Speed: 2.0ms preprocess, 8.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.4ms\n",
      "Speed: 2.0ms preprocess, 4.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.5ms\n",
      "Speed: 1.0ms preprocess, 5.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 1.9ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.5ms\n",
      "Speed: 1.0ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 11.1ms\n",
      "Speed: 1.0ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 4.5ms\n",
      "Speed: 2.0ms preprocess, 4.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.8ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.4ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.3ms\n",
      "Speed: 1.0ms preprocess, 5.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 9.3ms\n",
      "Speed: 2.0ms preprocess, 9.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.7ms\n",
      "Speed: 2.0ms preprocess, 6.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.5ms\n",
      "Speed: 2.0ms preprocess, 5.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.8ms\n",
      "Speed: 1.0ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.9ms\n",
      "Speed: 2.0ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 3.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.6ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.8ms\n",
      "Speed: 2.0ms preprocess, 5.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.4ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 13.6ms\n",
      "Speed: 1.0ms preprocess, 13.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.5ms\n",
      "Speed: 1.0ms preprocess, 5.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.0ms\n",
      "Speed: 1.7ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 4.5ms\n",
      "Speed: 2.0ms preprocess, 4.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 4.6ms\n",
      "Speed: 2.0ms preprocess, 4.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.9ms\n",
      "Speed: 2.0ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.1ms\n",
      "Speed: 2.0ms preprocess, 5.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 12.0ms\n",
      "Speed: 3.4ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.6ms\n",
      "Speed: 2.0ms preprocess, 5.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.8ms\n",
      "Speed: 1.0ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.7ms\n",
      "Speed: 2.0ms preprocess, 6.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.9ms\n",
      "Speed: 1.9ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.1ms\n",
      "Speed: 2.0ms preprocess, 5.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 8.0ms\n",
      "Speed: 1.6ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.8ms\n",
      "Speed: 1.0ms preprocess, 4.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.9ms\n",
      "Speed: 1.0ms preprocess, 5.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.2ms\n",
      "Speed: 2.0ms preprocess, 6.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.6ms\n",
      "Speed: 9.0ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.0ms\n",
      "Speed: 1.5ms preprocess, 7.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 4.9ms\n",
      "Speed: 1.6ms preprocess, 4.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.9ms\n",
      "Speed: 2.0ms preprocess, 13.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.7ms\n",
      "Speed: 1.0ms preprocess, 5.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.8ms\n",
      "Speed: 2.0ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 0.8ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.5ms\n",
      "Speed: 2.0ms preprocess, 9.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 microwave, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 microwave, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 microwave, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 microwave, 6.0ms\n",
      "Speed: 3.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 microwave, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 3.2ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.3ms\n",
      "Speed: 1.0ms preprocess, 8.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.8ms\n",
      "Speed: 2.0ms preprocess, 5.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.3ms\n",
      "Speed: 2.0ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 refrigerator, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.8ms\n",
      "Speed: 2.0ms preprocess, 4.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 refrigerator, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 4.8ms\n",
      "Speed: 2.0ms preprocess, 4.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.8ms\n",
      "Speed: 2.0ms preprocess, 8.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.1ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.7ms\n",
      "Speed: 1.0ms preprocess, 6.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.1ms\n",
      "Speed: 1.9ms preprocess, 5.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 3.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 cell phone, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.6ms\n",
      "Speed: 1.0ms preprocess, 4.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.6ms\n",
      "Speed: 2.0ms preprocess, 8.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.1ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.8ms\n",
      "Speed: 1.0ms preprocess, 9.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.8ms\n",
      "Speed: 2.0ms preprocess, 9.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.5ms\n",
      "Speed: 1.0ms preprocess, 13.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.9ms\n",
      "Speed: 2.0ms preprocess, 10.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.4ms\n",
      "Speed: 1.0ms preprocess, 9.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.5ms\n",
      "Speed: 2.0ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 4.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.0ms\n",
      "Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.5ms\n",
      "Speed: 2.0ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.2ms\n",
      "Speed: 2.0ms preprocess, 9.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.5ms\n",
      "Speed: 1.0ms preprocess, 6.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 2.6ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.8ms\n",
      "Speed: 1.0ms preprocess, 12.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 3.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 1.6ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.8ms\n",
      "Speed: 1.0ms preprocess, 5.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.1ms\n",
      "Speed: 2.0ms preprocess, 7.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.3ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.9ms\n",
      "Speed: 1.0ms preprocess, 7.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.2ms\n",
      "Speed: 1.8ms preprocess, 7.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.8ms\n",
      "Speed: 2.0ms preprocess, 6.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.3ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.9ms\n",
      "Speed: 1.0ms preprocess, 7.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 3.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.8ms\n",
      "Speed: 2.0ms preprocess, 4.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.5ms\n",
      "Speed: 1.0ms preprocess, 5.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.5ms\n",
      "Speed: 2.0ms preprocess, 5.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 2.9ms preprocess, 9.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.5ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.6ms\n",
      "Speed: 3.0ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.8ms\n",
      "Speed: 2.0ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.1ms\n",
      "Speed: 3.0ms preprocess, 5.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.0ms\n",
      "Speed: 1.9ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 3.4ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.0ms\n",
      "Speed: 3.0ms preprocess, 7.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 1.2ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.2ms\n",
      "Speed: 1.0ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.5ms\n",
      "Speed: 2.8ms preprocess, 5.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 2.1ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 4.9ms\n",
      "Speed: 2.0ms preprocess, 4.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 3.1ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 9.9ms\n",
      "Speed: 1.0ms preprocess, 9.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.8ms\n",
      "Speed: 2.0ms preprocess, 5.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 0.8ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 13.5ms\n",
      "Speed: 1.0ms preprocess, 13.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.8ms\n",
      "Speed: 2.0ms preprocess, 11.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 2.6ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.8ms\n",
      "Speed: 1.0ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 9.8ms\n",
      "Speed: 2.0ms preprocess, 9.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.8ms\n",
      "Speed: 2.0ms preprocess, 5.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.9ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.5ms\n",
      "Speed: 2.0ms preprocess, 5.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.0ms\n",
      "Speed: 1.8ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.6ms\n",
      "Speed: 1.0ms preprocess, 5.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 10.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 13.0ms\n",
      "Speed: 1.6ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.8ms\n",
      "Speed: 2.0ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.8ms\n",
      "Speed: 2.0ms preprocess, 4.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.5ms\n",
      "Speed: 1.0ms preprocess, 5.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.3ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 2.4ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.5ms\n",
      "Speed: 1.0ms preprocess, 5.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.2ms\n",
      "Speed: 1.8ms preprocess, 7.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.2ms\n",
      "Speed: 2.0ms preprocess, 13.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.7ms\n",
      "Speed: 1.0ms preprocess, 7.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.4ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.4ms preprocess, 7.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.4ms\n",
      "Speed: 2.0ms preprocess, 5.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.0ms\n",
      "Speed: 1.1ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.6ms\n",
      "Speed: 2.0ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.9ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.6ms\n",
      "Speed: 1.0ms preprocess, 7.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.6ms\n",
      "Speed: 0.8ms preprocess, 5.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.4ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.6ms\n",
      "Speed: 2.0ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.8ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.8ms\n",
      "Speed: 3.0ms preprocess, 4.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.4ms\n",
      "Speed: 2.0ms preprocess, 5.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.8ms\n",
      "Speed: 1.0ms preprocess, 5.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.6ms\n",
      "Speed: 2.0ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.8ms\n",
      "Speed: 2.0ms preprocess, 5.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.6ms\n",
      "Speed: 3.0ms preprocess, 11.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.7ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.2ms\n",
      "Speed: 2.0ms preprocess, 5.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.0ms\n",
      "Speed: 2.4ms preprocess, 11.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.8ms\n",
      "Speed: 1.0ms preprocess, 11.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.3ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.5ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.8ms\n",
      "Speed: 1.0ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.8ms\n",
      "Speed: 2.0ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.5ms\n",
      "Speed: 1.0ms preprocess, 6.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.6ms\n",
      "Speed: 1.0ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 1.8ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.7ms\n",
      "Speed: 2.0ms preprocess, 5.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.5ms\n",
      "Speed: 2.0ms preprocess, 5.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 1.8ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.3ms\n",
      "Speed: 2.0ms preprocess, 7.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.5ms\n",
      "Speed: 2.0ms preprocess, 4.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 1.8ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.3ms\n",
      "Speed: 3.0ms preprocess, 13.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.7ms\n",
      "Speed: 1.0ms preprocess, 6.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.8ms\n",
      "Speed: 2.0ms preprocess, 5.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.9ms\n",
      "Speed: 2.0ms preprocess, 6.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.7ms\n",
      "Speed: 2.0ms preprocess, 6.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.8ms\n",
      "Speed: 2.0ms preprocess, 4.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.8ms\n",
      "Speed: 1.0ms preprocess, 5.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.1ms\n",
      "Speed: 1.9ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.7ms\n",
      "Speed: 2.0ms preprocess, 4.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.8ms\n",
      "Speed: 1.0ms preprocess, 5.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.0ms\n",
      "Speed: 1.8ms preprocess, 13.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 3.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.6ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.5ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.9ms\n",
      "Speed: 2.0ms preprocess, 4.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.1ms\n",
      "Speed: 1.0ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.2ms\n",
      "Speed: 2.0ms preprocess, 7.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.2ms\n",
      "Speed: 2.0ms preprocess, 7.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.9ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.8ms\n",
      "Speed: 2.0ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.6ms\n",
      "Speed: 1.0ms preprocess, 7.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.9ms\n",
      "Speed: 2.0ms preprocess, 4.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.8ms\n",
      "Speed: 1.0ms preprocess, 5.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.4ms\n",
      "Speed: 2.0ms preprocess, 5.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.8ms\n",
      "Speed: 1.0ms preprocess, 5.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 3.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.5ms\n",
      "Speed: 2.0ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.7ms\n",
      "Speed: 1.0ms preprocess, 5.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.6ms\n",
      "Speed: 2.0ms preprocess, 5.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.4ms\n",
      "Speed: 1.0ms preprocess, 8.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.4ms\n",
      "Speed: 1.0ms preprocess, 5.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.3ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.6ms\n",
      "Speed: 3.0ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.8ms\n",
      "Speed: 2.0ms preprocess, 6.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.8ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 1.7ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 3.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.2ms\n",
      "Speed: 1.0ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.9ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.8ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.8ms\n",
      "Speed: 2.0ms preprocess, 6.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.4ms\n",
      "Speed: 1.0ms preprocess, 5.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 18.0ms\n",
      "Speed: 2.0ms preprocess, 18.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.6ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.0ms\n",
      "Speed: 1.0ms preprocess, 14.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.9ms\n",
      "Speed: 2.1ms preprocess, 4.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.8ms\n",
      "Speed: 2.0ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.3ms\n",
      "Speed: 2.0ms preprocess, 11.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 22.1ms\n",
      "Speed: 2.0ms preprocess, 22.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.9ms\n",
      "Speed: 2.0ms preprocess, 4.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 1.7ms preprocess, 8.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.8ms\n",
      "Speed: 2.0ms preprocess, 6.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.4ms\n",
      "Speed: 2.0ms preprocess, 5.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.8ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.8ms\n",
      "Speed: 1.0ms preprocess, 11.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.8ms\n",
      "Speed: 1.0ms preprocess, 5.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.8ms\n",
      "Speed: 2.0ms preprocess, 5.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.8ms\n",
      "Speed: 1.0ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.5ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.2ms\n",
      "Speed: 2.0ms preprocess, 6.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.3ms\n",
      "Speed: 2.0ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 1.9ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.5ms\n",
      "Speed: 1.0ms preprocess, 10.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.4ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.8ms\n",
      "Speed: 2.0ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.8ms\n",
      "Speed: 2.0ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.8ms\n",
      "Speed: 2.0ms preprocess, 4.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.4ms\n",
      "Speed: 2.0ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.8ms\n",
      "Speed: 1.0ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.5ms\n",
      "Speed: 2.0ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.9ms\n",
      "Speed: 3.0ms preprocess, 14.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.5ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.5ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.4ms\n",
      "Speed: 2.0ms preprocess, 5.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.8ms\n",
      "Speed: 2.0ms preprocess, 5.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 0.8ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.8ms\n",
      "Speed: 2.0ms preprocess, 5.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.7ms\n",
      "Speed: 3.0ms preprocess, 4.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.9ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.8ms\n",
      "Speed: 1.0ms preprocess, 5.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.9ms\n",
      "Speed: 2.0ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.4ms\n",
      "Speed: 2.0ms preprocess, 5.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.3ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.7ms\n",
      "Speed: 2.0ms preprocess, 7.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.1ms\n",
      "Speed: 1.0ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.5ms\n",
      "Speed: 1.0ms preprocess, 4.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.6ms\n",
      "Speed: 3.0ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.5ms\n",
      "Speed: 2.0ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.8ms\n",
      "Speed: 1.0ms preprocess, 9.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.7ms\n",
      "Speed: 1.0ms preprocess, 5.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.8ms\n",
      "Speed: 2.0ms preprocess, 4.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 book, 13.2ms\n",
      "Speed: 2.0ms preprocess, 13.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 4.6ms\n",
      "Speed: 2.0ms preprocess, 4.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 12.1ms\n",
      "Speed: 3.0ms preprocess, 12.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.0ms\n",
      "Speed: 1.7ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 13.4ms\n",
      "Speed: 2.0ms preprocess, 13.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 8.8ms\n",
      "Speed: 2.0ms preprocess, 8.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.5ms\n",
      "Speed: 1.0ms preprocess, 5.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.6ms\n",
      "Speed: 1.0ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 8.9ms\n",
      "Speed: 2.0ms preprocess, 8.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.0ms\n",
      "Speed: 2.4ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 tvs, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.3ms\n",
      "Speed: 0.8ms preprocess, 6.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 1.7ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 13.8ms\n",
      "Speed: 2.0ms preprocess, 13.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.0ms\n",
      "Speed: 3.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.8ms\n",
      "Speed: 2.0ms preprocess, 7.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 8.0ms\n",
      "Speed: 1.9ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 4.0ms preprocess, 5.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 4.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 13.1ms\n",
      "Speed: 2.0ms preprocess, 13.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 11.0ms\n",
      "Speed: 1.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.8ms\n",
      "Speed: 1.0ms preprocess, 6.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.5ms\n",
      "Speed: 1.0ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 10.0ms\n",
      "Speed: 2.7ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.0ms\n",
      "Speed: 1.8ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 3.0ms preprocess, 5.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 2.1ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 9.8ms\n",
      "Speed: 2.0ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.7ms\n",
      "Speed: 2.0ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.3ms\n",
      "Speed: 1.0ms preprocess, 5.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.6ms\n",
      "Speed: 2.0ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 12.6ms\n",
      "Speed: 2.0ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.5ms\n",
      "Speed: 1.0ms preprocess, 5.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.0ms\n",
      "Speed: 3.0ms preprocess, 7.0ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.6ms\n",
      "Speed: 2.0ms preprocess, 6.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 10.4ms\n",
      "Speed: 1.0ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 2.5ms preprocess, 6.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 9.8ms\n",
      "Speed: 2.0ms preprocess, 9.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 4.4ms\n",
      "Speed: 2.0ms preprocess, 4.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 8.5ms\n",
      "Speed: 2.0ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 13.6ms\n",
      "Speed: 1.0ms preprocess, 13.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 10.2ms\n",
      "Speed: 1.0ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.4ms\n",
      "Speed: 1.0ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.2ms\n",
      "Speed: 2.0ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 11.0ms\n",
      "Speed: 6.0ms preprocess, 11.0ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 8.5ms\n",
      "Speed: 1.3ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.8ms\n",
      "Speed: 3.0ms preprocess, 6.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 12.0ms\n",
      "Speed: 1.0ms preprocess, 12.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.6ms\n",
      "Speed: 2.0ms preprocess, 5.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.2ms\n",
      "Speed: 2.0ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 11.0ms\n",
      "Speed: 3.5ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 4.7ms\n",
      "Speed: 2.0ms preprocess, 4.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 8.1ms\n",
      "Speed: 2.0ms preprocess, 8.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 3.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 13.0ms\n",
      "Speed: 1.9ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 14.5ms\n",
      "Speed: 1.0ms preprocess, 14.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 9.3ms\n",
      "Speed: 2.0ms preprocess, 9.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.9ms\n",
      "Speed: 2.0ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 9.5ms\n",
      "Speed: 2.0ms preprocess, 9.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 9.4ms\n",
      "Speed: 3.0ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.4ms\n",
      "Speed: 1.0ms preprocess, 5.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 13.9ms\n",
      "Speed: 1.0ms preprocess, 13.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 9.8ms\n",
      "Speed: 1.0ms preprocess, 9.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 4.9ms\n",
      "Speed: 1.5ms preprocess, 4.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 4.8ms\n",
      "Speed: 2.1ms preprocess, 4.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 3.4ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 9.8ms\n",
      "Speed: 2.0ms preprocess, 9.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.8ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.7ms\n",
      "Speed: 1.0ms preprocess, 6.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.3ms\n",
      "Speed: 1.7ms preprocess, 5.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 13.4ms\n",
      "Speed: 3.0ms preprocess, 13.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 10.4ms\n",
      "Speed: 2.0ms preprocess, 10.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.8ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.5ms\n",
      "Speed: 2.0ms preprocess, 5.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 10.3ms\n",
      "Speed: 1.0ms preprocess, 10.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.5ms\n",
      "Speed: 2.0ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 4.8ms\n",
      "Speed: 2.0ms preprocess, 4.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.6ms\n",
      "Speed: 2.0ms preprocess, 5.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 13.0ms\n",
      "Speed: 1.9ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 14.0ms\n",
      "Speed: 1.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.6ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.9ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 13.8ms\n",
      "Speed: 1.0ms preprocess, 13.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.0ms\n",
      "Speed: 3.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 1 book, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 1 book, 5.0ms\n",
      "Speed: 4.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 book, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 book, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.8ms\n",
      "Speed: 2.0ms preprocess, 8.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.5ms\n",
      "Speed: 2.0ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.6ms\n",
      "Speed: 2.0ms preprocess, 13.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 remote, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 remote, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 remote, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 remote, 7.0ms\n",
      "Speed: 8.0ms preprocess, 7.0ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.8ms\n",
      "Speed: 3.0ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.8ms\n",
      "Speed: 2.0ms preprocess, 14.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.6ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 0.9ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 7.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.9ms preprocess, 5.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.8ms\n",
      "Speed: 2.0ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.0ms\n",
      "Speed: 6.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.9ms\n",
      "Speed: 2.0ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.6ms\n",
      "Speed: 2.0ms preprocess, 7.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 remote, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.5ms\n",
      "Speed: 2.0ms preprocess, 5.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.5ms\n",
      "Speed: 2.0ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.6ms\n",
      "Speed: 3.0ms preprocess, 5.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 0.8ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.5ms\n",
      "Speed: 3.0ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.5ms\n",
      "Speed: 4.0ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.8ms\n",
      "Speed: 1.0ms preprocess, 4.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.8ms\n",
      "Speed: 1.0ms preprocess, 4.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.4ms\n",
      "Speed: 4.0ms preprocess, 10.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.7ms\n",
      "Speed: 1.0ms preprocess, 8.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.2ms\n",
      "Speed: 2.0ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.9ms\n",
      "Speed: 1.0ms preprocess, 4.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 4.0ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.5ms\n",
      "Speed: 4.0ms preprocess, 14.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.9ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.8ms\n",
      "Speed: 2.0ms preprocess, 13.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 3.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.9ms\n",
      "Speed: 2.0ms preprocess, 4.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.8ms\n",
      "Speed: 1.0ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 3.0ms preprocess, 6.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.9ms\n",
      "Speed: 1.0ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.7ms\n",
      "Speed: 1.0ms preprocess, 7.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 5.0ms preprocess, 9.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.8ms\n",
      "Speed: 2.0ms preprocess, 4.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.6ms\n",
      "Speed: 2.0ms preprocess, 4.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.0ms\n",
      "Speed: 1.0ms preprocess, 13.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.7ms\n",
      "Speed: 2.0ms preprocess, 6.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.8ms\n",
      "Speed: 1.0ms preprocess, 11.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.8ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.1ms\n",
      "Speed: 2.0ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.3ms\n",
      "Speed: 1.0ms preprocess, 5.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.4ms\n",
      "Speed: 2.0ms preprocess, 12.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.3ms\n",
      "Speed: 2.0ms preprocess, 5.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.8ms\n",
      "Speed: 2.0ms preprocess, 4.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.7ms\n",
      "Speed: 2.0ms preprocess, 7.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 1.4ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 3.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.4ms\n",
      "Speed: 2.0ms preprocess, 4.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.8ms\n",
      "Speed: 1.0ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.9ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.6ms\n",
      "Speed: 2.0ms preprocess, 4.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 3.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 4.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.6ms\n",
      "Speed: 2.0ms preprocess, 5.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.8ms\n",
      "Speed: 1.0ms preprocess, 4.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.9ms\n",
      "Speed: 1.0ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.5ms\n",
      "Speed: 1.0ms preprocess, 6.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 4.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.6ms\n",
      "Speed: 2.0ms preprocess, 5.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.9ms\n",
      "Speed: 2.0ms preprocess, 5.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.9ms\n",
      "Speed: 2.0ms preprocess, 4.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.8ms\n",
      "Speed: 1.0ms preprocess, 9.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.5ms\n",
      "Speed: 1.0ms preprocess, 5.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.9ms\n",
      "Speed: 1.0ms preprocess, 9.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.0ms\n",
      "Speed: 3.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 3.4ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.9ms\n",
      "Speed: 1.0ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.4ms\n",
      "Speed: 1.0ms preprocess, 5.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.0ms\n",
      "Speed: 1.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.1ms\n",
      "Speed: 2.0ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 4.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.9ms\n",
      "Speed: 2.0ms preprocess, 14.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 4.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.6ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.6ms\n",
      "Speed: 2.0ms preprocess, 5.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.2ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.5ms\n",
      "Speed: 1.0ms preprocess, 5.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 3.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.9ms\n",
      "Speed: 2.0ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.2ms\n",
      "Speed: 1.0ms preprocess, 8.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.5ms\n",
      "Speed: 2.0ms preprocess, 4.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.8ms\n",
      "Speed: 1.0ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.4ms\n",
      "Speed: 2.0ms preprocess, 4.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.8ms\n",
      "Speed: 2.0ms preprocess, 13.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.8ms\n",
      "Speed: 2.0ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.6ms\n",
      "Speed: 2.0ms preprocess, 11.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 5.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 3.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.7ms\n",
      "Speed: 2.0ms preprocess, 6.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.8ms\n",
      "Speed: 2.0ms preprocess, 4.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.8ms\n",
      "Speed: 2.0ms preprocess, 8.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.5ms\n",
      "Speed: 2.0ms preprocess, 4.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 4.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.7ms\n",
      "Speed: 1.0ms preprocess, 6.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.8ms\n",
      "Speed: 2.0ms preprocess, 12.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.6ms\n",
      "Speed: 3.0ms preprocess, 5.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.4ms\n",
      "Speed: 2.0ms preprocess, 13.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.9ms\n",
      "Speed: 1.0ms preprocess, 4.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 5.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 1.8ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.5ms\n",
      "Speed: 2.0ms preprocess, 11.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.8ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.9ms\n",
      "Speed: 2.0ms preprocess, 4.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.2ms\n",
      "Speed: 1.0ms preprocess, 8.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.9ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.4ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.8ms\n",
      "Speed: 2.0ms preprocess, 9.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.8ms\n",
      "Speed: 2.0ms preprocess, 7.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.3ms\n",
      "Speed: 2.0ms preprocess, 10.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.1ms\n",
      "Speed: 1.0ms preprocess, 6.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.1ms\n",
      "Speed: 2.5ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.7ms\n",
      "Speed: 2.0ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.8ms\n",
      "Speed: 2.0ms preprocess, 5.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.8ms\n",
      "Speed: 2.0ms preprocess, 5.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.7ms\n",
      "Speed: 3.0ms preprocess, 7.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.1ms\n",
      "Speed: 2.0ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.1ms\n",
      "Speed: 2.0ms preprocess, 7.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 6.0ms\n",
      "Speed: 4.0ms preprocess, 6.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.9ms\n",
      "Speed: 2.0ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 1 book, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 8.3ms\n",
      "Speed: 1.0ms preprocess, 8.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.5ms\n",
      "Speed: 2.0ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 5.0ms\n",
      "Speed: 1.8ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.0ms\n",
      "Speed: 3.0ms preprocess, 7.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.8ms\n",
      "Speed: 2.7ms preprocess, 7.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 tv, 7.8ms\n",
      "Speed: 2.0ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 book, 11.9ms\n",
      "Speed: 2.9ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.3ms\n",
      "Speed: 1.0ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 3.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.8ms\n",
      "Speed: 2.0ms preprocess, 4.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.8ms\n",
      "Speed: 1.9ms preprocess, 4.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.6ms\n",
      "Speed: 2.0ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.4ms\n",
      "Speed: 2.0ms preprocess, 9.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.7ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.5ms\n",
      "Speed: 2.0ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.4ms\n",
      "Speed: 1.8ms preprocess, 7.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.6ms\n",
      "Speed: 3.0ms preprocess, 5.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 3.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.5ms\n",
      "Speed: 2.0ms preprocess, 8.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.4ms\n",
      "Speed: 2.0ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.8ms\n",
      "Speed: 1.0ms preprocess, 13.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.4ms\n",
      "Speed: 2.5ms preprocess, 8.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.6ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.8ms\n",
      "Speed: 1.0ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.4ms\n",
      "Speed: 1.0ms preprocess, 8.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.4ms\n",
      "Speed: 1.0ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.3ms\n",
      "Speed: 2.0ms preprocess, 12.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.8ms\n",
      "Speed: 2.0ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.7ms\n",
      "Speed: 1.0ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.6ms\n",
      "Speed: 2.0ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.8ms\n",
      "Speed: 2.0ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.7ms\n",
      "Speed: 2.3ms preprocess, 5.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.8ms\n",
      "Speed: 2.0ms preprocess, 5.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.1ms\n",
      "Speed: 1.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.8ms\n",
      "Speed: 1.0ms preprocess, 7.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.8ms\n",
      "Speed: 1.0ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.2ms\n",
      "Speed: 2.0ms preprocess, 8.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.8ms\n",
      "Speed: 2.0ms preprocess, 9.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.5ms\n",
      "Speed: 3.0ms preprocess, 7.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.7ms\n",
      "Speed: 2.0ms preprocess, 10.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.5ms\n",
      "Speed: 2.0ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.6ms\n",
      "Speed: 3.0ms preprocess, 7.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 1.6ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 4.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.9ms\n",
      "Speed: 1.0ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.6ms\n",
      "Speed: 1.0ms preprocess, 8.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.3ms\n",
      "Speed: 2.0ms preprocess, 6.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 3.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.1ms\n",
      "Speed: 3.0ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.4ms\n",
      "Speed: 2.0ms preprocess, 5.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.4ms\n",
      "Speed: 1.0ms preprocess, 8.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.8ms\n",
      "Speed: 2.0ms preprocess, 5.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.8ms\n",
      "Speed: 2.0ms preprocess, 5.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 5.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.0ms\n",
      "Speed: 2.8ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.8ms\n",
      "Speed: 2.0ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 4.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.1ms\n",
      "Speed: 1.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 stop signs, 5.0ms\n",
      "Speed: 1.9ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 stop sign, 7.5ms\n",
      "Speed: 2.0ms preprocess, 7.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 1.9ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.4ms\n",
      "Speed: 2.0ms preprocess, 5.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.4ms\n",
      "Speed: 2.0ms preprocess, 11.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 1.8ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.6ms\n",
      "Speed: 2.0ms preprocess, 4.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 21.0ms\n",
      "Speed: 4.0ms preprocess, 21.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.5ms\n",
      "Speed: 2.0ms preprocess, 5.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.4ms\n",
      "Speed: 1.0ms preprocess, 11.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 2.9ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "from segment_anything import SamAutomaticMaskGenerator, sam_model_registry\n",
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLO  # Example with YOLOv8\n",
    "import numpy as np\n",
    "# Load SAM\n",
    "model_type = \"vit_b\"\n",
    "sam_checkpoint = \"sam_vit_b.pth\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint).to(device)\n",
    "mask_generator = SamAutomaticMaskGenerator(sam)\n",
    "\n",
    "# Load YOLO (Human detection model)\n",
    "yolo = YOLO(\"yolov8n.pt\")  # Pre-trained YOLOv8 model\n",
    "yolo.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Load model to GPU\n",
    "# Video paths\n",
    "video_path = \"pilot2/sangsu/03_Elevator1.mp4\"\n",
    "# eye_data_path = \"pilot2/processed/eyetracker.pkl\"\n",
    "# eye_data = pd.read_pickle(eye_data_path)\n",
    "output_video = \"pilot2/processed/output_with_humans.mp4\"\n",
    "\n",
    "# Open video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "out = cv2.VideoWriter(output_video, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (frame_width, frame_height))\n",
    "\n",
    "# Color for human masks\n",
    "human_color = (0, 255, 255, 127)  # Yellow (semi-transparent)\n",
    "\n",
    "def add_transparent_mask(image, mask, color):\n",
    "    \"\"\"Overlay a transparent mask on the image.\"\"\"\n",
    "    overlay = image.copy()\n",
    "    overlay[mask] = color[:3]  # RGB values\n",
    "    return cv2.addWeighted(overlay, color[3] / 255, image, 1 - color[3] / 255, 0)\n",
    "\n",
    "# Process each frame\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Detect humans using YOLO\n",
    "    results = yolo(frame)  # YOLO inference\n",
    "    human_boxes = []\n",
    "\n",
    "    # Extract detections from results\n",
    "    for result in results:\n",
    "        # Iterate through each detection\n",
    "        for detection in result.boxes:  # Access bounding boxes\n",
    "            cls = int(detection.cls)  # Class label\n",
    "            conf = detection.conf  # Confidence score\n",
    "            if cls == 0 and conf > 0.5:  # Class 0 corresponds to \"person\"\n",
    "                x_min, y_min, x_max, y_max = map(int, detection.xyxy[0])  # Bounding box coordinates\n",
    "                human_boxes.append([x_min, y_min, x_max, y_max])\n",
    "\n",
    "    # Generate fine masks for humans using SAM\n",
    "    for box in human_boxes:\n",
    "        x_min, y_min, x_max, y_max = box\n",
    "        sam_input = frame[y_min:y_max, x_min:x_max]  # Crop the human region\n",
    "        masks = mask_generator.generate(sam_input)\n",
    "\n",
    "        # Apply the mask (assume the largest mask is the human)\n",
    "        if masks:\n",
    "            largest_mask = max(masks, key=lambda m: m['area'])\n",
    "            full_mask = np.zeros(frame.shape[:2], dtype=bool)\n",
    "            full_mask[y_min:y_max, x_min:x_max] = largest_mask['segmentation']\n",
    "            frame = add_transparent_mask(frame, full_mask, human_color)\n",
    "\n",
    "    # Write the frame\n",
    "    out.write(frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'segment_anything'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msegment_anything\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SamPredictor, sam_model_registry\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'segment_anything'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from segment_anything import SamPredictor, sam_model_registry\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Download and Load SAM Model\n",
    "sam_checkpoint = \"./sam_vit_b.pth\"  # Replace with appropriate model path\n",
    "model_type = \"vit_b\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint).to(device)\n",
    "predictor = SamPredictor(sam)\n",
    "\n",
    "# 2. Process Video Frames\n",
    "video_path = \"pilot2/sangsu/02_ElevatorTest.mp4\"\n",
    "eye_data_path = \"pilot2/processed/eyetracker.pkl\"\n",
    "eye_data = pd.read_pickle(eye_data_path)\n",
    "eye_data['frame_idx'] = eye_data['frame_idx'].astype(int)\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# 3. Segment and Match Gaze Points\n",
    "gaze_summary = {\"agent\": 0, \"others\": 0}\n",
    "frame_idx = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Resize and preprocess for SAM\n",
    "    input_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    predictor.set_image(input_frame)\n",
    "    masks, _, _ = predictor.predict(box=None, multimask_output=True)  # Modify for AOI detection\n",
    "    \n",
    "    # Example: Define AOIs (simplify as agent/other for illustration)\n",
    "    agent_mask = masks[0]  # Assume the first mask corresponds to the agent\n",
    "    other_mask = masks[1]  # Adjust logic based on segmentation results\n",
    "    \n",
    "    # Match gaze points to AOIs\n",
    "    gaze_data = eye_data[eye_data['frame_idx'] == frame_idx]\n",
    "    for _, gaze_point in gaze_data.iterrows():\n",
    "        x, y = int((gaze_point['pupilLSensorPosL_X']+gaze_point['pupilLSensorPosR_X'])/2), \n",
    "        int((gaze_point['pupilLSensorPosL_Y']+gaze_point['pupilLSensorPosR_Y'])/2)\n",
    "        if agent_mask[y, x]:\n",
    "            gaze_summary[\"agent\"] += 1 / fps  # Increment time spent in AOI\n",
    "        elif other_mask[y, x]:\n",
    "            gaze_summary[\"others\"] += 1 / fps\n",
    "    \n",
    "    frame_idx += 1\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# 4. Summarize and Visualize Gaze Statistics\n",
    "summary_df = pd.DataFrame([gaze_summary])\n",
    "print(summary_df)\n",
    "\n",
    "# Plotting\n",
    "plt.bar(gaze_summary.keys(), gaze_summary.values(), color=['blue', 'green'])\n",
    "plt.title(\"Gaze Time by AOI\")\n",
    "plt.ylabel(\"Time (seconds)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Tracker Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.animation import PillowWriter\n",
    "import os\n",
    "import pyxdf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def normalize_data(data):\n",
    "    \"\"\"Normalize data while handling edge cases.\"\"\"\n",
    "    data_range = np.max(data, axis=0) - np.min(data, axis=0)\n",
    "    # Prevent division by zero\n",
    "    data_range[data_range == 0] = 1\n",
    "    return (data - np.min(data, axis=0)) / data_range\n",
    "\n",
    "def check_ffmpeg():\n",
    "    \"\"\"Check if ffmpeg is available.\"\"\"\n",
    "    try:\n",
    "        import shutil\n",
    "        if shutil.which(\"ffmpeg\") is None:\n",
    "            print(\"Warning: ffmpeg not found. Using PillowWriter instead.\")\n",
    "            return False\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking ffmpeg: {e}\")\n",
    "        return False\n",
    "\n",
    "def validate_data(data):\n",
    "    \"\"\"Ensure data is valid for processing.\"\"\"\n",
    "    if not isinstance(data, np.ndarray):\n",
    "        raise ValueError(\"Input data must be a NumPy array.\")\n",
    "    if data.size == 0:\n",
    "        raise ValueError(\"Input data is empty.\")\n",
    "    if np.isnan(data).any():\n",
    "        raise ValueError(\"Input data contains NaN values.\")\n",
    "\n",
    "def create_lip_tracking_video(lip_data, output_file=\"lip_tracking.mp4\"):\n",
    "    \"\"\"\n",
    "    Create a video visualizing lip tracking data.\n",
    "    \n",
    "    Parameters:\n",
    "    - lip_data: np.ndarray\n",
    "        Lip tracking data with shape (frames, features).\n",
    "    - output_file: str\n",
    "        Path to save the video.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate lip data\n",
    "        validate_data(lip_data)\n",
    "        \n",
    "        # Normalize the lip data\n",
    "        lip_data_normalized = normalize_data(lip_data)\n",
    "\n",
    "        # Check if ffmpeg is available\n",
    "        use_ffmpeg = check_ffmpeg()\n",
    "\n",
    "        # Set up the figure\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_ylim(0, 1)\n",
    "        scatter = ax.scatter([], [])\n",
    "\n",
    "        def update(frame):\n",
    "            # Update scatter plot with the current frame\n",
    "            scatter.set_offsets(lip_data_normalized[frame].reshape(-1, 2))\n",
    "            return scatter,\n",
    "\n",
    "        # Create animation\n",
    "        ani = animation.FuncAnimation(\n",
    "            fig, update, frames=len(lip_data_normalized), blit=True\n",
    "        )\n",
    "\n",
    "        # Choose writer\n",
    "        if use_ffmpeg:\n",
    "            writer = animation.FFMpegWriter(fps=30)\n",
    "        else:\n",
    "            writer = PillowWriter(fps=30)\n",
    "\n",
    "        # Save animation\n",
    "        ani.save(output_file, writer=writer)\n",
    "        print(f\"Video saved to {output_file}\")\n",
    "    \n",
    "    except ValueError as e:\n",
    "        print(f\"ValueError: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "    finally:\n",
    "        plt.close(fig)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Simulate some lip data for testing\n",
    "    # frames = 100\n",
    "    # features = 2  # X, Y for simplicity\n",
    "    # lip_data = np.random.rand(frames, features)\n",
    "    file_path = './pilot2/raw/sangsu/sangsu_VR.xdf'\n",
    "    streams, header = pyxdf.load_xdf(file_path)\n",
    "\n",
    "    # Test the function\n",
    "    create_lip_tracking_video(lip_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stream 1: Calculated effective sampling rate 88.5949 Hz is different from specified rate 50.0000 Hz.\n",
      "Stream 2: Calculated effective sampling rate 104.0061 Hz is different from specified rate 60.0000 Hz.\n",
      "Stream 3: Calculated effective sampling rate 104.0071 Hz is different from specified rate 250.0000 Hz.\n",
      "C:\\Users\\Jiyoon\\AppData\\Local\\Temp/ipykernel_33856/887015895.py:26: RuntimeWarning: invalid value encountered in true_divide\n",
      "  lip_data_normalized = (lip_data - np.min(lip_data, axis=0)) / (np.max(lip_data, axis=0) - np.min(lip_data, axis=0))\n",
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "unknown file extension: .mp4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Jiyoon\\anaconda3\\envs\\torch\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2219\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2220\u001b[1;33m                 \u001b[0mformat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEXTENSION\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mext\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2221\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '.mp4'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_33856/887015895.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;31m# Save animation as video\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[0mani\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./pilot2/processed/lip_tracking.mp4\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ffmpeg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Jiyoon\\anaconda3\\envs\\torch\\lib\\site-packages\\matplotlib\\animation.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filename, writer, fps, dpi, codec, bitrate, extra_args, metadata, extra_anim, savefig_kwargs, progress_callback)\u001b[0m\n\u001b[0;32m   1175\u001b[0m                         \u001b[0mprogress_callback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe_number\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_frames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m                         \u001b[0mframe_number\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1177\u001b[1;33m                 \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrab_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0msavefig_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Jiyoon\\anaconda3\\envs\\torch\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Jiyoon\\anaconda3\\envs\\torch\\lib\\site-packages\\matplotlib\\animation.py\u001b[0m in \u001b[0;36msaving\u001b[1;34m(self, fig, outfile, dpi, *args, **kwargs)\u001b[0m\n\u001b[0;32m    236\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Jiyoon\\anaconda3\\envs\\torch\\lib\\site-packages\\matplotlib\\animation.py\u001b[0m in \u001b[0;36mfinish\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfinish\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 540\u001b[1;33m         self._frames[0].save(\n\u001b[0m\u001b[0;32m    541\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_all\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappend_images\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_frames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m             duration=int(1000 / self.fps), loop=0)\n",
      "\u001b[1;32mc:\\Users\\Jiyoon\\anaconda3\\envs\\torch\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2220\u001b[0m                 \u001b[0mformat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEXTENSION\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mext\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2221\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2222\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"unknown file extension: {ext}\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2224\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mSAVE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: unknown file extension: .mp4"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyxdf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load the .xdf file\n",
    "file_path = './pilot2/raw/sangsu/sangsu_VR.xdf'\n",
    "streams, header = pyxdf.load_xdf(file_path)\n",
    "\n",
    "# Find the stream containing lip tracking data\n",
    "lip_stream = None\n",
    "for stream in streams:\n",
    "    if \"lip\" in stream['info']['name'][0].lower():  # Assumes \"lip\" is in the name\n",
    "        lip_stream = stream\n",
    "        break\n",
    "\n",
    "if not lip_stream:\n",
    "    raise ValueError(\"No stream containing 'lip' data found in the .xdf file.\")\n",
    "\n",
    "# Extract lip tracking data (e.g., x, y coordinates)\n",
    "timestamps = np.array(lip_stream['time_stamps'])\n",
    "lip_data = np.array(lip_stream['time_series'])  # Assuming 2D (x, y) or 3D (x, y, z) data\n",
    "\n",
    "# Normalize data for visualization\n",
    "lip_data_normalized = (lip_data - np.min(lip_data, axis=0)) / (np.max(lip_data, axis=0) - np.min(lip_data, axis=0))\n",
    "\n",
    "# Create a real-time animation\n",
    "fig, ax = plt.subplots()\n",
    "scat = ax.scatter([], [], s=50)\n",
    "\n",
    "def init():\n",
    "    ax.set_xlim(0, 1)  # Normalized range for x\n",
    "    ax.set_ylim(0, 1)  # Normalized range for y\n",
    "    return scat,\n",
    "\n",
    "def update(frame):\n",
    "    x, y = lip_data_normalized[frame, :2]  # Extract x, y for the current frame\n",
    "    scat.set_offsets([x, y])\n",
    "    return scat,\n",
    "\n",
    "ani = FuncAnimation(fig, update, frames=len(lip_data_normalized), init_func=init, interval=30, blit=True)\n",
    "\n",
    "# Save animation as video\n",
    "ani.save(\"./pilot2/processed/lip_tracking.mp4\", writer='ffmpeg', fps=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
